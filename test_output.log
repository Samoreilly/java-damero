WARNING: A terminally deprecated method in sun.misc.Unsafe has been called
WARNING: sun.misc.Unsafe::staticFieldBase has been called by com.google.inject.internal.aop.HiddenClassDefiner (file:/home/sam-o-reilly/.m2/wrapper/dists/apache-maven-3.9.11/a2d47e15/lib/guice-5.1.0-classes.jar)
WARNING: Please consider reporting this to the maintainers of class com.google.inject.internal.aop.HiddenClassDefiner
WARNING: sun.misc.Unsafe::staticFieldBase will be removed in a future release
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for io.github.samoreilly:java-damero:jar:1.0.0
[WARNING] 'build.plugins.plugin.(groupId:artifactId)' must be unique but found duplicate declaration of plugin org.apache.maven.plugins:maven-compiler-plugin @ line 177, column 12
[WARNING] 'build.plugins.plugin.(groupId:artifactId)' must be unique but found duplicate declaration of plugin org.springframework.boot:spring-boot-maven-plugin @ line 189, column 12
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] Inspecting build with total of 1 modules
[INFO] Installing Central Publishing features
[INFO] 
[INFO] ------------------< io.github.samoreilly:java-damero >------------------
[INFO] Building java-damero 1.0.0
[INFO]   from pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- resources:3.3.1:resources (default-resources) @ java-damero ---
[INFO] Copying 1 resource from src/main/resources to target/classes
[INFO] Copying 1 resource from src/main/resources to target/classes
[INFO] 
[INFO] --- compiler:3.14.1:compile (default-compile) @ java-damero ---
[INFO] Nothing to compile - all classes are up to date.
[INFO] 
[INFO] --- resources:3.3.1:testResources (default-testResources) @ java-damero ---
[INFO] skip non existing resourceDirectory /home/sam-o-reilly/Downloads/java-damero/src/test/resources
[INFO] 
[INFO] --- compiler:3.14.1:testCompile (default-testCompile) @ java-damero ---
[INFO] Recompiling the module because of changed source code.
[INFO] Compiling 18 source files with javac [debug parameters release 21] to target/test-classes
[INFO] /home/sam-o-reilly/Downloads/java-damero/src/test/java/net/damero/RetrySchedTest.java: /home/sam-o-reilly/Downloads/java-damero/src/test/java/net/damero/RetrySchedTest.java uses unchecked or unsafe operations.
[INFO] /home/sam-o-reilly/Downloads/java-damero/src/test/java/net/damero/RetrySchedTest.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.4:test (default-test) @ java-damero ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running net.damero.TypeHandlingIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.7)

2025-12-18T15:26:16.348Z  INFO 53856 --- [           main] k.utils.Log4jControllerRegistration$     : Registered kafka:type=kafka.Log4jController MBean
2025-12-18T15:26:16.361Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : 
2025-12-18T15:26:16.361Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :   ______                  _                                          
2025-12-18T15:26:16.361Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :  |___  /                 | |                                         
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :                                               | |                     
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     :                                               |_|                     
2025-12-18T15:26:16.362Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : 
2025-12-18T15:26:16.366Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC
2025-12-18T15:26:16.366Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:host.name=Samdev
2025-12-18T15:26:16.366Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.version=25.0.1
2025-12-18T15:26:16.366Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.vendor=Oracle Corporation
2025-12-18T15:26:16.366Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.home=/usr/lib/jvm/jdk-25.0.1-oracle-x64
2025-12-18T15:26:16.366Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.class.path=/home/sam-o-reilly/Downloads/java-damero/target/test-classes:/home/sam-o-reilly/Downloads/java-damero/target/classes:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-web/3.5.7/spring-boot-starter-web-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter/3.5.7/spring-boot-starter-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot/3.5.7/spring-boot-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.5.7/spring-boot-autoconfigure-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.5.7/spring-boot-starter-logging-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.24.3/log4j-to-slf4j-2.24.3.jar:/home/sam-o-reilly/.m2/repository/org/apache/logging/log4j/log4j-api/2.24.3/log4j-api-2.24.3.jar:/home/sam-o-reilly/.m2/repository/org/slf4j/jul-to-slf4j/2.0.17/jul-to-slf4j-2.0.17.jar:/home/sam-o-reilly/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/sam-o-reilly/.m2/repository/org/yaml/snakeyaml/2.4/snakeyaml-2.4.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.5.7/spring-boot-starter-json-3.5.7.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.19.2/jackson-datatype-jdk8-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.19.2/jackson-module-parameter-names-2.19.2.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/3.5.7/spring-boot-starter-tomcat-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/10.1.48/tomcat-embed-core-10.1.48.jar:/home/sam-o-reilly/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/10.1.48/tomcat-embed-el-10.1.48.jar:/home/sam-o-reilly/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/10.1.48/tomcat-embed-websocket-10.1.48.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-web/6.2.12/spring-web-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-webmvc/6.2.12/spring-webmvc-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-context/6.2.12/spring-context-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-aop/6.2.12/spring-aop-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-beans/6.2.12/spring-beans-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-core/6.2.12/spring-core-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-jcl/6.2.12/spring-jcl-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-expression/6.2.12/spring-expression-6.2.12.jar:/home/sam-o-reilly/.m2/repository/io/micrometer/micrometer-observation/1.15.5/micrometer-observation-1.15.5.jar:/home/sam-o-reilly/.m2/repository/org/projectlombok/lombok/1.18.42/lombok-1.18.42.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-aop/3.5.7/spring-boot-starter-aop-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/aspectj/aspectjweaver/1.9.24/aspectjweaver-1.9.24.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-test/3.5.7/spring-boot-starter-test-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-test/3.5.7/spring-boot-test-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/3.5.7/spring-boot-test-autoconfigure-3.5.7.jar:/home/sam-o-reilly/.m2/repository/com/jayway/jsonpath/json-path/2.9.0/json-path-2.9.0.jar:/home/sam-o-reilly/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/4.0.4/jakarta.xml.bind-api-4.0.4.jar:/home/sam-o-reilly/.m2/repository/jakarta/activation/jakarta.activation-api/2.1.4/jakarta.activation-api-2.1.4.jar:/home/sam-o-reilly/.m2/repository/net/minidev/json-smart/2.5.2/json-smart-2.5.2.jar:/home/sam-o-reilly/.m2/repository/net/minidev/accessors-smart/2.5.2/accessors-smart-2.5.2.jar:/home/sam-o-reilly/.m2/repository/org/ow2/asm/asm/9.7.1/asm-9.7.1.jar:/home/sam-o-reilly/.m2/repository/org/assertj/assertj-core/3.27.6/assertj-core-3.27.6.jar:/home/sam-o-reilly/.m2/repository/net/bytebuddy/byte-buddy/1.17.8/byte-buddy-1.17.8.jar:/home/sam-o-reilly/.m2/repository/org/hamcrest/hamcrest/3.0/hamcrest-3.0.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter/5.12.2/junit-jupiter-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.12.2/junit-jupiter-params-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.12.2/junit-jupiter-engine-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/mockito/mockito-core/5.17.0/mockito-core-5.17.0.jar:/home/sam-o-reilly/.m2/repository/net/bytebuddy/byte-buddy-agent/1.17.8/byte-buddy-agent-1.17.8.jar:/home/sam-o-reilly/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/sam-o-reilly/.m2/repository/org/mockito/mockito-junit-jupiter/5.17.0/mockito-junit-jupiter-5.17.0.jar:/home/sam-o-reilly/.m2/repository/org/skyscreamer/jsonassert/1.5.3/jsonassert-1.5.3.jar:/home/sam-o-reilly/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-test/6.2.12/spring-test-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/xmlunit/xmlunit-core/2.10.4/xmlunit-core-2.10.4.jar:/home/sam-o-reilly/.m2/repository/io/micrometer/micrometer-core/1.15.5/micrometer-core-1.15.5.jar:/home/sam-o-reilly/.m2/repository/io/micrometer/micrometer-commons/1.15.5/micrometer-commons-1.15.5.jar:/home/sam-o-reilly/.m2/repository/org/hdrhistogram/HdrHistogram/2.2.2/HdrHistogram-2.2.2.jar:/home/sam-o-reilly/.m2/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/home/sam-o-reilly/.m2/repository/io/github/resilience4j/resilience4j-circuitbreaker/2.1.0/resilience4j-circuitbreaker-2.1.0.jar:/home/sam-o-reilly/.m2/repository/io/github/resilience4j/resilience4j-core/2.1.0/resilience4j-core-2.1.0.jar:/home/sam-o-reilly/.m2/repository/org/slf4j/slf4j-api/2.0.17/slf4j-api-2.0.17.jar:/home/sam-o-reilly/.m2/repository/com/github/ben-manes/caffeine/caffeine/3.1.8/caffeine-3.1.8.jar:/home/sam-o-reilly/.m2/repository/org/checkerframework/checker-qual/3.37.0/checker-qual-3.37.0.jar:/home/sam-o-reilly/.m2/repository/com/google/errorprone/error_prone_annotations/2.21.1/error_prone_annotations-2.21.1.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-data-redis/3.5.7/spring-boot-starter-data-redis-3.5.7.jar:/home/sam-o-reilly/.m2/repository/io/lettuce/lettuce-core/6.6.0.RELEASE/lettuce-core-6.6.0.RELEASE.jar:/home/sam-o-reilly/.m2/repository/redis/clients/authentication/redis-authx-core/0.1.1-beta2/redis-authx-core-0.1.1-beta2.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-common/4.1.128.Final/netty-common-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-handler/4.1.128.Final/netty-handler-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-resolver/4.1.128.Final/netty-resolver-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-buffer/4.1.128.Final/netty-buffer-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.128.Final/netty-transport-native-unix-common-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-codec/4.1.128.Final/netty-codec-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport/4.1.128.Final/netty-transport-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/projectreactor/reactor-core/3.7.12/reactor-core-3.7.12.jar:/home/sam-o-reilly/.m2/repository/org/reactivestreams/reactive-streams/1.0.4/reactive-streams-1.0.4.jar:/home/sam-o-reilly/.m2/repository/org/springframework/data/spring-data-redis/3.5.5/spring-data-redis-3.5.5.jar:/home/sam-o-reilly/.m2/repository/org/springframework/data/spring-data-keyvalue/3.5.5/spring-data-keyvalue-3.5.5.jar:/home/sam-o-reilly/.m2/repository/org/springframework/data/spring-data-commons/3.5.5/spring-data-commons-3.5.5.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-oxm/6.2.12/spring-oxm-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-context-support/6.2.12/spring-context-support-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/sam-o-reilly/.m2/repository/org/javassist/javassist/3.28.0-GA/javassist-3.28.0-GA.jar:/home/sam-o-reilly/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.19.2/jackson-databind-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.19.2/jackson-annotations-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.19.2/jackson-core-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.19.2/jackson-datatype-jsr310-2.19.2.jar:/home/sam-o-reilly/.m2/repository/org/springframework/kafka/spring-kafka/3.3.10/spring-kafka-3.3.10.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-messaging/6.2.12/spring-messaging-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-tx/6.2.12/spring-tx-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/retry/spring-retry/2.0.12/spring-retry-2.0.12.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1.jar:/home/sam-o-reilly/.m2/repository/com/github/luben/zstd-jni/1.5.6-4/zstd-jni-1.5.6-4.jar:/home/sam-o-reilly/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/home/sam-o-reilly/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/sam-o-reilly/.m2/repository/io/opentelemetry/opentelemetry-api/1.33.0/opentelemetry-api-1.33.0.jar:/home/sam-o-reilly/.m2/repository/io/opentelemetry/opentelemetry-context/1.49.0/opentelemetry-context-1.49.0.jar:/home/sam-o-reilly/.m2/repository/org/springframework/kafka/spring-kafka-test/3.3.10/spring-kafka-test-3.3.10.jar:/home/sam-o-reilly/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/sam-o-reilly/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/sam-o-reilly/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport-native-epoll/4.1.128.Final/netty-transport-native-epoll-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.128.Final/netty-transport-classes-epoll-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/ch/qos/logback/logback-core/1.5.20/logback-core-1.5.20.jar:/home/sam-o-reilly/.m2/repository/ch/qos/logback/logback-classic/1.5.20/logback-classic-1.5.20.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1-test.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-server/3.9.1/kafka-server-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-storage/3.9.1/kafka-storage-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-group-coordinator/3.9.1/kafka-group-coordinator-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-transaction-coordinator/3.9.1/kafka-transaction-coordinator-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-raft/3.9.1/kafka-raft-3.9.1.jar:/home/sam-o-reilly/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-metadata/3.9.1/kafka-metadata-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1.jar:/home/sam-o-reilly/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/home/sam-o-reilly/.m2/repository/org/pcollections/pcollections/4.0.1/pcollections-4.0.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1-test.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-streams-test-utils/3.9.1/kafka-streams-test-utils-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-streams/3.9.1/kafka-streams-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/rocksdb/rocksdbjni/7.9.2/rocksdbjni-7.9.2.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/scala-library/2.13.15/scala-library-2.13.15.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-group-coordinator-api/3.9.1/kafka-group-coordinator-api-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-storage-api/3.9.1/kafka-storage-api-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-tools-api/3.9.1/kafka-tools-api-3.9.1.jar:/home/sam-o-reilly/.m2/repository/net/sourceforge/argparse4j/argparse4j/0.7.0/argparse4j-0.7.0.jar:/home/sam-o-reilly/.m2/repository/commons-validator/commons-validator/1.7/commons-validator-1.7.jar:/home/sam-o-reilly/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/sam-o-reilly/.m2/repository/commons-digester/commons-digester/2.1/commons-digester-2.1.jar:/home/sam-o-reilly/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.13/2.19.2/jackson-module-scala_2.13-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8.3/paranamer-2.8.3.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-csv/2.19.2/jackson-dataformat-csv-2.19.2.jar:/home/sam-o-reilly/.m2/repository/org/bitbucket/b_c/jose4j/0.9.4/jose4j-0.9.4.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/modules/scala-collection-compat_2.13/2.10.0/scala-collection-compat_2.13-2.10.0.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/modules/scala-java8-compat_2.13/1.0.2/scala-java8-compat_2.13-1.0.2.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/scala-reflect/2.13.15/scala-reflect-2.13.15.jar:/home/sam-o-reilly/.m2/repository/com/typesafe/scala-logging/scala-logging_2.13/3.9.5/scala-logging_2.13-3.9.5.jar:/home/sam-o-reilly/.m2/repository/io/dropwizard/metrics/metrics-core/4.1.12.1/metrics-core-4.1.12.1.jar:/home/sam-o-reilly/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1-test.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.12.2/junit-jupiter-api-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/sam-o-reilly/.m2/repository/org/junit/platform/junit-platform-commons/1.12.2/junit-platform-commons-1.12.2.jar:/home/sam-o-reilly/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/platform/junit-platform-launcher/1.12.2/junit-platform-launcher-1.12.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/platform/junit-platform-engine/1.12.2/junit-platform-engine-1.12.2.jar:/home/sam-o-reilly/.m2/repository/commons-io/commons-io/2.17.0/commons-io-2.17.0.jar:/home/sam-o-reilly/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:
2025-12-18T15:26:16.368Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib
2025-12-18T15:26:16.368Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.io.tmpdir=/tmp
2025-12-18T15:26:16.368Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.compiler=<NA>
2025-12-18T15:26:16.368Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.name=Linux
2025-12-18T15:26:16.368Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.arch=amd64
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.version=6.14.0-35-generic
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:user.name=sam-o-reilly
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:user.home=/home/sam-o-reilly
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:user.dir=/home/sam-o-reilly/Downloads/java-damero
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.memory.free=40MB
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.memory.max=3932MB
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.memory.total=68MB
2025-12-18T15:26:16.369Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.enableEagerACLCheck = false
2025-12-18T15:26:16.370Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.digest.enabled = true
2025-12-18T15:26:16.370Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.closeSessionTxn.enabled = true
2025-12-18T15:26:16.371Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.flushDelay = 0 ms
2025-12-18T15:26:16.371Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.maxWriteQueuePollTime = 0 ms
2025-12-18T15:26:16.371Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.maxBatchSize=1000
2025-12-18T15:26:16.371Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : zookeeper.intBufferStartingSizeBytes = 1024
2025-12-18T15:26:16.373Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : zookeeper.snapshot.trust.empty : false
2025-12-18T15:26:16.382Z  INFO 53856 --- [           main] o.a.z.server.watch.WatchManagerFactory   : Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-12-18T15:26:16.382Z  INFO 53856 --- [           main] o.a.z.server.watch.WatchManagerFactory   : Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-12-18T15:26:16.382Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : zookeeper.snapshotSizeFactor = 0.33
2025-12-18T15:26:16.382Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : zookeeper.commitLogCount=500
2025-12-18T15:26:16.384Z  INFO 53856 --- [           main] o.apache.zookeeper.server.BlueThrottle   : Weighed connection throttling is disabled
2025-12-18T15:26:16.385Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to 1600 ms
2025-12-18T15:26:16.385Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to 16000 ms
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.apache.zookeeper.server.ResponseCache  : getData response cache size is initialized with value 400.
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.apache.zookeeper.server.ResponseCache  : getChildren response cache size is initialized with value 400.
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.slotCapacity = 60
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.slotDuration = 15
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.maxDepth = 6
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.initialDelay = 5
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.delay = 5
2025-12-18T15:26:16.386Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.enabled = false
2025-12-18T15:26:16.387Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : The max bytes for all large requests are set to 104857600
2025-12-18T15:26:16.387Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : The large request threshold is set to -1
2025-12-18T15:26:16.387Z  INFO 53856 --- [           main] o.a.z.server.AuthenticationHelper        : zookeeper.enforce.auth.enabled = false
2025-12-18T15:26:16.388Z  INFO 53856 --- [           main] o.a.z.server.AuthenticationHelper        : zookeeper.enforce.auth.schemes = []
2025-12-18T15:26:16.388Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Created server with tickTime 800 ms minSessionTimeout 1600 ms maxSessionTimeout 16000 ms clientPortListenBacklog -1 datadir /tmp/kafka-12529879620354830330/version-2 snapdir /tmp/kafka-10946241806091244046/version-2
2025-12-18T15:26:16.390Z  WARN 53856 --- [           main] o.a.zookeeper.server.ServerCnxnFactory   : maxCnxns is not configured, using default value 0.
2025-12-18T15:26:16.391Z  INFO 53856 --- [           main] o.a.z.server.NIOServerCnxnFactory        : Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-12-18T15:26:16.395Z  INFO 53856 --- [           main] o.a.z.server.NIOServerCnxnFactory        : binding to port /127.0.0.1:0
2025-12-18T15:26:16.405Z  INFO 53856 --- [           main] o.a.z.server.persistence.SnapStream      : zookeeper.snapshot.compression.method = CHECKED
2025-12-18T15:26:16.406Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : Snapshotting: 0x0 to /tmp/kafka-10946241806091244046/version-2/snapshot.0
2025-12-18T15:26:16.408Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : Snapshot loaded in 12 ms, highest zxid is 0x0, digest is 1371985504
2025-12-18T15:26:16.409Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : Snapshotting: 0x0 to /tmp/kafka-10946241806091244046/version-2/snapshot.0
2025-12-18T15:26:16.409Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Snapshot taken in 1 ms
2025-12-18T15:26:16.415Z  INFO 53856 --- [0 cport:42119):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-12-18T15:26:16.415Z  INFO 53856 --- [           main] o.a.zookeeper.server.RequestThrottler    : zookeeper.request_throttler.shutdownTimeout = 10000 ms
2025-12-18T15:26:16.514Z  INFO 53856 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 100
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:42119
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-12-18T15:26:16.535Z  INFO 53856 --- [           main] org.apache.zookeeper.common.X509Util     : Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2025-12-18T15:26:16.587Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : starting
2025-12-18T15:26:16.587Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:42119
2025-12-18T15:26:16.602Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:42119.
2025-12-18T15:26:16.604Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC
2025-12-18T15:26:16.604Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:host.name=Samdev
2025-12-18T15:26:16.604Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.version=25.0.1
2025-12-18T15:26:16.604Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.vendor=Oracle Corporation
2025-12-18T15:26:16.604Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.home=/usr/lib/jvm/jdk-25.0.1-oracle-x64
2025-12-18T15:26:16.604Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.class.path=/home/sam-o-reilly/Downloads/java-damero/target/test-classes:/home/sam-o-reilly/Downloads/java-damero/target/classes:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-web/3.5.7/spring-boot-starter-web-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter/3.5.7/spring-boot-starter-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot/3.5.7/spring-boot-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.5.7/spring-boot-autoconfigure-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.5.7/spring-boot-starter-logging-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.24.3/log4j-to-slf4j-2.24.3.jar:/home/sam-o-reilly/.m2/repository/org/apache/logging/log4j/log4j-api/2.24.3/log4j-api-2.24.3.jar:/home/sam-o-reilly/.m2/repository/org/slf4j/jul-to-slf4j/2.0.17/jul-to-slf4j-2.0.17.jar:/home/sam-o-reilly/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/sam-o-reilly/.m2/repository/org/yaml/snakeyaml/2.4/snakeyaml-2.4.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.5.7/spring-boot-starter-json-3.5.7.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.19.2/jackson-datatype-jdk8-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.19.2/jackson-module-parameter-names-2.19.2.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/3.5.7/spring-boot-starter-tomcat-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/10.1.48/tomcat-embed-core-10.1.48.jar:/home/sam-o-reilly/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/10.1.48/tomcat-embed-el-10.1.48.jar:/home/sam-o-reilly/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/10.1.48/tomcat-embed-websocket-10.1.48.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-web/6.2.12/spring-web-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-webmvc/6.2.12/spring-webmvc-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-context/6.2.12/spring-context-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-aop/6.2.12/spring-aop-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-beans/6.2.12/spring-beans-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-core/6.2.12/spring-core-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-jcl/6.2.12/spring-jcl-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-expression/6.2.12/spring-expression-6.2.12.jar:/home/sam-o-reilly/.m2/repository/io/micrometer/micrometer-observation/1.15.5/micrometer-observation-1.15.5.jar:/home/sam-o-reilly/.m2/repository/org/projectlombok/lombok/1.18.42/lombok-1.18.42.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-aop/3.5.7/spring-boot-starter-aop-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/aspectj/aspectjweaver/1.9.24/aspectjweaver-1.9.24.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-test/3.5.7/spring-boot-starter-test-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-test/3.5.7/spring-boot-test-3.5.7.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/3.5.7/spring-boot-test-autoconfigure-3.5.7.jar:/home/sam-o-reilly/.m2/repository/com/jayway/jsonpath/json-path/2.9.0/json-path-2.9.0.jar:/home/sam-o-reilly/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/4.0.4/jakarta.xml.bind-api-4.0.4.jar:/home/sam-o-reilly/.m2/repository/jakarta/activation/jakarta.activation-api/2.1.4/jakarta.activation-api-2.1.4.jar:/home/sam-o-reilly/.m2/repository/net/minidev/json-smart/2.5.2/json-smart-2.5.2.jar:/home/sam-o-reilly/.m2/repository/net/minidev/accessors-smart/2.5.2/accessors-smart-2.5.2.jar:/home/sam-o-reilly/.m2/repository/org/ow2/asm/asm/9.7.1/asm-9.7.1.jar:/home/sam-o-reilly/.m2/repository/org/assertj/assertj-core/3.27.6/assertj-core-3.27.6.jar:/home/sam-o-reilly/.m2/repository/net/bytebuddy/byte-buddy/1.17.8/byte-buddy-1.17.8.jar:/home/sam-o-reilly/.m2/repository/org/hamcrest/hamcrest/3.0/hamcrest-3.0.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter/5.12.2/junit-jupiter-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.12.2/junit-jupiter-params-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.12.2/junit-jupiter-engine-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/mockito/mockito-core/5.17.0/mockito-core-5.17.0.jar:/home/sam-o-reilly/.m2/repository/net/bytebuddy/byte-buddy-agent/1.17.8/byte-buddy-agent-1.17.8.jar:/home/sam-o-reilly/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/sam-o-reilly/.m2/repository/org/mockito/mockito-junit-jupiter/5.17.0/mockito-junit-jupiter-5.17.0.jar:/home/sam-o-reilly/.m2/repository/org/skyscreamer/jsonassert/1.5.3/jsonassert-1.5.3.jar:/home/sam-o-reilly/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-test/6.2.12/spring-test-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/xmlunit/xmlunit-core/2.10.4/xmlunit-core-2.10.4.jar:/home/sam-o-reilly/.m2/repository/io/micrometer/micrometer-core/1.15.5/micrometer-core-1.15.5.jar:/home/sam-o-reilly/.m2/repository/io/micrometer/micrometer-commons/1.15.5/micrometer-commons-1.15.5.jar:/home/sam-o-reilly/.m2/repository/org/hdrhistogram/HdrHistogram/2.2.2/HdrHistogram-2.2.2.jar:/home/sam-o-reilly/.m2/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/home/sam-o-reilly/.m2/repository/io/github/resilience4j/resilience4j-circuitbreaker/2.1.0/resilience4j-circuitbreaker-2.1.0.jar:/home/sam-o-reilly/.m2/repository/io/github/resilience4j/resilience4j-core/2.1.0/resilience4j-core-2.1.0.jar:/home/sam-o-reilly/.m2/repository/org/slf4j/slf4j-api/2.0.17/slf4j-api-2.0.17.jar:/home/sam-o-reilly/.m2/repository/com/github/ben-manes/caffeine/caffeine/3.1.8/caffeine-3.1.8.jar:/home/sam-o-reilly/.m2/repository/org/checkerframework/checker-qual/3.37.0/checker-qual-3.37.0.jar:/home/sam-o-reilly/.m2/repository/com/google/errorprone/error_prone_annotations/2.21.1/error_prone_annotations-2.21.1.jar:/home/sam-o-reilly/.m2/repository/org/springframework/boot/spring-boot-starter-data-redis/3.5.7/spring-boot-starter-data-redis-3.5.7.jar:/home/sam-o-reilly/.m2/repository/io/lettuce/lettuce-core/6.6.0.RELEASE/lettuce-core-6.6.0.RELEASE.jar:/home/sam-o-reilly/.m2/repository/redis/clients/authentication/redis-authx-core/0.1.1-beta2/redis-authx-core-0.1.1-beta2.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-common/4.1.128.Final/netty-common-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-handler/4.1.128.Final/netty-handler-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-resolver/4.1.128.Final/netty-resolver-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-buffer/4.1.128.Final/netty-buffer-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.128.Final/netty-transport-native-unix-common-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-codec/4.1.128.Final/netty-codec-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport/4.1.128.Final/netty-transport-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/projectreactor/reactor-core/3.7.12/reactor-core-3.7.12.jar:/home/sam-o-reilly/.m2/repository/org/reactivestreams/reactive-streams/1.0.4/reactive-streams-1.0.4.jar:/home/sam-o-reilly/.m2/repository/org/springframework/data/spring-data-redis/3.5.5/spring-data-redis-3.5.5.jar:/home/sam-o-reilly/.m2/repository/org/springframework/data/spring-data-keyvalue/3.5.5/spring-data-keyvalue-3.5.5.jar:/home/sam-o-reilly/.m2/repository/org/springframework/data/spring-data-commons/3.5.5/spring-data-commons-3.5.5.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-oxm/6.2.12/spring-oxm-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-context-support/6.2.12/spring-context-support-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/sam-o-reilly/.m2/repository/org/javassist/javassist/3.28.0-GA/javassist-3.28.0-GA.jar:/home/sam-o-reilly/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.19.2/jackson-databind-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.19.2/jackson-annotations-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.19.2/jackson-core-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.19.2/jackson-datatype-jsr310-2.19.2.jar:/home/sam-o-reilly/.m2/repository/org/springframework/kafka/spring-kafka/3.3.10/spring-kafka-3.3.10.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-messaging/6.2.12/spring-messaging-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/spring-tx/6.2.12/spring-tx-6.2.12.jar:/home/sam-o-reilly/.m2/repository/org/springframework/retry/spring-retry/2.0.12/spring-retry-2.0.12.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1.jar:/home/sam-o-reilly/.m2/repository/com/github/luben/zstd-jni/1.5.6-4/zstd-jni-1.5.6-4.jar:/home/sam-o-reilly/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/home/sam-o-reilly/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/sam-o-reilly/.m2/repository/io/opentelemetry/opentelemetry-api/1.33.0/opentelemetry-api-1.33.0.jar:/home/sam-o-reilly/.m2/repository/io/opentelemetry/opentelemetry-context/1.49.0/opentelemetry-context-1.49.0.jar:/home/sam-o-reilly/.m2/repository/org/springframework/kafka/spring-kafka-test/3.3.10/spring-kafka-test-3.3.10.jar:/home/sam-o-reilly/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/sam-o-reilly/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/sam-o-reilly/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport-native-epoll/4.1.128.Final/netty-transport-native-epoll-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.128.Final/netty-transport-classes-epoll-4.1.128.Final.jar:/home/sam-o-reilly/.m2/repository/ch/qos/logback/logback-core/1.5.20/logback-core-1.5.20.jar:/home/sam-o-reilly/.m2/repository/ch/qos/logback/logback-classic/1.5.20/logback-classic-1.5.20.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1-test.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-server/3.9.1/kafka-server-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-storage/3.9.1/kafka-storage-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-group-coordinator/3.9.1/kafka-group-coordinator-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-transaction-coordinator/3.9.1/kafka-transaction-coordinator-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-raft/3.9.1/kafka-raft-3.9.1.jar:/home/sam-o-reilly/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-metadata/3.9.1/kafka-metadata-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1.jar:/home/sam-o-reilly/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/home/sam-o-reilly/.m2/repository/org/pcollections/pcollections/4.0.1/pcollections-4.0.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1-test.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-streams-test-utils/3.9.1/kafka-streams-test-utils-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-streams/3.9.1/kafka-streams-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/rocksdb/rocksdbjni/7.9.2/rocksdbjni-7.9.2.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/scala-library/2.13.15/scala-library-2.13.15.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-group-coordinator-api/3.9.1/kafka-group-coordinator-api-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-storage-api/3.9.1/kafka-storage-api-3.9.1.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka-tools-api/3.9.1/kafka-tools-api-3.9.1.jar:/home/sam-o-reilly/.m2/repository/net/sourceforge/argparse4j/argparse4j/0.7.0/argparse4j-0.7.0.jar:/home/sam-o-reilly/.m2/repository/commons-validator/commons-validator/1.7/commons-validator-1.7.jar:/home/sam-o-reilly/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/sam-o-reilly/.m2/repository/commons-digester/commons-digester/2.1/commons-digester-2.1.jar:/home/sam-o-reilly/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.13/2.19.2/jackson-module-scala_2.13-2.19.2.jar:/home/sam-o-reilly/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8.3/paranamer-2.8.3.jar:/home/sam-o-reilly/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-csv/2.19.2/jackson-dataformat-csv-2.19.2.jar:/home/sam-o-reilly/.m2/repository/org/bitbucket/b_c/jose4j/0.9.4/jose4j-0.9.4.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/modules/scala-collection-compat_2.13/2.10.0/scala-collection-compat_2.13-2.10.0.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/modules/scala-java8-compat_2.13/1.0.2/scala-java8-compat_2.13-1.0.2.jar:/home/sam-o-reilly/.m2/repository/org/scala-lang/scala-reflect/2.13.15/scala-reflect-2.13.15.jar:/home/sam-o-reilly/.m2/repository/com/typesafe/scala-logging/scala-logging_2.13/3.9.5/scala-logging_2.13-3.9.5.jar:/home/sam-o-reilly/.m2/repository/io/dropwizard/metrics/metrics-core/4.1.12.1/metrics-core-4.1.12.1.jar:/home/sam-o-reilly/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/sam-o-reilly/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1-test.jar:/home/sam-o-reilly/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.12.2/junit-jupiter-api-5.12.2.jar:/home/sam-o-reilly/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/sam-o-reilly/.m2/repository/org/junit/platform/junit-platform-commons/1.12.2/junit-platform-commons-1.12.2.jar:/home/sam-o-reilly/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/platform/junit-platform-launcher/1.12.2/junit-platform-launcher-1.12.2.jar:/home/sam-o-reilly/.m2/repository/org/junit/platform/junit-platform-engine/1.12.2/junit-platform-engine-1.12.2.jar:/home/sam-o-reilly/.m2/repository/commons-io/commons-io/2.17.0/commons-io-2.17.0.jar:/home/sam-o-reilly/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:
2025-12-18T15:26:16.605Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib
2025-12-18T15:26:16.605Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.io.tmpdir=/tmp
2025-12-18T15:26:16.605Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.compiler=<NA>
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.name=Linux
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.arch=amd64
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.version=6.14.0-35-generic
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.name=sam-o-reilly
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.home=/home/sam-o-reilly
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.dir=/home/sam-o-reilly/Downloads/java-damero
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.memory.free=13MB
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.memory.max=3932MB
2025-12-18T15:26:16.606Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.memory.total=68MB
2025-12-18T15:26:16.607Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:42119 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2b8bd798
2025-12-18T15:26:16.608Z  INFO 53856 --- [           main] org.apache.zookeeper.ClientCnxnSocket    : jute.maxbuffer value is 4194304 Bytes
2025-12-18T15:26:16.611Z  INFO 53856 --- [           main] org.apache.zookeeper.ClientCnxn          : zookeeper.request.timeout value is 0. feature enabled=false
2025-12-18T15:26:16.612Z  INFO 53856 --- [27.0.0.1:42119)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server /127.0.0.1:42119.
2025-12-18T15:26:16.612Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Waiting until connected.
2025-12-18T15:26:16.613Z  INFO 53856 --- [27.0.0.1:42119)] org.apache.zookeeper.ClientCnxn          : Socket connection established, initiating session, client: /127.0.0.1:57822, server: /127.0.0.1:42119
2025-12-18T15:26:16.617Z  INFO 53856 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2025-12-18T15:26:16.619Z  INFO 53856 --- [   SyncThread:0] o.a.zookeeper.audit.ZKAuditProvider      : ZooKeeper audit is disabled.
2025-12-18T15:26:16.622Z  INFO 53856 --- [27.0.0.1:42119)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server /127.0.0.1:42119, session id = 0x1000070ce430000, negotiated timeout = 16000
2025-12-18T15:26:16.624Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Connected.
2025-12-18T15:26:16.710Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : Cluster ID = covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:16.740Z  INFO 53856 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 100
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:42119
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-12-18T15:26:16.757Z  INFO 53856 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Starting
2025-12-18T15:26:16.757Z  INFO 53856 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Starting
2025-12-18T15:26:16.757Z  INFO 53856 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Starting
2025-12-18T15:26:16.759Z  INFO 53856 --- [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Starting
2025-12-18T15:26:16.762Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Rewriting /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/meta.properties
2025-12-18T15:26:16.786Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Loading logs from log dirs ArrayBuffer(/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280)
2025-12-18T15:26:16.789Z  INFO 53856 --- [           main] kafka.log.LogManager                     : No logs found to be loaded in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280
2025-12-18T15:26:16.796Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Loaded 0 logs in 9ms
2025-12-18T15:26:16.797Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2025-12-18T15:26:16.797Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2025-12-18T15:26:16.804Z  INFO 53856 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2025-12-18T15:26:16.809Z  INFO 53856 --- [leaner-thread-0] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Starting
2025-12-18T15:26:16.815Z  INFO 53856 --- [-process-thread] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Starting
2025-12-18T15:26:16.820Z  INFO 53856 --- [-process-thread] k.server.FinalizedFeatureChangeListener  : Feature ZK node at path: /feature does not exist
2025-12-18T15:26:16.835Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Starting
2025-12-18T15:26:16.996Z  INFO 53856 --- [           main] kafka.network.ConnectionQuotas           : Updated connection-accept-rate max connection creation rate to 2147483647
2025-12-18T15:26:16.998Z  INFO 53856 --- [           main] kafka.network.DataPlaneAcceptor          : Awaiting socket connections on localhost:35181.
2025-12-18T15:26:16.998Z  INFO 53856 --- [           main] kafka.network.DataPlaneAcceptor          : Opened wildcard endpoint localhost:35181
2025-12-18T15:26:17.006Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-12-18T15:26:17.008Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting
2025-12-18T15:26:17.022Z  INFO 53856 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Starting
2025-12-18T15:26:17.022Z  INFO 53856 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Starting
2025-12-18T15:26:17.023Z  INFO 53856 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Starting
2025-12-18T15:26:17.023Z  INFO 53856 --- [r-0-ElectLeader] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Starting
2025-12-18T15:26:17.023Z  INFO 53856 --- [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Starting
2025-12-18T15:26:17.030Z  INFO 53856 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2025-12-18T15:26:17.031Z  INFO 53856 --- [nSenderThread-0] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Starting
2025-12-18T15:26:17.048Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/0 (is it secure? false)
2025-12-18T15:26:17.058Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Stat of the created znode at /brokers/ids/0 is: 25,25,1766071577054,1766071577054,1,0,0,72058078534762496,204,0,25

2025-12-18T15:26:17.059Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:35181, czxid (broker epoch): 25
2025-12-18T15:26:17.081Z  INFO 53856 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Starting
2025-12-18T15:26:17.085Z  INFO 53856 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Starting
2025-12-18T15:26:17.088Z  INFO 53856 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Starting
2025-12-18T15:26:17.088Z  INFO 53856 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Starting
2025-12-18T15:26:17.090Z  INFO 53856 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Successfully created /controller_epoch with initial epoch 0
2025-12-18T15:26:17.093Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-12-18T15:26:17.095Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-12-18T15:26:17.097Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Starting up.
2025-12-18T15:26:17.098Z  INFO 53856 --- [ain-EventThread] k.server.FinalizedFeatureChangeListener  : Feature ZK node created at path: /feature
2025-12-18T15:26:17.100Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Startup complete.
2025-12-18T15:26:17.108Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Starting up.
2025-12-18T15:26:17.110Z  INFO 53856 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Starting
2025-12-18T15:26:17.110Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Startup complete.
2025-12-18T15:26:17.117Z  INFO 53856 --- [-process-thread] kafka.server.metadata.ZkMetadataCache    : [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0).
2025-12-18T15:26:17.117Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Registering handlers
2025-12-18T15:26:17.119Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Deleting log dir event notifications
2025-12-18T15:26:17.120Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Deleting isr change notifications
2025-12-18T15:26:17.122Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initializing controller context
2025-12-18T15:26:17.128Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-12-18T15:26:17.134Z  INFO 53856 --- [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Starting
2025-12-18T15:26:17.137Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Starting
2025-12-18T15:26:17.137Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-12-18T15:26:17.137Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-12-18T15:26:17.138Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Current list of topics in the cluster: HashSet()
2025-12-18T15:26:17.138Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Fetching topic deletions in progress
2025-12-18T15:26:17.140Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] List of topics to be deleted: 
2025-12-18T15:26:17.140Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] List of topics ineligible for deletion: 
2025-12-18T15:26:17.140Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initializing topic deletion manager
2025-12-18T15:26:17.141Z  INFO 53856 --- [er-event-thread] kafka.controller.TopicDeletionManager    : [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-12-18T15:26:17.142Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Sending update metadata request
2025-12-18T15:26:17.145Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-12-18T15:26:17.148Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Initializing replica state
2025-12-18T15:26:17.149Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-12-18T15:26:17.150Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-12-18T15:26:17.150Z  INFO 53856 --- [er-event-thread] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Initializing partition state
2025-12-18T15:26:17.151Z  INFO 53856 --- [er-event-thread] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-12-18T15:26:17.151Z  INFO 53856 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2025-12-18T15:26:17.152Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Ready to serve as the new controller with epoch 1
2025-12-18T15:26:17.153Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Controller 0 connected to localhost:35181 (id: 0 rack: null) for sending state change requests
2025-12-18T15:26:17.155Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Partitions undergoing preferred replica election: 
2025-12-18T15:26:17.155Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Partitions that completed preferred replica election: 
2025-12-18T15:26:17.155Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-12-18T15:26:17.155Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Resuming preferred replica election for partitions: 
2025-12-18T15:26:17.156Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-12-18T15:26:17.156Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-12-18T15:26:17.158Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Start processing authorizer futures
2025-12-18T15:26:17.158Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] End processing authorizer futures
2025-12-18T15:26:17.159Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Start processing enable request processing future
2025-12-18T15:26:17.159Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] End processing enable request processing future
2025-12-18T15:26:17.159Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:17.160Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:17.160Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071577159
2025-12-18T15:26:17.160Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] started
2025-12-18T15:26:17.162Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Starting the controller scheduler
2025-12-18T15:26:17.164Z  INFO 53856 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [127.0.0.1:35181]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-12-18T15:26:17.176Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:17.176Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:17.176Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071577176
2025-12-18T15:26:17.209Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:35181 (id: 0 rack: null)
2025-12-18T15:26:17.215Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic dlq-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:17.228Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(dlq-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(dlq-topic,Some(oSt_1DOWQiu4AcZ_3ghX0w),Map(dlq-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:17.228Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for dlq-topic-0
2025-12-18T15:26:17.230Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic object-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:17.230Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition dlq-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:17.230Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:17.234Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:17.237Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic double-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:17.238Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:35181 (id: 0 rack: null)
2025-12-18T15:26:17.244Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic string-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:17.248Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition dlq-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:17.250Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:17.251Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:17.251Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(object-topic, string-topic, double-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(object-topic,Some(Bqg0mNSbQ7i7aezRulS9CA),Map(object-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(string-topic,Some(FB37qzu-RR2vhzc8AR-Ctg),Map(string-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(double-topic,Some(bXZB5l2pRNyzAzBF57Km_w),Map(double-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for object-topic-0,string-topic-0,double-topic-0
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition object-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition string-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition double-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:17.254Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:17.255Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2025-12-18T15:26:17.259Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition object-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:17.259Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition string-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:17.259Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition double-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:17.260Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 3 become-leader and 0 become-follower partitions
2025-12-18T15:26:17.260Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 3 partitions
2025-12-18T15:26:17.260Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:17.265Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(dlq-topic-0)
2025-12-18T15:26:17.266Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:17.296Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=dlq-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:17.302Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition dlq-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/dlq-topic-0 with properties {}
2025-12-18T15:26:17.303Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition dlq-topic-0 broker=0] No checkpointed highwatermark is found for partition dlq-topic-0
2025-12-18T15:26:17.304Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition dlq-topic-0 broker=0] Log loaded for partition dlq-topic-0 with initial high watermark 0
2025-12-18T15:26:17.305Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader dlq-topic-0 with topic id Some(oSt_1DOWQiu4AcZ_3ghX0w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:17.315Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 61ms correlationId 1 from controller 0 for 1 partitions
2025-12-18T15:26:17.320Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-12-18T15:26:17.321Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 3 partitions
2025-12-18T15:26:17.322Z  INFO 53856 --- [quest-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(object-topic-0, double-topic-0, string-topic-0)
2025-12-18T15:26:17.322Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 3 partitions
2025-12-18T15:26:17.324Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=object-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:17.324Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition object-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/object-topic-0 with properties {}
2025-12-18T15:26:17.325Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition object-topic-0 broker=0] No checkpointed highwatermark is found for partition object-topic-0
2025-12-18T15:26:17.325Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition object-topic-0 broker=0] Log loaded for partition object-topic-0 with initial high watermark 0
2025-12-18T15:26:17.325Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader object-topic-0 with topic id Some(Bqg0mNSbQ7i7aezRulS9CA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:17.333Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=double-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:17.333Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition double-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/double-topic-0 with properties {}
2025-12-18T15:26:17.334Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition double-topic-0 broker=0] No checkpointed highwatermark is found for partition double-topic-0
2025-12-18T15:26:17.334Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition double-topic-0 broker=0] Log loaded for partition double-topic-0 with initial high watermark 0
2025-12-18T15:26:17.334Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader double-topic-0 with topic id Some(bXZB5l2pRNyzAzBF57Km_w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:17.340Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=string-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:17.341Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition string-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/string-topic-0 with properties {}
2025-12-18T15:26:17.341Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition string-topic-0 broker=0] No checkpointed highwatermark is found for partition string-topic-0
2025-12-18T15:26:17.341Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition string-topic-0 broker=0] Log loaded for partition string-topic-0 with initial high watermark 0
2025-12-18T15:26:17.341Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader string-topic-0 with topic id Some(FB37qzu-RR2vhzc8AR-Ctg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:17.345Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 24ms correlationId 3 from controller 0 for 3 partitions
2025-12-18T15:26:17.348Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 3 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-12-18T15:26:17.352Z  INFO 53856 --- [| adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2025-12-18T15:26:17.355Z  INFO 53856 --- [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:17.355Z  INFO 53856 --- [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:17.355Z  INFO 53856 --- [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:17.360Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : Starting TypeHandlingIntegrationTest using Java 25.0.1 with PID 53856 (started by sam-o-reilly in /home/sam-o-reilly/Downloads/java-damero)
2025-12-18T15:26:17.361Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : No active profile set, falling back to 1 default profile: "default"
2025-12-18T15:26:17.625Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.625Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'testEventProducerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'testEventProducerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.626Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.627Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'dlqKafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=dlqKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=dlqKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:17.627Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:17.627Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:17.627Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'consumerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=consumerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=consumerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:17.627Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:17.645Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:17.645Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:17.646Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:17.646Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:17.721Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
2025-12-18T15:26:17.722Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-12-18T15:26:17.744Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 13 ms. Found 0 Redis repository interfaces.
2025-12-18T15:26:18.114Z  WARN 53856 --- [           main] n.d.K.C.CustomKafkaAutoConfiguration     : ==> Redis not available - PluggableRedisCache using Caffeine in-memory cache. This is NOT recommended for multi-instance deployments. Add spring-boot-starter-data-redis dependency and configure Redis for production use.
2025-12-18T15:26:18.115Z  INFO 53856 --- [           main] n.d.Kafka.Config.PluggableRedisCache     : === PluggableRedisCache initialized with Caffeine backend ===
2025-12-18T15:26:18.116Z  INFO 53856 --- [           main] n.d.K.A.D.DuplicationManager             : Initializing DuplicationManager with 10 HOURS window (TTL: PT10H)
2025-12-18T15:26:18.116Z  INFO 53856 --- [           main] n.d.K.A.D.DuplicationManager             : DuplicationManager initialized. Max capacity: 50000000 entries
2025-12-18T15:26:18.116Z  INFO 53856 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : Inconsistent constructor declaration on bean with name 'circuitBreakerService': single autowire-marked constructor flagged as optional - this constructor is effectively required since there is no default constructor to fall back to: public net.damero.Kafka.Resilience.CircuitBreakerService(java.lang.Object)
2025-12-18T15:26:18.131Z  INFO 53856 --- [           main] n.d.K.T.OpenTelemetryTracingService      : OpenTelemetryTracingService initialized - distributed tracing enabled
2025-12-18T15:26:18.218Z  INFO 53856 --- [           main] org.reflections.Reflections              : Reflections took 34 ms to scan 2 urls, producing 20 keys and 496 values
WARNING: A terminally deprecated method in sun.misc.Unsafe has been called
WARNING: sun.misc.Unsafe::allocateMemory has been called by io.netty.util.internal.PlatformDependent0$2 (file:/home/sam-o-reilly/.m2/repository/io/netty/netty-common/4.1.128.Final/netty-common-4.1.128.Final.jar)
WARNING: Please consider reporting this to the maintainers of class io.netty.util.internal.PlatformDependent0$2
WARNING: sun.misc.Unsafe::allocateMemory will be removed in a future release
2025-12-18T15:26:18.832Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-dlq-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.852Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.876Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.876Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.876Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578876
2025-12-18T15:26:18.877Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Subscribed to topic(s): test-dlq
2025-12-18T15:26:18.881Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-validation-dlq-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = validation-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.881Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.887Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.887Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.888Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578887
2025-12-18T15:26:18.888Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Subscribed to topic(s): validation-dlq
2025-12-18T15:26:18.889Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-timeout-dlq-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = timeout-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.890Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.895Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.895Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.895Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578895
2025-12-18T15:26:18.895Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Subscribed to topic(s): timeout-dlq
2025-12-18T15:26:18.896Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-default-dlq-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = default-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.897Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.897Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic test-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.897Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic validation-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.899Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.899Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.899Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578899
2025-12-18T15:26:18.899Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Subscribed to topic(s): default-dlq
2025-12-18T15:26:18.900Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic timeout-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.900Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-window-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-window-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.900Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.903Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.903Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.903Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578903
2025-12-18T15:26:18.903Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Subscribed to topic(s): batch-window-topic
2025-12-18T15:26:18.905Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-circuit-breaker-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = circuit-breaker-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.905Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.905Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(validation-dlq, test-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(validation-dlq,Some(hQBiFmRNTjifQ20AYzehlg),Map(validation-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(test-dlq,Some(6Pi0mZ5kReioYY6R3YwF_w),Map(test-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.905Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for validation-dlq-0,test-dlq-0
2025-12-18T15:26:18.905Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition validation-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.905Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.905Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.905Z  WARN 53856 --- [ntainer#6-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.905Z  WARN 53856 --- [ntainer#7-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {validation-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.906Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.906Z  INFO 53856 --- [ntainer#6-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.906Z  INFO 53856 --- [ntainer#7-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.907Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic default-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.907Z  WARN 53856 --- [ntainer#8-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {timeout-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.907Z  INFO 53856 --- [ntainer#8-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.907Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.907Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.907Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578907
2025-12-18T15:26:18.908Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Subscribed to topic(s): circuit-breaker-topic
2025-12-18T15:26:18.909Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-circuit-breaker-dlq-tracker-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = circuit-breaker-dlq-tracker
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.909Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.910Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic batch-window-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.910Z  INFO 53856 --- [quest-handler-2] kafka.zk.AdminZkClient                   : Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-12-18T15:26:18.911Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition validation-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.911Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.911Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.911Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578911
2025-12-18T15:26:18.911Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.911Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.911Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Subscribed to topic(s): circuit-breaker-dlq
2025-12-18T15:26:18.912Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:18.912Z  WARN 53856 --- [ntainer#9-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {default-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.912Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.912Z  INFO 53856 --- [ntainer#9-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.912Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 5 from controller 0 for 2 partitions
2025-12-18T15:26:18.913Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-conditional-test-group-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = conditional-test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.913Z  INFO 53856 --- [quest-handler-5] kafka.zk.AdminZkClient                   : Creating topic circuit-breaker-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.913Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.913Z  INFO 53856 --- [quest-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(validation-dlq-0, test-dlq-0)
2025-12-18T15:26:18.914Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:18.914Z  WARN 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-window-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.914Z  INFO 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.916Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(timeout-dlq, default-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(default-dlq,Some(1JmnWuIZRyWTZ-H6x7DIAg),Map(default-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(timeout-dlq,Some(JdlpSe2tSBCCquu_D3UNqQ),Map(timeout-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.916Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for default-dlq-0,timeout-dlq-0
2025-12-18T15:26:18.916Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=validation-dlq-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.916Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition default-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.916Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition timeout-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.916Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.917Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition validation-dlq-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/validation-dlq-0 with properties {}
2025-12-18T15:26:18.917Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.917Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition validation-dlq-0 broker=0] No checkpointed highwatermark is found for partition validation-dlq-0
2025-12-18T15:26:18.917Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition validation-dlq-0 broker=0] Log loaded for partition validation-dlq-0 with initial high watermark 0
2025-12-18T15:26:18.917Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader validation-dlq-0 with topic id Some(hQBiFmRNTjifQ20AYzehlg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.917Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.917Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.917Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578917
2025-12-18T15:26:18.917Z  WARN 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {circuit-breaker-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.917Z  INFO 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.917Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Subscribed to topic(s): conditional-routing-test
2025-12-18T15:26:18.917Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic circuit-breaker-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.919Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.919Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.921Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.921Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.921Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578921
2025-12-18T15:26:18.922Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Subscribed to topic(s): replay-source-topic-6
2025-12-18T15:26:18.922Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition default-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.922Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition timeout-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.922Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.922Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:18.922Z  WARN 53856 --- [ntainer#4-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {circuit-breaker-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.922Z  INFO 53856 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.922Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.922Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic conditional-routing-test with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.923Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.923Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.925Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(__consumer_offsets, circuit-breaker-topic, batch-window-topic, circuit-breaker-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(OAE15fMDQuy1CtUeBdUYgg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(batch-window-topic,Some(FXjuBEJpRim96uSAB9XcwQ),Map(batch-window-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(circuit-breaker-topic,Some(Zg9oFpsORlqL9KNYajK4TA),Map(circuit-breaker-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(circuit-breaker-dlq,Some(l8umVaJlRzyxP0jX6fDwEg),Map(circuit-breaker-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.925Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=test-dlq-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.926Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition test-dlq-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/test-dlq-0 with properties {}
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for circuit-breaker-topic-0,__consumer_offsets-4,__consumer_offsets-3,batch-window-topic-0,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1,circuit-breaker-dlq-0
2025-12-18T15:26:18.926Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition test-dlq-0 broker=0] No checkpointed highwatermark is found for partition test-dlq-0
2025-12-18T15:26:18.926Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition test-dlq-0 broker=0] Log loaded for partition test-dlq-0 with initial high watermark 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader test-dlq-0 with topic id Some(6Pi0mZ5kReioYY6R3YwF_w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-window-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.926Z  INFO 53856 --- [quest-handler-5] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-6 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.926Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.927Z  WARN 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {conditional-routing-test=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.927Z  INFO 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.927Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.928Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.928Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578927
2025-12-18T15:26:18.928Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Subscribed to topic(s): replay-source-topic-4
2025-12-18T15:26:18.930Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.930Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.932Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 19ms correlationId 5 from controller 0 for 2 partitions
2025-12-18T15:26:18.932Z  WARN 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-6=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.932Z  INFO 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.933Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.933Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.933Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578933
2025-12-18T15:26:18.933Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 6
2025-12-18T15:26:18.933Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Subscribed to topic(s): replay-source-topic-5
2025-12-18T15:26:18.934Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 7 from controller 0 for 2 partitions
2025-12-18T15:26:18.934Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlq-group-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.934Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-window-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [quest-handler-2] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-4 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(timeout-dlq-0, default-dlq-0)
2025-12-18T15:26:18.935Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 7 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 8 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.935Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 8 partitions
2025-12-18T15:26:18.936Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.938Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=timeout-dlq-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.938Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.938Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.938Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578938
2025-12-18T15:26:18.938Z  INFO 53856 --- [quest-handler-5] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-5 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.938Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(conditional-routing-test, replay-source-topic-6)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(conditional-routing-test,Some(ahzTZhq9SqKJpfqXs5_HVw),Map(conditional-routing-test-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-6,Some(tFM7NuNbSS2nfeaPP3bL2A),Map(replay-source-topic-6-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.938Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for conditional-routing-test-0,replay-source-topic-6-0
2025-12-18T15:26:18.938Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Subscribed to topic(s): dlq-topic
2025-12-18T15:26:18.938Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition timeout-dlq-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/timeout-dlq-0 with properties {}
2025-12-18T15:26:18.938Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition conditional-routing-test-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.938Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-6-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.938Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.938Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition timeout-dlq-0 broker=0] No checkpointed highwatermark is found for partition timeout-dlq-0
2025-12-18T15:26:18.938Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition timeout-dlq-0 broker=0] Log loaded for partition timeout-dlq-0 with initial high watermark 0
2025-12-18T15:26:18.938Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader timeout-dlq-0 with topic id Some(JdlpSe2tSBCCquu_D3UNqQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.938Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.939Z  WARN 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-4=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.939Z  INFO 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.940Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-double-group-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = double-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.940Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.942Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.942Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.942Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578942
2025-12-18T15:26:18.942Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-double-group-13, groupId=double-group] Subscribed to topic(s): double-topic
2025-12-18T15:26:18.943Z  WARN 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-5=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.943Z  INFO 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.943Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition conditional-routing-test-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.943Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-6-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.943Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.943Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:18.943Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.944Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-capacity-group-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-capacity-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.944Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.945Z  INFO 53856 --- [tainer#11-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.946Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.946Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.946Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578946
2025-12-18T15:26:18.946Z  INFO 53856 --- [tainer#12-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-double-group-13, groupId=double-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.946Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Subscribed to topic(s): batch-capacity-topic
2025-12-18T15:26:18.946Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-4, replay-source-topic-5)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-5,Some(rMqUt7oWTFqLWMH5Dk_AWw),Map(replay-source-topic-5-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-4,Some(O9je3gMuSOu29Qk25W_CIw),Map(replay-source-topic-4-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.947Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-5-0,replay-source-topic-4-0
2025-12-18T15:26:18.947Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-5-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.947Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-4-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.947Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.947Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.947Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-multi-partition-test-group-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = multi-partition-test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.948Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.950Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-5-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.950Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-4-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.950Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.950Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:18.951Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.960Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=default-dlq-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.960Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition default-dlq-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/default-dlq-0 with properties {}
2025-12-18T15:26:18.960Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition default-dlq-0 broker=0] No checkpointed highwatermark is found for partition default-dlq-0
2025-12-18T15:26:18.960Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition default-dlq-0 broker=0] Log loaded for partition default-dlq-0 with initial high watermark 0
2025-12-18T15:26:18.961Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader default-dlq-0 with topic id Some(1JmnWuIZRyWTZ-H6x7DIAg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.961Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.961Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.961Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578961
2025-12-18T15:26:18.961Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Subscribed to topic(s): multi-partition-topic
2025-12-18T15:26:18.962Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-mixed-group-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-mixed-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.962Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.964Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.964Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic batch-capacity-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.964Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.964Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578964
2025-12-18T15:26:18.964Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Subscribed to topic(s): batch-mixed-topic
2025-12-18T15:26:18.964Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic multi-partition-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.965Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.965Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.966Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 32ms correlationId 7 from controller 0 for 2 partitions
2025-12-18T15:26:18.967Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 8
2025-12-18T15:26:18.968Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.968Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.968Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578968
2025-12-18T15:26:18.968Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-17, groupId=test-group] Subscribed to topic(s): test-topic
2025-12-18T15:26:18.968Z  WARN 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-capacity-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.968Z  INFO 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.968Z  WARN 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {multi-partition-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.968Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 9 from controller 0 for 8 partitions
2025-12-18T15:26:18.968Z  INFO 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.969Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic batch-mixed-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.969Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-multi-partition-dlq-collector-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = multi-partition-dlq-collector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.970Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.971Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(circuit-breaker-topic-0, __consumer_offsets-4, __consumer_offsets-3, batch-window-topic-0, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1, circuit-breaker-dlq-0)
2025-12-18T15:26:18.971Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 9 from controller 0 epoch 1 as part of the become-leader transition for 8 partitions
2025-12-18T15:26:18.972Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(multi-partition-topic, batch-capacity-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(batch-capacity-topic,Some(BB8JCUhMQ0Wt3O5hw9OoVQ),Map(batch-capacity-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(multi-partition-topic,Some(UGJ_xWg8SYCwQXZ5Ihn16Q),Map(multi-partition-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.972Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for batch-capacity-topic-0,multi-partition-topic-0
2025-12-18T15:26:18.972Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-capacity-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.972Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.972Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.973Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.974Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic test-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.974Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.974Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.974Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578974
2025-12-18T15:26:18.975Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Subscribed to topic(s): multi-partition-dlq
2025-12-18T15:26:18.976Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-3, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.976Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.976Z  WARN 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-mixed-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.976Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.977Z  INFO 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.977Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:18.978Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-12-18T15:26:18.978Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-capacity-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.978Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-12-18T15:26:18.978Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.978Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-3 with topic id Some(OAE15fMDQuy1CtUeBdUYgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.978Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.978Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:18.978Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.979Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.979Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.979Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578979
2025-12-18T15:26:18.979Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Subscribed to topic(s): replay-source-topic-2
2025-12-18T15:26:18.981Z  WARN 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-17, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.981Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(batch-mixed-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(batch-mixed-topic,Some(7PPEssAOTOSO3dj86_ZfPg),Map(batch-mixed-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.981Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for batch-mixed-topic-0
2025-12-18T15:26:18.981Z  INFO 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-17, groupId=test-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.981Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-mixed-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.981Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.981Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.981Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.981Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic multi-partition-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.981Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.985Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-2, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.985Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.985Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.985Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578985
2025-12-18T15:26:18.985Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-2 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.985Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Subscribed to topic(s): replay-source-topic-3
2025-12-18T15:26:18.986Z  WARN 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {multi-partition-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.986Z  INFO 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.986Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:18.986Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-12-18T15:26:18.986Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-12-18T15:26:18.986Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-2 with topic id Some(OAE15fMDQuy1CtUeBdUYgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.987Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-string-group-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = string-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.987Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.987Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-mixed-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.987Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.988Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:18.988Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.990Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(test-topic, multi-partition-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(test-topic,Some(eBtE6czfRye2FHylvZoTZQ),Map(test-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(multi-partition-dlq,Some(713EuCPCTty0lcnNSNwOLQ),Map(multi-partition-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.990Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for test-topic-0,multi-partition-dlq-0
2025-12-18T15:26:18.990Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.990Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.991Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.991Z  WARN 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-2=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.991Z  INFO 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.991Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.991Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-3 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:18.991Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.991Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.991Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578991
2025-12-18T15:26:18.992Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-string-group-21, groupId=string-group] Subscribed to topic(s): string-topic
2025-12-18T15:26:18.992Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=circuit-breaker-dlq-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:18.993Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition circuit-breaker-dlq-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/circuit-breaker-dlq-0 with properties {}
2025-12-18T15:26:18.993Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition circuit-breaker-dlq-0 broker=0] No checkpointed highwatermark is found for partition circuit-breaker-dlq-0
2025-12-18T15:26:18.993Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition circuit-breaker-dlq-0 broker=0] Log loaded for partition circuit-breaker-dlq-0 with initial high watermark 0
2025-12-18T15:26:18.993Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader circuit-breaker-dlq-0 with topic id Some(l8umVaJlRzyxP0jX6fDwEg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:18.993Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:35181]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:18.994Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:18.994Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.994Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:18.994Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:18.994Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:18.995Z  WARN 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-3=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:18.995Z  INFO 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.995Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.996Z  INFO 53856 --- [tainer#13-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-string-group-21, groupId=string-group] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:18.997Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-3, replay-source-topic-2)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-3,Some(3RpXxtXBQEeaUfzGgsvyGQ),Map(replay-source-topic-3-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-2,Some(kI29XTsZSCGSnE9WEa_RXw),Map(replay-source-topic-2-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:18.997Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-3-0,replay-source-topic-2-0
2025-12-18T15:26:18.998Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-3-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.998Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-2-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:18.997Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:18.998Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:18.998Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:18.998Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071578997
2025-12-18T15:26:18.998Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Subscribed to topic(s): replay-source-topic-1
2025-12-18T15:26:18.998Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:19.000Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=circuit-breaker-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.001Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition circuit-breaker-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/circuit-breaker-topic-0 with properties {}
2025-12-18T15:26:19.001Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition circuit-breaker-topic-0 broker=0] No checkpointed highwatermark is found for partition circuit-breaker-topic-0
2025-12-18T15:26:19.001Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition circuit-breaker-topic-0 broker=0] Log loaded for partition circuit-breaker-topic-0 with initial high watermark 0
2025-12-18T15:26:19.001Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader circuit-breaker-topic-0 with topic id Some(Zg9oFpsORlqL9KNYajK4TA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.002Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-3-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:19.002Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-2-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:19.002Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:19.002Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:19.003Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:19.003Z  INFO 53856 --- [quest-handler-2] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-1 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:19.007Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : Started TypeHandlingIntegrationTest in 2.902 seconds (process running for 3.482)
2025-12-18T15:26:19.007Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-4, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.008Z  WARN 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-1=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.008Z  INFO 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:19.008Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:19.008Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-12-18T15:26:19.008Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-12-18T15:26:19.008Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-4 with topic id Some(OAE15fMDQuy1CtUeBdUYgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.009Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-1)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-1,Some(Cg43b8npRcWPESBXDnEJcw),Map(replay-source-topic-1-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:19.009Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-1-0
2025-12-18T15:26:19.009Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-1-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:19.009Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:19.009Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:19.011Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-1-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:19.012Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:19.012Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:19.012Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:19.014Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-window-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.015Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition batch-window-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/batch-window-topic-0 with properties {}
2025-12-18T15:26:19.015Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition batch-window-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-window-topic-0
2025-12-18T15:26:19.015Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition batch-window-topic-0 broker=0] Log loaded for partition batch-window-topic-0 with initial high watermark 0
2025-12-18T15:26:19.015Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader batch-window-topic-0 with topic id Some(FXjuBEJpRim96uSAB9XcwQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.021Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-1, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.022Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:19.022Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-12-18T15:26:19.022Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-12-18T15:26:19.022Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-1 with topic id Some(OAE15fMDQuy1CtUeBdUYgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.029Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.030Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:19.030Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-12-18T15:26:19.030Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-12-18T15:26:19.030Z  WARN 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {circuit-breaker-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.030Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-0 with topic id Some(OAE15fMDQuy1CtUeBdUYgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.033Z  WARN 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {batch-window-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.035Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-12-18T15:26:19.036Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-12-18T15:26:19.037Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 69ms correlationId 9 from controller 0 for 8 partitions
Mockito is currently self-attaching to enable the inline-mock-maker. This will no longer work in future releases of the JDK. Please add Mockito as an agent to your build as described in Mockito's documentation: https://javadoc.io/doc/org.mockito/mockito-core/latest/org.mockito/org/mockito/Mockito.html#0.3
2025-12-18T15:26:19.038Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 8 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 10
2025-12-18T15:26:19.039Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 11 from controller 0 for 2 partitions
2025-12-18T15:26:19.039Z  INFO 53856 --- [quest-handler-2] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-6-0, conditional-routing-test-0)
2025-12-18T15:26:19.039Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 11 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:19.041Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2025-12-18T15:26:19.041Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2025-12-18T15:26:19.041Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2025-12-18T15:26:19.041Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2025-12-18T15:26:19.041Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2025-12-18T15:26:19.042Z  INFO 53856 --- [quest-handler-2] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-6-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.042Z  INFO 53856 --- [quest-handler-2] kafka.log.LogManager                     : Created log for partition replay-source-topic-6-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/replay-source-topic-6-0 with properties {}
2025-12-18T15:26:19.042Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition replay-source-topic-6-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-6-0
2025-12-18T15:26:19.042Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition replay-source-topic-6-0 broker=0] Log loaded for partition replay-source-topic-6-0 with initial high watermark 0
2025-12-18T15:26:19.042Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Leader replay-source-topic-6-0 with topic id Some(tFM7NuNbSS2nfeaPP3bL2A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.044Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.046Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] (Re-)joining group
2025-12-18T15:26:19.046Z  WARN 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-6=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.047Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.048Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] (Re-)joining group
2025-12-18T15:26:19.048Z  WARN 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {conditional-routing-test=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.049Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.049Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] (Re-)joining group
2025-12-18T15:26:19.050Z  INFO 53856 --- [quest-handler-2] kafka.log.UnifiedLog$                    : [LogLoader partition=conditional-routing-test-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.050Z  INFO 53856 --- [quest-handler-2] kafka.log.LogManager                     : Created log for partition conditional-routing-test-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/conditional-routing-test-0 with properties {}
2025-12-18T15:26:19.050Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition conditional-routing-test-0 broker=0] No checkpointed highwatermark is found for partition conditional-routing-test-0
2025-12-18T15:26:19.050Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition conditional-routing-test-0 broker=0] Log loaded for partition conditional-routing-test-0 with initial high watermark 0
2025-12-18T15:26:19.050Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Leader conditional-routing-test-0 with topic id Some(ahzTZhq9SqKJpfqXs5_HVw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.053Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.054Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] (Re-)joining group
2025-12-18T15:26:19.055Z  WARN 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-5=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.055Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 16ms correlationId 11 from controller 0 for 2 partitions
2025-12-18T15:26:19.061Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.061Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 12
2025-12-18T15:26:19.061Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] (Re-)joining group
2025-12-18T15:26:19.063Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 13 from controller 0 for 2 partitions
2025-12-18T15:26:19.064Z  WARN 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-4=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.064Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-5-0, replay-source-topic-4-0)
2025-12-18T15:26:19.064Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 13 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:19.065Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.065Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] (Re-)joining group
2025-12-18T15:26:19.066Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-5-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.067Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition replay-source-topic-5-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/replay-source-topic-5-0 with properties {}
2025-12-18T15:26:19.067Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.067Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition replay-source-topic-5-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-5-0
2025-12-18T15:26:19.067Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition replay-source-topic-5-0 broker=0] Log loaded for partition replay-source-topic-5-0 with initial high watermark 0
2025-12-18T15:26:19.067Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] (Re-)joining group
2025-12-18T15:26:19.067Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader replay-source-topic-5-0 with topic id Some(rMqUt7oWTFqLWMH5Dk_AWw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.071Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group circuit-breaker-dlq-tracker in Empty state. Created a new member id consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0 and request the member to rejoin with this id.
2025-12-18T15:26:19.071Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 in Empty state. Created a new member id consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061 and request the member to rejoin with this id.
2025-12-18T15:26:19.071Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 in Empty state. Created a new member id consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b and request the member to rejoin with this id.
2025-12-18T15:26:19.071Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group double-group in Empty state. Created a new member id consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4 and request the member to rejoin with this id.
2025-12-18T15:26:19.071Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group dlq-group in Empty state. Created a new member id consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97 and request the member to rejoin with this id.
2025-12-18T15:26:19.072Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc in Empty state. Created a new member id consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa and request the member to rejoin with this id.
2025-12-18T15:26:19.072Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group conditional-test-group in Empty state. Created a new member id consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a and request the member to rejoin with this id.
2025-12-18T15:26:19.074Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97
2025-12-18T15:26:19.074Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-4-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.074Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Request joining group due to: need to re-join with the given member-id: consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0
2025-12-18T15:26:19.074Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] (Re-)joining group
2025-12-18T15:26:19.074Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] (Re-)joining group
2025-12-18T15:26:19.074Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b
2025-12-18T15:26:19.074Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] (Re-)joining group
2025-12-18T15:26:19.074Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Request joining group due to: need to re-join with the given member-id: consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4
2025-12-18T15:26:19.075Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] (Re-)joining group
2025-12-18T15:26:19.075Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition replay-source-topic-4-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/replay-source-topic-4-0 with properties {}
2025-12-18T15:26:19.075Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition replay-source-topic-4-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-4-0
2025-12-18T15:26:19.075Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition replay-source-topic-4-0 broker=0] Log loaded for partition replay-source-topic-4-0 with initial high watermark 0
2025-12-18T15:26:19.075Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader replay-source-topic-4-0 with topic id Some(O9je3gMuSOu29Qk25W_CIw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.075Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Request joining group due to: need to re-join with the given member-id: consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a
2025-12-18T15:26:19.075Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061
2025-12-18T15:26:19.075Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] (Re-)joining group
2025-12-18T15:26:19.075Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa
2025-12-18T15:26:19.075Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] (Re-)joining group
2025-12-18T15:26:19.075Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] (Re-)joining group
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 16ms correlationId 13 from controller 0 for 2 partitions
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa)
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97 with group instance id None; client reason: need to re-join with the given member-id: consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97)
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group double-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4 with group instance id None; client reason: need to re-join with the given member-id: consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4)
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b)
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061)
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-dlq-tracker in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0 with group instance id None; client reason: need to re-join with the given member-id: consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0)
2025-12-18T15:26:19.080Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group conditional-test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a with group instance id None; client reason: need to re-join with the given member-id: consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a)
2025-12-18T15:26:19.081Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 14
2025-12-18T15:26:19.082Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 15 from controller 0 for 2 partitions
2025-12-18T15:26:19.082Z  WARN 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {batch-capacity-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.082Z  INFO 53856 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-partition-topic-0, batch-capacity-topic-0)
2025-12-18T15:26:19.082Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 15 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:19.083Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.084Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] (Re-)joining group
2025-12-18T15:26:19.084Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=multi-partition-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.085Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition multi-partition-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/multi-partition-topic-0 with properties {}
2025-12-18T15:26:19.085Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition multi-partition-topic-0 broker=0] No checkpointed highwatermark is found for partition multi-partition-topic-0
2025-12-18T15:26:19.085Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition multi-partition-topic-0 broker=0] Log loaded for partition multi-partition-topic-0 with initial high watermark 0
2025-12-18T15:26:19.085Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader multi-partition-topic-0 with topic id Some(UGJ_xWg8SYCwQXZ5Ihn16Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.085Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:19.086Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-capacity-group in Empty state. Created a new member id consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc and request the member to rejoin with this id.
2025-12-18T15:26:19.086Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc
2025-12-18T15:26:19.086Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] (Re-)joining group
2025-12-18T15:26:19.087Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa', protocol='range'}
2025-12-18T15:26:19.087Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-capacity-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc)
2025-12-18T15:26:19.088Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.088Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061', protocol='range'}
2025-12-18T15:26:19.088Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:19.088Z  WARN 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {multi-partition-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.089Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b', protocol='range'}
2025-12-18T15:26:19.089Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group dlq-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:19.089Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97', protocol='range'}
2025-12-18T15:26:19.089Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group double-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:19.089Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.089Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] (Re-)joining group
2025-12-18T15:26:19.090Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4', protocol='range'}
2025-12-18T15:26:19.090Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group circuit-breaker-dlq-tracker generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:19.090Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group conditional-test-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.090Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Successfully joined group with generation Generation{generationId=1, memberId='consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0', protocol='range'}
2025-12-18T15:26:19.091Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-capacity-group generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:19.091Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a', protocol='range'}
2025-12-18T15:26:19.091Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc', protocol='range'}
2025-12-18T15:26:19.091Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group multi-partition-test-group in Empty state. Created a new member id consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0 and request the member to rejoin with this id.
2025-12-18T15:26:19.092Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Request joining group due to: need to re-join with the given member-id: consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0
2025-12-18T15:26:19.092Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] (Re-)joining group
2025-12-18T15:26:19.092Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0 with group instance id None; client reason: need to re-join with the given member-id: consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0)
2025-12-18T15:26:19.093Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-capacity-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.093Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group multi-partition-test-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:19.093Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0', protocol='range'}
2025-12-18T15:26:19.093Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition batch-capacity-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/batch-capacity-topic-0 with properties {}
2025-12-18T15:26:19.093Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition batch-capacity-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-capacity-topic-0
2025-12-18T15:26:19.093Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition batch-capacity-topic-0 broker=0] Log loaded for partition batch-capacity-topic-0 with initial high watermark 0
2025-12-18T15:26:19.093Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader batch-capacity-topic-0 with topic id Some(BB8JCUhMQ0Wt3O5hw9OoVQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.093Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Finished assignment for group at generation 1: {consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0=Assignment(partitions=[circuit-breaker-dlq-0])}
2025-12-18T15:26:19.093Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Finished assignment for group at generation 1: {consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4=Assignment(partitions=[double-topic-0])}
2025-12-18T15:26:19.093Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Finished assignment for group at generation 1: {consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97=Assignment(partitions=[dlq-topic-0])}
2025-12-18T15:26:19.098Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 16ms correlationId 15 from controller 0 for 2 partitions
2025-12-18T15:26:19.099Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0 for group circuit-breaker-dlq-tracker for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.099Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97 for group dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.099Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4 for group double-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.099Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 16
2025-12-18T15:26:19.100Z  WARN 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-17, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {test-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.100Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 17 from controller 0 for 1 partitions
2025-12-18T15:26:19.101Z  WARN 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {batch-mixed-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.101Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.101Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(batch-mixed-topic-0)
2025-12-18T15:26:19.101Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 17 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:19.101Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] (Re-)joining group
2025-12-18T15:26:19.101Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.102Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] (Re-)joining group
2025-12-18T15:26:19.103Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-group in Empty state. Created a new member id consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd and request the member to rejoin with this id.
2025-12-18T15:26:19.103Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd
2025-12-18T15:26:19.103Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] (Re-)joining group
2025-12-18T15:26:19.103Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-mixed-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.103Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd with group instance id None; client reason: need to re-join with the given member-id: consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd)
2025-12-18T15:26:19.103Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-mixed-group in Empty state. Created a new member id consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a and request the member to rejoin with this id.
2025-12-18T15:26:19.103Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition batch-mixed-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/batch-mixed-topic-0 with properties {}
2025-12-18T15:26:19.104Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group test-group generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:19.104Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition batch-mixed-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-mixed-topic-0
2025-12-18T15:26:19.104Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition batch-mixed-topic-0 broker=0] Log loaded for partition batch-mixed-topic-0 with initial high watermark 0
2025-12-18T15:26:19.104Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader batch-mixed-topic-0 with topic id Some(7PPEssAOTOSO3dj86_ZfPg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.104Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a
2025-12-18T15:26:19.104Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] (Re-)joining group
2025-12-18T15:26:19.104Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd', protocol='range'}
2025-12-18T15:26:19.104Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-mixed-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a)
2025-12-18T15:26:19.105Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-mixed-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:19.105Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a', protocol='range'}
2025-12-18T15:26:19.105Z  WARN 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {multi-partition-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.107Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.107Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] (Re-)joining group
2025-12-18T15:26:19.108Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 8ms correlationId 17 from controller 0 for 1 partitions
2025-12-18T15:26:19.108Z  WARN 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-2=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.109Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group multi-partition-dlq-collector in Empty state. Created a new member id consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336 and request the member to rejoin with this id.
2025-12-18T15:26:19.109Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 18
2025-12-18T15:26:19.110Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.110Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Request joining group due to: need to re-join with the given member-id: consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336
2025-12-18T15:26:19.110Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] (Re-)joining group
2025-12-18T15:26:19.110Z  WARN 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-3=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.111Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] (Re-)joining group
2025-12-18T15:26:19.111Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-dlq-collector in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336 with group instance id None; client reason: need to re-join with the given member-id: consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336)
2025-12-18T15:26:19.111Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 19 from controller 0 for 2 partitions
2025-12-18T15:26:19.111Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.112Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] (Re-)joining group
2025-12-18T15:26:19.112Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group multi-partition-dlq-collector generation 1 (__consumer_offsets-3) with 1 members
2025-12-18T15:26:19.112Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(test-topic-0, multi-partition-dlq-0)
2025-12-18T15:26:19.112Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 19 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:19.113Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Successfully joined group with generation Generation{generationId=1, memberId='consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336', protocol='range'}
2025-12-18T15:26:19.114Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 in Empty state. Created a new member id consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee and request the member to rejoin with this id.
2025-12-18T15:26:19.115Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee
2025-12-18T15:26:19.115Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] (Re-)joining group
2025-12-18T15:26:19.115Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a in Empty state. Created a new member id consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39 and request the member to rejoin with this id.
2025-12-18T15:26:19.115Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=test-topic-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.115Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition test-topic-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/test-topic-0 with properties {}
2025-12-18T15:26:19.116Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition test-topic-0 broker=0] No checkpointed highwatermark is found for partition test-topic-0
2025-12-18T15:26:19.116Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0
2025-12-18T15:26:19.116Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader test-topic-0 with topic id Some(eBtE6czfRye2FHylvZoTZQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.117Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee)
2025-12-18T15:26:19.117Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39
2025-12-18T15:26:19.117Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] (Re-)joining group
2025-12-18T15:26:19.117Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.118Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee', protocol='range'}
2025-12-18T15:26:19.118Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.118Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39)
2025-12-18T15:26:19.118Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:19.119Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] (Re-)joining group
2025-12-18T15:26:19.119Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39', protocol='range'}
2025-12-18T15:26:19.120Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group string-group in Empty state. Created a new member id consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e and request the member to rejoin with this id.
2025-12-18T15:26:19.120Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Request joining group due to: need to re-join with the given member-id: consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e
2025-12-18T15:26:19.121Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] (Re-)joining group
2025-12-18T15:26:19.121Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group string-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e with group instance id None; client reason: need to re-join with the given member-id: consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e)
2025-12-18T15:26:19.121Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=multi-partition-dlq-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.121Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group string-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:19.122Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition multi-partition-dlq-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/multi-partition-dlq-0 with properties {}
2025-12-18T15:26:19.122Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition multi-partition-dlq-0 broker=0] No checkpointed highwatermark is found for partition multi-partition-dlq-0
2025-12-18T15:26:19.122Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition multi-partition-dlq-0 broker=0] Log loaded for partition multi-partition-dlq-0 with initial high watermark 0
2025-12-18T15:26:19.122Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e', protocol='range'}
2025-12-18T15:26:19.122Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader multi-partition-dlq-0 with topic id Some(713EuCPCTty0lcnNSNwOLQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.122Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Finished assignment for group at generation 1: {consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e=Assignment(partitions=[string-topic-0])}
2025-12-18T15:26:19.123Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e for group string-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.127Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 16ms correlationId 19 from controller 0 for 2 partitions
2025-12-18T15:26:19.128Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 20
2025-12-18T15:26:19.129Z  WARN 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-1=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:19.129Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.130Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 21 from controller 0 for 2 partitions
2025-12-18T15:26:19.130Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] (Re-)joining group
2025-12-18T15:26:19.131Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e', protocol='range'}
2025-12-18T15:26:19.131Z  INFO 53856 --- [quest-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-3-0, replay-source-topic-2-0)
2025-12-18T15:26:19.131Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4', protocol='range'}
2025-12-18T15:26:19.131Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 21 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:19.131Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Notifying assignor about the new Assignment(partitions=[string-topic-0])
2025-12-18T15:26:19.131Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Notifying assignor about the new Assignment(partitions=[double-topic-0])
2025-12-18T15:26:19.131Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97', protocol='range'}
2025-12-18T15:26:19.131Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Notifying assignor about the new Assignment(partitions=[dlq-topic-0])
2025-12-18T15:26:19.132Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Successfully synced group in generation Generation{generationId=1, memberId='consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0', protocol='range'}
2025-12-18T15:26:19.132Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Notifying assignor about the new Assignment(partitions=[circuit-breaker-dlq-0])
2025-12-18T15:26:19.133Z  INFO 53856 --- [tainer#13-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-string-group-21, groupId=string-group] Adding newly assigned partitions: string-topic-0
2025-12-18T15:26:19.133Z  INFO 53856 --- [tainer#12-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-double-group-13, groupId=double-group] Adding newly assigned partitions: double-topic-0
2025-12-18T15:26:19.133Z  INFO 53856 --- [tainer#11-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Adding newly assigned partitions: dlq-topic-0
2025-12-18T15:26:19.133Z  INFO 53856 --- [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Adding newly assigned partitions: circuit-breaker-dlq-0
2025-12-18T15:26:19.134Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 in Empty state. Created a new member id consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00 and request the member to rejoin with this id.
2025-12-18T15:26:19.134Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00
2025-12-18T15:26:19.134Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] (Re-)joining group
2025-12-18T15:26:19.135Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-3-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.136Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00)
2025-12-18T15:26:19.136Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.137Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00', protocol='range'}
2025-12-18T15:26:19.137Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition replay-source-topic-3-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/replay-source-topic-3-0 with properties {}
2025-12-18T15:26:19.137Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition replay-source-topic-3-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-3-0
2025-12-18T15:26:19.137Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition replay-source-topic-3-0 broker=0] Log loaded for partition replay-source-topic-3-0 with initial high watermark 0
2025-12-18T15:26:19.137Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader replay-source-topic-3-0 with topic id Some(3RpXxtXBQEeaUfzGgsvyGQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.143Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Found no committed offset for partition string-topic-0
2025-12-18T15:26:19.143Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Found no committed offset for partition dlq-topic-0
2025-12-18T15:26:19.143Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Found no committed offset for partition circuit-breaker-dlq-0
2025-12-18T15:26:19.143Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-2-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.143Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Found no committed offset for partition double-topic-0
2025-12-18T15:26:19.143Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition replay-source-topic-2-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/replay-source-topic-2-0 with properties {}
2025-12-18T15:26:19.143Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition replay-source-topic-2-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-2-0
2025-12-18T15:26:19.143Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition replay-source-topic-2-0 broker=0] Log loaded for partition replay-source-topic-2-0 with initial high watermark 0
2025-12-18T15:26:19.143Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader replay-source-topic-2-0 with topic id Some(kI29XTsZSCGSnE9WEa_RXw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.148Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 18ms correlationId 21 from controller 0 for 2 partitions
2025-12-18T15:26:19.149Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 22
2025-12-18T15:26:19.150Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 23 from controller 0 for 1 partitions
2025-12-18T15:26:19.151Z  INFO 53856 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-1-0)
2025-12-18T15:26:19.151Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 23 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:19.151Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Resetting offset for partition circuit-breaker-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.151Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-string-group-21, groupId=string-group] Resetting offset for partition string-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.151Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Resetting offset for partition dlq-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.151Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-double-group-13, groupId=double-group] Resetting offset for partition double-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.152Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: partitions assigned: [circuit-breaker-dlq-0]
2025-12-18T15:26:19.152Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: partitions assigned: [double-topic-0]
2025-12-18T15:26:19.152Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: partitions assigned: [dlq-topic-0]
2025-12-18T15:26:19.152Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: partitions assigned: [string-topic-0]
2025-12-18T15:26:19.153Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-1-0, dir=/tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:19.154Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition replay-source-topic-1-0 in /tmp/spring.kafka.d9920dfd-2cee-47a5-a056-992925e4be107894569072488557280/replay-source-topic-1-0 with properties {}
2025-12-18T15:26:19.154Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-1-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-1-0
2025-12-18T15:26:19.154Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-1-0 broker=0] Log loaded for partition replay-source-topic-1-0 with initial high watermark 0
2025-12-18T15:26:19.154Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader replay-source-topic-1-0 with topic id Some(Cg43b8npRcWPESBXDnEJcw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:19.158Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 8ms correlationId 23 from controller 0 for 1 partitions
2025-12-18T15:26:19.159Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 24
2025-12-18T15:26:19.185Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.185Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] (Re-)joining group
2025-12-18T15:26:19.187Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group timeout-dlq-group in Empty state. Created a new member id consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30 and request the member to rejoin with this id.
2025-12-18T15:26:19.188Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30
2025-12-18T15:26:19.188Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] (Re-)joining group
2025-12-18T15:26:19.188Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group timeout-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30 with group instance id None; client reason: need to re-join with the given member-id: consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30)
2025-12-18T15:26:19.189Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group timeout-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.189Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30', protocol='range'}
2025-12-18T15:26:19.189Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Finished assignment for group at generation 1: {consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30=Assignment(partitions=[timeout-dlq-0])}
2025-12-18T15:26:19.189Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30 for group timeout-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.190Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30', protocol='range'}
2025-12-18T15:26:19.190Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Notifying assignor about the new Assignment(partitions=[timeout-dlq-0])
2025-12-18T15:26:19.191Z  INFO 53856 --- [ntainer#8-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Adding newly assigned partitions: timeout-dlq-0
2025-12-18T15:26:19.191Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Found no committed offset for partition timeout-dlq-0
2025-12-18T15:26:19.192Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Resetting offset for partition timeout-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.192Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: partitions assigned: [timeout-dlq-0]
2025-12-18T15:26:19.210Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.211Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] (Re-)joining group
2025-12-18T15:26:19.213Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group default-dlq-group in Empty state. Created a new member id consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65 and request the member to rejoin with this id.
2025-12-18T15:26:19.213Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65
2025-12-18T15:26:19.213Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] (Re-)joining group
2025-12-18T15:26:19.213Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group default-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65 with group instance id None; client reason: need to re-join with the given member-id: consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65)
2025-12-18T15:26:19.214Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group default-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.214Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65', protocol='range'}
2025-12-18T15:26:19.214Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Finished assignment for group at generation 1: {consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65=Assignment(partitions=[default-dlq-0])}
2025-12-18T15:26:19.215Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65 for group default-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.215Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.215Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] (Re-)joining group
2025-12-18T15:26:19.216Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65', protocol='range'}
2025-12-18T15:26:19.216Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Notifying assignor about the new Assignment(partitions=[default-dlq-0])
2025-12-18T15:26:19.216Z  INFO 53856 --- [ntainer#9-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Adding newly assigned partitions: default-dlq-0
2025-12-18T15:26:19.217Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Found no committed offset for partition default-dlq-0
2025-12-18T15:26:19.217Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group validation-dlq-group in Empty state. Created a new member id consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14 and request the member to rejoin with this id.
2025-12-18T15:26:19.217Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14
2025-12-18T15:26:19.217Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] (Re-)joining group
2025-12-18T15:26:19.217Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Resetting offset for partition default-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.218Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: partitions assigned: [default-dlq-0]
2025-12-18T15:26:19.218Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group validation-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14 with group instance id None; client reason: need to re-join with the given member-id: consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14)
2025-12-18T15:26:19.218Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group validation-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.218Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14', protocol='range'}
2025-12-18T15:26:19.218Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Finished assignment for group at generation 1: {consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14=Assignment(partitions=[validation-dlq-0])}
2025-12-18T15:26:19.219Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14 for group validation-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.220Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14', protocol='range'}
2025-12-18T15:26:19.220Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Notifying assignor about the new Assignment(partitions=[validation-dlq-0])
2025-12-18T15:26:19.220Z  INFO 53856 --- [ntainer#7-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Adding newly assigned partitions: validation-dlq-0
2025-12-18T15:26:19.221Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Found no committed offset for partition validation-dlq-0
2025-12-18T15:26:19.221Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Resetting offset for partition validation-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.221Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: partitions assigned: [validation-dlq-0]
2025-12-18T15:26:19.246Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.247Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] (Re-)joining group
2025-12-18T15:26:19.249Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-dlq-group in Empty state. Created a new member id consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273 and request the member to rejoin with this id.
2025-12-18T15:26:19.249Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273
2025-12-18T15:26:19.249Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] (Re-)joining group
2025-12-18T15:26:19.250Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273 with group instance id None; client reason: need to re-join with the given member-id: consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273)
2025-12-18T15:26:19.251Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group test-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:19.251Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273', protocol='range'}
2025-12-18T15:26:19.251Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Finished assignment for group at generation 1: {consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273=Assignment(partitions=[test-dlq-0])}
2025-12-18T15:26:19.252Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273 for group test-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.252Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273', protocol='range'}
2025-12-18T15:26:19.252Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Notifying assignor about the new Assignment(partitions=[test-dlq-0])
2025-12-18T15:26:19.252Z  INFO 53856 --- [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Adding newly assigned partitions: test-dlq-0
2025-12-18T15:26:19.253Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Found no committed offset for partition test-dlq-0
2025-12-18T15:26:19.254Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Resetting offset for partition test-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.254Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: partitions assigned: [test-dlq-0]
WARNING: A Java agent has been loaded dynamically (/home/sam-o-reilly/.m2/repository/net/bytebuddy/byte-buddy-agent/1.17.8/byte-buddy-agent-1.17.8.jar)
WARNING: If a serviceability tool is in use, please run with -XX:+EnableDynamicAgentLoading to hide this warning
WARNING: If a serviceability tool is not in use, please run with -Djdk.instrument.traceUsage for more information
WARNING: Dynamic loading of agents will be disallowed by default in a future release
2025-12-18T15:26:19.264Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Finished assignment for group at generation 1: {consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a=Assignment(partitions=[conditional-routing-test-0])}
Java HotSpot(TM) 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
2025-12-18T15:26:19.265Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a for group conditional-test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.265Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.266Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] (Re-)joining group
2025-12-18T15:26:19.266Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a', protocol='range'}
2025-12-18T15:26:19.266Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Notifying assignor about the new Assignment(partitions=[conditional-routing-test-0])
2025-12-18T15:26:19.267Z  INFO 53856 --- [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Adding newly assigned partitions: conditional-routing-test-0
2025-12-18T15:26:19.268Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Found no committed offset for partition conditional-routing-test-0
2025-12-18T15:26:19.268Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group circuit-breaker-group in Empty state. Created a new member id consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3 and request the member to rejoin with this id.
2025-12-18T15:26:19.269Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Resetting offset for partition conditional-routing-test-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.269Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Request joining group due to: need to re-join with the given member-id: consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3
2025-12-18T15:26:19.269Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: partitions assigned: [conditional-routing-test-0]
2025-12-18T15:26:19.269Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] (Re-)joining group
2025-12-18T15:26:19.269Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3 with group instance id None; client reason: need to re-join with the given member-id: consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3)
2025-12-18T15:26:19.270Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group circuit-breaker-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:19.270Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3', protocol='range'}
2025-12-18T15:26:19.270Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Finished assignment for group at generation 1: {consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3=Assignment(partitions=[circuit-breaker-topic-0])}
2025-12-18T15:26:19.270Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3 for group circuit-breaker-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.272Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3', protocol='range'}
2025-12-18T15:26:19.272Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Notifying assignor about the new Assignment(partitions=[circuit-breaker-topic-0])
2025-12-18T15:26:19.272Z  INFO 53856 --- [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Adding newly assigned partitions: circuit-breaker-topic-0
2025-12-18T15:26:19.272Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Finished assignment for group at generation 1: {consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b=Assignment(partitions=[replay-source-topic-4-0])}
2025-12-18T15:26:19.272Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Finished assignment for group at generation 1: {consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061=Assignment(partitions=[replay-source-topic-6-0])}
2025-12-18T15:26:19.272Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b for group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.273Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Found no committed offset for partition circuit-breaker-topic-0
2025-12-18T15:26:19.273Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061 for group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.273Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Discovered group coordinator localhost:35181 (id: 2147483647 rack: null)
2025-12-18T15:26:19.274Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Resetting offset for partition circuit-breaker-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.274Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: partitions assigned: [circuit-breaker-topic-0]
2025-12-18T15:26:19.274Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b', protocol='range'}
2025-12-18T15:26:19.274Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Notifying assignor about the new Assignment(partitions=[replay-source-topic-4-0])
2025-12-18T15:26:19.274Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] (Re-)joining group
2025-12-18T15:26:19.274Z  INFO 53856 --- [tainer#17-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Adding newly assigned partitions: replay-source-topic-4-0
2025-12-18T15:26:19.274Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061', protocol='range'}
2025-12-18T15:26:19.274Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Notifying assignor about the new Assignment(partitions=[replay-source-topic-6-0])
2025-12-18T15:26:19.274Z  INFO 53856 --- [tainer#19-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Adding newly assigned partitions: replay-source-topic-6-0
2025-12-18T15:26:19.275Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Found no committed offset for partition replay-source-topic-4-0
2025-12-18T15:26:19.275Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Resetting offset for partition replay-source-topic-4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.275Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9: partitions assigned: [replay-source-topic-4-0]
2025-12-18T15:26:19.275Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Found no committed offset for partition replay-source-topic-6-0
2025-12-18T15:26:19.275Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-window-group in Empty state. Created a new member id consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409 and request the member to rejoin with this id.
2025-12-18T15:26:19.275Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409
2025-12-18T15:26:19.276Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] (Re-)joining group
2025-12-18T15:26:19.276Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Resetting offset for partition replay-source-topic-6-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.276Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-window-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409 with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409)
2025-12-18T15:26:19.276Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8: partitions assigned: [replay-source-topic-6-0]
2025-12-18T15:26:19.276Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Finished assignment for group at generation 1: {consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc=Assignment(partitions=[batch-capacity-topic-0])}
2025-12-18T15:26:19.276Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-window-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:19.276Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409', protocol='range'}
2025-12-18T15:26:19.277Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc for group batch-capacity-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.277Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Finished assignment for group at generation 1: {consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409=Assignment(partitions=[batch-window-topic-0])}
2025-12-18T15:26:19.277Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409 for group batch-window-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.277Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc', protocol='range'}
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Notifying assignor about the new Assignment(partitions=[batch-capacity-topic-0])
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409', protocol='range'}
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Adding newly assigned partitions: batch-capacity-topic-0
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Notifying assignor about the new Assignment(partitions=[batch-window-topic-0])
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Adding newly assigned partitions: batch-window-topic-0
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Found no committed offset for partition batch-window-topic-0
2025-12-18T15:26:19.278Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Found no committed offset for partition batch-capacity-topic-0
2025-12-18T15:26:19.279Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Resetting offset for partition batch-window-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.279Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Resetting offset for partition batch-capacity-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.279Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: partitions assigned: [batch-window-topic-0]
2025-12-18T15:26:19.279Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: partitions assigned: [batch-capacity-topic-0]
2025-12-18T15:26:19.289Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Finished assignment for group at generation 1: {consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa=Assignment(partitions=[replay-source-topic-5-0])}
2025-12-18T15:26:19.289Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa for group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.290Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa', protocol='range'}
2025-12-18T15:26:19.290Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Notifying assignor about the new Assignment(partitions=[replay-source-topic-5-0])
2025-12-18T15:26:19.290Z  INFO 53856 --- [tainer#18-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Adding newly assigned partitions: replay-source-topic-5-0
2025-12-18T15:26:19.291Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Found no committed offset for partition replay-source-topic-5-0
2025-12-18T15:26:19.292Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Resetting offset for partition replay-source-topic-5-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.292Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc: partitions assigned: [replay-source-topic-5-0]
2025-12-18T15:26:19.297Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Finished assignment for group at generation 1: {consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee=Assignment(partitions=[replay-source-topic-3-0])}
2025-12-18T15:26:19.297Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee for group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.299Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee', protocol='range'}
2025-12-18T15:26:19.299Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Notifying assignor about the new Assignment(partitions=[replay-source-topic-3-0])
2025-12-18T15:26:19.299Z  INFO 53856 --- [tainer#16-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Adding newly assigned partitions: replay-source-topic-3-0
2025-12-18T15:26:19.299Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Found no committed offset for partition replay-source-topic-3-0
2025-12-18T15:26:19.300Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Resetting offset for partition replay-source-topic-3-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.300Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56: partitions assigned: [replay-source-topic-3-0]
2025-12-18T15:26:19.316Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Finished assignment for group at generation 1: {consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39=Assignment(partitions=[replay-source-topic-2-0])}
2025-12-18T15:26:19.317Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39 for group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.317Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Finished assignment for group at generation 1: {consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0=Assignment(partitions=[multi-partition-topic-0])}
2025-12-18T15:26:19.318Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39', protocol='range'}
2025-12-18T15:26:19.318Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Notifying assignor about the new Assignment(partitions=[replay-source-topic-2-0])
2025-12-18T15:26:19.318Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0 for group multi-partition-test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.318Z  INFO 53856 --- [tainer#15-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Adding newly assigned partitions: replay-source-topic-2-0
2025-12-18T15:26:19.318Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Found no committed offset for partition replay-source-topic-2-0
2025-12-18T15:26:19.319Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0', protocol='range'}
2025-12-18T15:26:19.319Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Notifying assignor about the new Assignment(partitions=[multi-partition-topic-0])
2025-12-18T15:26:19.319Z  INFO 53856 --- [tainer#20-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Adding newly assigned partitions: multi-partition-topic-0
2025-12-18T15:26:19.319Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Resetting offset for partition replay-source-topic-2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.319Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a: partitions assigned: [replay-source-topic-2-0]
2025-12-18T15:26:19.320Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Found no committed offset for partition multi-partition-topic-0
2025-12-18T15:26:19.320Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Resetting offset for partition multi-partition-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.320Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: partitions assigned: [multi-partition-topic-0]
2025-12-18T15:26:19.333Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd=Assignment(partitions=[test-topic-0])}
2025-12-18T15:26:19.333Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd for group test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.334Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd', protocol='range'}
2025-12-18T15:26:19.334Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Notifying assignor about the new Assignment(partitions=[test-topic-0])
2025-12-18T15:26:19.334Z  INFO 53856 --- [tainer#10-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-17, groupId=test-group] Adding newly assigned partitions: test-topic-0
2025-12-18T15:26:19.335Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Found no committed offset for partition test-topic-0
2025-12-18T15:26:19.335Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Finished assignment for group at generation 1: {consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336=Assignment(partitions=[multi-partition-dlq-0])}
2025-12-18T15:26:19.335Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-17, groupId=test-group] Resetting offset for partition test-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.335Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [test-topic-0]
2025-12-18T15:26:19.335Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336 for group multi-partition-dlq-collector for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.336Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Successfully synced group in generation Generation{generationId=1, memberId='consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336', protocol='range'}
2025-12-18T15:26:19.337Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Notifying assignor about the new Assignment(partitions=[multi-partition-dlq-0])
2025-12-18T15:26:19.337Z  INFO 53856 --- [tainer#21-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Adding newly assigned partitions: multi-partition-dlq-0
2025-12-18T15:26:19.337Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Found no committed offset for partition multi-partition-dlq-0
2025-12-18T15:26:19.337Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Finished assignment for group at generation 1: {consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a=Assignment(partitions=[batch-mixed-topic-0])}
2025-12-18T15:26:19.338Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a for group batch-mixed-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.338Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Resetting offset for partition multi-partition-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.338Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: partitions assigned: [multi-partition-dlq-0]
2025-12-18T15:26:19.338Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a', protocol='range'}
2025-12-18T15:26:19.339Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Notifying assignor about the new Assignment(partitions=[batch-mixed-topic-0])
2025-12-18T15:26:19.339Z  INFO 53856 --- [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Adding newly assigned partitions: batch-mixed-topic-0
2025-12-18T15:26:19.339Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Found no committed offset for partition batch-mixed-topic-0
2025-12-18T15:26:19.340Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Resetting offset for partition batch-mixed-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.340Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: partitions assigned: [batch-mixed-topic-0]
2025-12-18T15:26:19.362Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Finished assignment for group at generation 1: {consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00=Assignment(partitions=[replay-source-topic-1-0])}
2025-12-18T15:26:19.363Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00 for group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:19.363Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00', protocol='range'}
2025-12-18T15:26:19.364Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Notifying assignor about the new Assignment(partitions=[replay-source-topic-1-0])
2025-12-18T15:26:19.364Z  INFO 53856 --- [tainer#14-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Adding newly assigned partitions: replay-source-topic-1-0
2025-12-18T15:26:19.364Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Found no committed offset for partition replay-source-topic-1-0
2025-12-18T15:26:19.365Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Resetting offset for partition replay-source-topic-1-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:35181 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:19.365Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184: partitions assigned: [replay-source-topic-1-0]
2025-12-18T15:26:19.438Z  INFO 53856 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:35181]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-12-18T15:26:19.439Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:19.443Z  INFO 53856 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-12-18T15:26:19.449Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:19.449Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:19.449Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071579449
2025-12-18T15:26:19.452Z  INFO 53856 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: covn66rfTOiWa7-NlbzZgQ
2025-12-18T15:26:19.461Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=0, firstProducerId=0, size=1000) by writing to Zk with path version 1
2025-12-18T15:26:19.557Z  INFO 53856 --- [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
2025-12-18T15:26:19.594Z  INFO 53856 --- [tainer#12-0-C-1] n.d.Kafka.RetryScheduler.RetrySched      : scheduled retry for event: 123.45 to topic: double-topic
2025-12-18T15:26:19.795Z  INFO 53856 --- [try-scheduler-1] n.d.Kafka.RetryScheduler.RetrySched      : retried event: 123.45 to topic: double-topic
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Revoke previously assigned partitions circuit-breaker-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#21-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Revoke previously assigned partitions multi-partition-dlq-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#11-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Revoke previously assigned partitions dlq-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#8-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Revoke previously assigned partitions timeout-dlq-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#7-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Revoke previously assigned partitions validation-dlq-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#13-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-string-group-21, groupId=string-group] Revoke previously assigned partitions string-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#18-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Revoke previously assigned partitions replay-source-topic-5-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#16-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Revoke previously assigned partitions replay-source-topic-3-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#12-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-double-group-13, groupId=double-group] Revoke previously assigned partitions double-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Revoke previously assigned partitions batch-window-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#14-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Revoke previously assigned partitions replay-source-topic-1-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Revoke previously assigned partitions test-dlq-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#9-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Revoke previously assigned partitions default-dlq-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: partitions revoked: [multi-partition-dlq-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: partitions revoked: [timeout-dlq-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#20-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Revoke previously assigned partitions multi-partition-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#15-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Revoke previously assigned partitions replay-source-topic-2-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#17-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Revoke previously assigned partitions replay-source-topic-4-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: partitions revoked: [dlq-topic-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9: partitions revoked: [replay-source-topic-4-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: partitions revoked: [multi-partition-topic-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56: partitions revoked: [replay-source-topic-3-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Revoke previously assigned partitions batch-mixed-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#19-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Revoke previously assigned partitions replay-source-topic-6-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Revoke previously assigned partitions conditional-routing-test-0
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8: partitions revoked: [replay-source-topic-6-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: partitions revoked: [batch-mixed-topic-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: partitions revoked: [conditional-routing-test-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Member consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Member consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#10-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-17, groupId=test-group] Revoke previously assigned partitions test-topic-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Revoke previously assigned partitions circuit-breaker-dlq-0
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184: partitions revoked: [replay-source-topic-1-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: partitions revoked: [test-dlq-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: partitions revoked: [double-topic-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: partitions revoked: [circuit-breaker-dlq-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: partitions revoked: [circuit-breaker-topic-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Member consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: partitions revoked: [string-topic-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: partitions revoked: [validation-dlq-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc: partitions revoked: [replay-source-topic-5-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Member consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Member consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Revoke previously assigned partitions batch-capacity-topic-0
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Member consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: partitions revoked: [default-dlq-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Member consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.887Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a: partitions revoked: [replay-source-topic-2-0]
2025-12-18T15:26:19.887Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: partitions revoked: [batch-window-topic-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Member consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Member consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Member consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Member consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: [test-topic-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Member consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Member consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Member consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Member consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Member consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-17, groupId=test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Member consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Member consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Member consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Member consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: partitions revoked: [batch-capacity-topic-0]
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Member consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409 sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-double-group-13, groupId=double-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-string-group-21, groupId=string-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, groupId=replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-3, groupId=timeout-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-21, groupId=string-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.888Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Member consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc sending LeaveGroup request to coordinator localhost:35181 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-13, groupId=double-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-2, groupId=validation-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, groupId=replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.889Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, groupId=replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.889Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, groupId=replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, groupId=replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-18, groupId=multi-partition-dlq-collector] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-8, groupId=conditional-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-17, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-16, groupId=batch-mixed-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-1, groupId=test-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-6, groupId=circuit-breaker-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, groupId=replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-5, groupId=batch-window-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-14, groupId=batch-capacity-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-7, groupId=circuit-breaker-dlq-tracker] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-4, groupId=default-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-12, groupId=dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.890Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-15, groupId=multi-partition-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group default-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-mixed-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group timeout-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.891Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group timeout-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-mixed-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group default-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group multi-partition-test-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:19.892Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19-3a304af2-eb61-4c02-a20a-13d6e4cd2e39, groupInstanceId=None, clientId=consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22-a25a2cde-b5e0-47eb-b2fb-2cf2bd2cff00, groupInstanceId=None, clientId=consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-mixed-group-16-40e02fc7-fc82-41a7-9d5f-429809b1133a, groupInstanceId=None, clientId=consumer-batch-mixed-group-16, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-mixed-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10-833a186c-611a-44d8-806f-e633c9583b8b, groupInstanceId=None, clientId=consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11-1efa203f-93a0-4db0-b41a-ae737b287dfa, groupInstanceId=None, clientId=consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-timeout-dlq-group-3-c105bb5a-6e78-43b1-9578-a6fb3f9c1a30, groupInstanceId=None, clientId=consumer-timeout-dlq-group-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group timeout-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.893Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-multi-partition-test-group-15-6492a4bc-b8b1-4fd1-abc6-9bcb3a2294a0, groupInstanceId=None, clientId=consumer-multi-partition-test-group-15, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group multi-partition-test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-default-dlq-group-4-91122990-02aa-416b-8e4a-7faf96a3de65, groupInstanceId=None, clientId=consumer-default-dlq-group-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group default-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group test-group with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-dlq-collector in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Removing member consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group multi-partition-dlq-collector with generation 2 is now empty (__consumer_offsets-3)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group string-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group string-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:19.894Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group circuit-breaker-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-group-17-c536c75c-421a-4388-9162-430af3222bfd, groupInstanceId=None, clientId=consumer-test-group-17, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-string-group-21-0da10653-4593-4836-8885-68e7bec3972e, groupInstanceId=None, clientId=consumer-string-group-21, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group string-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-multi-partition-dlq-collector-18-6a089c3f-4f24-4e6c-8019-d0dc11852336, groupInstanceId=None, clientId=consumer-multi-partition-dlq-collector-18, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group multi-partition-dlq-collector through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-circuit-breaker-group-6-b5c1e962-11e1-46a9-86bd-1ddef541d6e3, groupInstanceId=None, clientId=consumer-circuit-breaker-group-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group circuit-breaker-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group conditional-test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group double-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group conditional-test-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group dlq-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group test-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group double-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-dlq-tracker in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-dlq-group-12-00a21fa9-ac1e-488e-a1d5-9b221684bc97, groupInstanceId=None, clientId=consumer-dlq-group-12, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.895Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group circuit-breaker-dlq-tracker with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-window-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group validation-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-window-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group validation-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-circuit-breaker-dlq-tracker-7-678cb8c3-2caa-41a7-bd39-c87cfc59c0c0, groupInstanceId=None, clientId=consumer-circuit-breaker-dlq-tracker-7, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group circuit-breaker-dlq-tracker through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-double-group-13-9ca2ae94-8df7-4a61-96ab-9a78e459d5b4, groupInstanceId=None, clientId=consumer-double-group-13, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group double-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9-0f67988e-17a0-4913-b57b-a24e546e7061, groupInstanceId=None, clientId=consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-window-group-5-af4849d6-db7b-4c03-8063-bc86d7f32409, groupInstanceId=None, clientId=consumer-batch-window-group-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-window-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-capacity-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-capacity-group with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:19.896Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-conditional-test-group-8-1d62ebd0-b4f3-4c4b-a315-0b7e5f36350a, groupInstanceId=None, clientId=consumer-conditional-test-group-8, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group conditional-test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.897Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-capacity-group-14-90b91764-9b98-4e93-be1c-848baf89c4cc, groupInstanceId=None, clientId=consumer-batch-capacity-group-14, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-capacity-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.897Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20-0d608a3d-5aea-48c8-8a8e-43543f3cadee, groupInstanceId=None, clientId=consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.897Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-dlq-group-1-89f47290-eb45-4b90-be02-c294a56be273, groupInstanceId=None, clientId=consumer-test-dlq-group-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:19.897Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-validation-dlq-group-2-a1f27bcb-50dd-4e04-9bb7-312a2aa78f14, groupInstanceId=None, clientId=consumer-validation-dlq-group-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group validation-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.176Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.176Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.176Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.176Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.176Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.178Z  INFO 53856 --- [tainer#13-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-string-group-21 unregistered
2025-12-18T15:26:20.178Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: Consumer stopped
2025-12-18T15:26:20.178Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-circuit-breaker-dlq-tracker-7 unregistered
2025-12-18T15:26:20.178Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: Consumer stopped
2025-12-18T15:26:20.178Z  INFO 53856 --- [tainer#11-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-dlq-group-12 unregistered
2025-12-18T15:26:20.178Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: Consumer stopped
2025-12-18T15:26:20.197Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.197Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.197Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.197Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.199Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-timeout-dlq-group-3 unregistered
2025-12-18T15:26:20.199Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: Consumer stopped
2025-12-18T15:26:20.221Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.221Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.221Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.221Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.222Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-default-dlq-group-4 unregistered
2025-12-18T15:26:20.222Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: Consumer stopped
2025-12-18T15:26:20.224Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.224Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.224Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.224Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.225Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-validation-dlq-group-2 unregistered
2025-12-18T15:26:20.225Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: Consumer stopped
2025-12-18T15:26:20.259Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.259Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.259Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.259Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.261Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-test-dlq-group-1 unregistered
2025-12-18T15:26:20.261Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: Consumer stopped
2025-12-18T15:26:20.272Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.272Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.272Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.272Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.273Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-conditional-test-group-8 unregistered
2025-12-18T15:26:20.273Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: Consumer stopped
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.278Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.278Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.278Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.278Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.278Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.280Z  INFO 53856 --- [tainer#17-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9-10 unregistered
2025-12-18T15:26:20.280Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-f8fc1f8f-1bf3-44b3-b666-737c56cc19b9: Consumer stopped
2025-12-18T15:26:20.280Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-circuit-breaker-group-6 unregistered
2025-12-18T15:26:20.280Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: Consumer stopped
2025-12-18T15:26:20.281Z  INFO 53856 --- [tainer#19-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8-9 unregistered
2025-12-18T15:26:20.281Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-44aad66a-d48b-494c-82f8-d17c3a8cc2c8: Consumer stopped
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.282Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.283Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-capacity-group-14 unregistered
2025-12-18T15:26:20.283Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: Consumer stopped
2025-12-18T15:26:20.283Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-window-group-5 unregistered
2025-12-18T15:26:20.283Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: Consumer stopped
2025-12-18T15:26:20.297Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.297Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.297Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.297Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.298Z  INFO 53856 --- [tainer#18-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc-11 unregistered
2025-12-18T15:26:20.298Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-b046032f-2b56-4d3d-8ba7-de4adba0c9bc: Consumer stopped
2025-12-18T15:26:20.300Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.300Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.300Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.300Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.301Z  INFO 53856 --- [tainer#12-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-double-group-13 unregistered
2025-12-18T15:26:20.301Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: Consumer stopped
2025-12-18T15:26:20.303Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.303Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.303Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.303Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.304Z  INFO 53856 --- [tainer#16-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56-20 unregistered
2025-12-18T15:26:20.304Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-5e04a136-4e13-41c9-884c-bef3b70d4f56: Consumer stopped
2025-12-18T15:26:20.323Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.323Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.323Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.323Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.324Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.324Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.324Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.324Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.324Z  INFO 53856 --- [tainer#15-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a-19 unregistered
2025-12-18T15:26:20.324Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-31cb931f-e242-4dae-bebc-c2b6dea1a66a: Consumer stopped
2025-12-18T15:26:20.325Z  INFO 53856 --- [tainer#20-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-multi-partition-test-group-15 unregistered
2025-12-18T15:26:20.325Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: Consumer stopped
2025-12-18T15:26:20.338Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.338Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.338Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.338Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.339Z  INFO 53856 --- [tainer#10-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-test-group-17 unregistered
2025-12-18T15:26:20.339Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: Consumer stopped
2025-12-18T15:26:20.341Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.341Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.341Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.341Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.343Z  INFO 53856 --- [tainer#21-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-multi-partition-dlq-collector-18 unregistered
2025-12-18T15:26:20.343Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: Consumer stopped
2025-12-18T15:26:20.343Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.343Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.343Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.343Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.344Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-mixed-group-16 unregistered
2025-12-18T15:26:20.345Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: Consumer stopped
2025-12-18T15:26:20.368Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.368Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.368Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.368Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.370Z  INFO 53856 --- [tainer#14-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184-22 unregistered
2025-12-18T15:26:20.370Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-800f5210-da1c-42e4-82e8-80cb6f54c184: Consumer stopped
2025-12-18T15:26:20.373Z  INFO 53856 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-12-18T15:26:20.374Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.374Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.374Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:20.374Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.374Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-1 unregistered
2025-12-18T15:26:20.378Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2025-12-18T15:26:20.378Z  INFO 53856 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2025-12-18T15:26:20.379Z  INFO 53856 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2025-12-18T15:26:20.379Z  INFO 53856 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2025-12-18T15:26:20.379Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-12-18T15:26:20.380Z  INFO 53856 --- [channel-manager] org.apache.kafka.clients.NetworkClient   : [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected.
2025-12-18T15:26:20.381Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-12-18T15:26:20.381Z  INFO 53856 --- [           main] kafka.server.KafkaRequestHandlerPool     : [data-plane Kafka Request Handler on Broker 0], shutting down
2025-12-18T15:26:20.382Z  INFO 53856 --- [           main] kafka.server.KafkaRequestHandlerPool     : [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-12-18T15:26:20.383Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Shutting down
2025-12-18T15:26:20.383Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-12-18T15:26:20.383Z  INFO 53856 --- [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Stopped
2025-12-18T15:26:20.383Z  INFO 53856 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2025-12-18T15:26:20.383Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2025-12-18T15:26:20.384Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2025-12-18T15:26:20.384Z  INFO 53856 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2025-12-18T15:26:20.384Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2025-12-18T15:26:20.384Z  INFO 53856 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2025-12-18T15:26:20.384Z  INFO 53856 --- [           main] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Shutting down
2025-12-18T15:26:20.384Z  INFO 53856 --- [           main] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Shutdown completed
2025-12-18T15:26:20.384Z  INFO 53856 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Stopped
2025-12-18T15:26:20.385Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2025-12-18T15:26:20.385Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2025-12-18T15:26:20.385Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2025-12-18T15:26:20.385Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-12-18T15:26:20.385Z  INFO 53856 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2025-12-18T15:26:20.386Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2025-12-18T15:26:20.386Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-12-18T15:26:20.386Z  INFO 53856 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2025-12-18T15:26:20.386Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2025-12-18T15:26:20.386Z  INFO 53856 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2025-12-18T15:26:20.386Z  INFO 53856 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2025-12-18T15:26:20.386Z  INFO 53856 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2025-12-18T15:26:20.386Z  INFO 53856 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] k.server.ReplicaAlterLogDirsManager      : [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] k.server.ReplicaAlterLogDirsManager      : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2025-12-18T15:26:20.387Z  INFO 53856 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Shutting down
2025-12-18T15:26:20.387Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Shutdown completed
2025-12-18T15:26:20.387Z  INFO 53856 --- [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Stopped
2025-12-18T15:26:20.388Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2025-12-18T15:26:20.388Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2025-12-18T15:26:20.388Z  INFO 53856 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2025-12-18T15:26:20.388Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-12-18T15:26:20.388Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-12-18T15:26:20.388Z  INFO 53856 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2025-12-18T15:26:20.388Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Shutting down
2025-12-18T15:26:20.388Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-12-18T15:26:20.388Z  INFO 53856 --- [r-0-ElectLeader] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Stopped
2025-12-18T15:26:20.396Z  INFO 53856 --- [           main] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Shutting down
2025-12-18T15:26:20.396Z  INFO 53856 --- [           main] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Shutdown completed
2025-12-18T15:26:20.396Z  INFO 53856 --- [nSenderThread-0] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Stopped
2025-12-18T15:26:20.396Z  INFO 53856 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2025-12-18T15:26:20.396Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down
2025-12-18T15:26:20.396Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed
2025-12-18T15:26:20.396Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped
2025-12-18T15:26:20.397Z  INFO 53856 --- [           main] k.s.NodeToControllerChannelManagerImpl   : Node to controller channel manager for alter-partition shutdown
2025-12-18T15:26:20.397Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down
2025-12-18T15:26:20.397Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed
2025-12-18T15:26:20.397Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped
2025-12-18T15:26:20.397Z  INFO 53856 --- [           main] k.s.NodeToControllerChannelManagerImpl   : Node to controller channel manager for forwarding shutdown
2025-12-18T15:26:20.397Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Shutting down.
2025-12-18T15:26:20.398Z  INFO 53856 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2025-12-18T15:26:20.398Z  INFO 53856 --- [           main] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Shutting down
2025-12-18T15:26:20.398Z  INFO 53856 --- [           main] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Shutdown completed
2025-12-18T15:26:20.398Z  INFO 53856 --- [leaner-thread-0] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Stopped
2025-12-18T15:26:20.414Z  INFO 53856 --- [569072488557280] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-0] Wrote producer snapshot at offset 10 with 0 producer ids in 2 ms.
2025-12-18T15:26:20.419Z  INFO 53856 --- [569072488557280] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=double-topic-0] Wrote producer snapshot at offset 2 with 1 producer ids in 2 ms.
2025-12-18T15:26:20.465Z  INFO 53856 --- [569072488557280] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-3] Wrote producer snapshot at offset 2 with 0 producer ids in 1 ms.
2025-12-18T15:26:20.489Z  INFO 53856 --- [569072488557280] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 8 with 0 producer ids in 1 ms.
2025-12-18T15:26:20.501Z  INFO 53856 --- [569072488557280] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-1] Wrote producer snapshot at offset 10 with 0 producer ids in 2 ms.
2025-12-18T15:26:20.509Z  INFO 53856 --- [569072488557280] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-4] Wrote producer snapshot at offset 16 with 0 producer ids in 3 ms.
2025-12-18T15:26:20.537Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2025-12-18T15:26:20.537Z  INFO 53856 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2025-12-18T15:26:20.537Z  INFO 53856 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2025-12-18T15:26:20.537Z  INFO 53856 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2025-12-18T15:26:20.538Z  INFO 53856 --- [           main] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-12-18T15:26:20.538Z  INFO 53856 --- [           main] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-12-18T15:26:20.538Z  INFO 53856 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2025-12-18T15:26:20.538Z  INFO 53856 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2025-12-18T15:26:20.538Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2025-12-18T15:26:20.539Z  INFO 53856 --- [           main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2025-12-18T15:26:20.539Z  INFO 53856 --- [           main] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Shutting down
2025-12-18T15:26:20.540Z  INFO 53856 --- [-process-thread] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Stopped
2025-12-18T15:26:20.540Z  INFO 53856 --- [           main] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Shutdown completed
2025-12-18T15:26:20.540Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Closing.
2025-12-18T15:26:20.643Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000070ce430000 closed
2025-12-18T15:26:20.643Z  INFO 53856 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000070ce430000
2025-12-18T15:26:20.643Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Closed.
2025-12-18T15:26:20.643Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2025-12-18T15:26:20.644Z  INFO 53856 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2025-12-18T15:26:20.644Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-12-18T15:26:20.644Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2025-12-18T15:26:20.644Z  INFO 53856 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2025-12-18T15:26:20.644Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2025-12-18T15:26:20.644Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2025-12-18T15:26:20.645Z  INFO 53856 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2025-12-18T15:26:20.645Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2025-12-18T15:26:20.645Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-12-18T15:26:20.645Z  INFO 53856 --- [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-12-18T15:26:20.645Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-12-18T15:26:20.645Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-12-18T15:26:20.653Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-12-18T15:26:20.653Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.653Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.653Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.653Z  INFO 53856 --- [           main] kafka.server.BrokerTopicStats            : Broker and topic stats closed
2025-12-18T15:26:20.653Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.server for 0 unregistered
2025-12-18T15:26:20.654Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2025-12-18T15:26:20.656Z  INFO 53856 --- [nnectionExpirer] o.a.z.server.NIOServerCnxnFactory        : ConnnectionExpirerThread interrupted
2025-12-18T15:26:20.657Z  INFO 53856 --- [electorThread-0] o.a.z.server.NIOServerCnxnFactory        : selector thread exitted run method
2025-12-18T15:26:20.657Z  INFO 53856 --- [ad:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : accept thread exitted run method
2025-12-18T15:26:20.657Z  INFO 53856 --- [electorThread-1] o.a.z.server.NIOServerCnxnFactory        : selector thread exitted run method
2025-12-18T15:26:20.657Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2025-12-18T15:26:20.657Z  INFO 53856 --- [           main] o.a.zookeeper.server.RequestThrottler    : Shutting down
2025-12-18T15:26:20.657Z  INFO 53856 --- [equestThrottler] o.a.zookeeper.server.RequestThrottler    : Draining request throttler queue
2025-12-18T15:26:20.657Z  INFO 53856 --- [equestThrottler] o.a.zookeeper.server.RequestThrottler    : RequestThrottler shutdown. Dropped 0 requests
2025-12-18T15:26:20.657Z  INFO 53856 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2025-12-18T15:26:20.657Z  INFO 53856 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2025-12-18T15:26:20.657Z  INFO 53856 --- [0 cport:42119):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2025-12-18T15:26:20.657Z  INFO 53856 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2025-12-18T15:26:20.657Z  INFO 53856 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2025-12-18T15:26:20.657Z  INFO 53856 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.7)

2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : zookeeper.snapshot.trust.empty : false
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.watch.WatchManagerFactory   : Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.watch.WatchManagerFactory   : Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : zookeeper.snapshotSizeFactor = 0.33
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : zookeeper.commitLogCount=500
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to 1600 ms
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to 16000 ms
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.apache.zookeeper.server.ResponseCache  : getData response cache size is initialized with value 400.
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.apache.zookeeper.server.ResponseCache  : getChildren response cache size is initialized with value 400.
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.slotCapacity = 60
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.slotDuration = 15
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.maxDepth = 6
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.initialDelay = 5
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.delay = 5
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.enabled = false
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : The max bytes for all large requests are set to 104857600
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : The large request threshold is set to -1
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.AuthenticationHelper        : zookeeper.enforce.auth.enabled = false
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.AuthenticationHelper        : zookeeper.enforce.auth.schemes = []
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Created server with tickTime 800 ms minSessionTimeout 1600 ms maxSessionTimeout 16000 ms clientPortListenBacklog -1 datadir /tmp/kafka-2425779028733862303/version-2 snapdir /tmp/kafka-13244144895645543459/version-2
2025-12-18T15:26:20.678Z  WARN 53856 --- [           main] o.a.zookeeper.server.ServerCnxnFactory   : maxCnxns is not configured, using default value 0.
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.NIOServerCnxnFactory        : Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-12-18T15:26:20.678Z  INFO 53856 --- [           main] o.a.z.server.NIOServerCnxnFactory        : binding to port /127.0.0.1:0
2025-12-18T15:26:20.679Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : Snapshotting: 0x0 to /tmp/kafka-13244144895645543459/version-2/snapshot.0
2025-12-18T15:26:20.679Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2025-12-18T15:26:20.679Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : Snapshotting: 0x0 to /tmp/kafka-13244144895645543459/version-2/snapshot.0
2025-12-18T15:26:20.679Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Snapshot taken in 0 ms
2025-12-18T15:26:20.680Z  INFO 53856 --- [0 cport:40937):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-12-18T15:26:20.681Z  INFO 53856 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 100
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:40937
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : starting
2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:40937
2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:40937.
2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:40937 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2e903c69
2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] org.apache.zookeeper.ClientCnxnSocket    : jute.maxbuffer value is 4194304 Bytes
2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] org.apache.zookeeper.ClientCnxn          : zookeeper.request.timeout value is 0. feature enabled=false
2025-12-18T15:26:20.682Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Waiting until connected.
2025-12-18T15:26:20.682Z  INFO 53856 --- [27.0.0.1:40937)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server /127.0.0.1:40937.
2025-12-18T15:26:20.682Z  INFO 53856 --- [27.0.0.1:40937)] org.apache.zookeeper.ClientCnxn          : Socket connection established, initiating session, client: /127.0.0.1:37476, server: /127.0.0.1:40937
2025-12-18T15:26:20.683Z  INFO 53856 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2025-12-18T15:26:20.684Z  INFO 53856 --- [27.0.0.1:40937)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server /127.0.0.1:40937, session id = 0x1000070def00000, negotiated timeout = 16000
2025-12-18T15:26:20.684Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Connected.
2025-12-18T15:26:20.697Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : Cluster ID = _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:20.702Z  INFO 53856 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 100
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:40937
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-12-18T15:26:20.707Z  INFO 53856 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Starting
2025-12-18T15:26:20.707Z  INFO 53856 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Starting
2025-12-18T15:26:20.707Z  INFO 53856 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Starting
2025-12-18T15:26:20.707Z  INFO 53856 --- [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Starting
2025-12-18T15:26:20.707Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Rewriting /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/meta.properties
2025-12-18T15:26:20.712Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Loading logs from log dirs ArrayBuffer(/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277)
2025-12-18T15:26:20.713Z  INFO 53856 --- [           main] kafka.log.LogManager                     : No logs found to be loaded in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277
2025-12-18T15:26:20.713Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Loaded 0 logs in 0ms
2025-12-18T15:26:20.713Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2025-12-18T15:26:20.713Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2025-12-18T15:26:20.714Z  INFO 53856 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2025-12-18T15:26:20.714Z  INFO 53856 --- [leaner-thread-0] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Starting
2025-12-18T15:26:20.714Z  INFO 53856 --- [-process-thread] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Starting
2025-12-18T15:26:20.715Z  INFO 53856 --- [-process-thread] k.server.FinalizedFeatureChangeListener  : Feature ZK node at path: /feature does not exist
2025-12-18T15:26:20.716Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Starting
2025-12-18T15:26:20.720Z  INFO 53856 --- [           main] kafka.network.ConnectionQuotas           : Updated connection-accept-rate max connection creation rate to 2147483647
2025-12-18T15:26:20.720Z  INFO 53856 --- [           main] kafka.network.DataPlaneAcceptor          : Awaiting socket connections on localhost:46201.
2025-12-18T15:26:20.720Z  INFO 53856 --- [           main] kafka.network.DataPlaneAcceptor          : Opened wildcard endpoint localhost:46201
2025-12-18T15:26:20.721Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-12-18T15:26:20.721Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting
2025-12-18T15:26:20.722Z  INFO 53856 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Starting
2025-12-18T15:26:20.722Z  INFO 53856 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Starting
2025-12-18T15:26:20.722Z  INFO 53856 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Starting
2025-12-18T15:26:20.722Z  INFO 53856 --- [r-0-ElectLeader] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Starting
2025-12-18T15:26:20.722Z  INFO 53856 --- [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Starting
2025-12-18T15:26:20.723Z  INFO 53856 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2025-12-18T15:26:20.723Z  INFO 53856 --- [nSenderThread-0] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Starting
2025-12-18T15:26:20.723Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/0 (is it secure? false)
2025-12-18T15:26:20.724Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Stat of the created znode at /brokers/ids/0 is: 25,25,1766071580724,1766071580724,1,0,0,72058078814535680,204,0,25

2025-12-18T15:26:20.724Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:46201, czxid (broker epoch): 25
2025-12-18T15:26:20.725Z  INFO 53856 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Starting
2025-12-18T15:26:20.725Z  INFO 53856 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Starting
2025-12-18T15:26:20.725Z  INFO 53856 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Starting
2025-12-18T15:26:20.725Z  INFO 53856 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Starting
2025-12-18T15:26:20.725Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Starting up.
2025-12-18T15:26:20.726Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Startup complete.
2025-12-18T15:26:20.726Z  INFO 53856 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Successfully created /controller_epoch with initial epoch 0
2025-12-18T15:26:20.726Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Starting up.
2025-12-18T15:26:20.727Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-12-18T15:26:20.727Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Startup complete.
2025-12-18T15:26:20.727Z  INFO 53856 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Starting
2025-12-18T15:26:20.727Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-12-18T15:26:20.727Z  INFO 53856 --- [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Starting
2025-12-18T15:26:20.728Z  INFO 53856 --- [ain-EventThread] k.server.FinalizedFeatureChangeListener  : Feature ZK node created at path: /feature
2025-12-18T15:26:20.728Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Registering handlers
2025-12-18T15:26:20.728Z  INFO 53856 --- [-process-thread] kafka.server.metadata.ZkMetadataCache    : [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0).
2025-12-18T15:26:20.729Z  INFO 53856 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2025-12-18T15:26:20.729Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Deleting log dir event notifications
2025-12-18T15:26:20.729Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Deleting isr change notifications
2025-12-18T15:26:20.730Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initializing controller context
2025-12-18T15:26:20.730Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-12-18T15:26:20.731Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Start processing authorizer futures
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] End processing authorizer futures
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Start processing enable request processing future
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] End processing enable request processing future
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071580731
2025-12-18T15:26:20.731Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] started
2025-12-18T15:26:20.732Z  INFO 53856 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [127.0.0.1:46201]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-12-18T15:26:20.732Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:20.732Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:20.732Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071580732
2025-12-18T15:26:20.733Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Starting
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Current list of topics in the cluster: HashSet()
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Fetching topic deletions in progress
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] List of topics to be deleted: 
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] List of topics ineligible for deletion: 
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initializing topic deletion manager
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.TopicDeletionManager    : [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Sending update metadata request
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-12-18T15:26:20.733Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Initializing replica state
2025-12-18T15:26:20.734Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-12-18T15:26:20.734Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-12-18T15:26:20.734Z  INFO 53856 --- [er-event-thread] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Initializing partition state
2025-12-18T15:26:20.734Z  INFO 53856 --- [er-event-thread] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-12-18T15:26:20.734Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Ready to serve as the new controller with epoch 1
2025-12-18T15:26:20.734Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Controller 0 connected to localhost:46201 (id: 0 rack: null) for sending state change requests
2025-12-18T15:26:20.735Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Partitions undergoing preferred replica election: 
2025-12-18T15:26:20.735Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Partitions that completed preferred replica election: 
2025-12-18T15:26:20.735Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-12-18T15:26:20.735Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Resuming preferred replica election for partitions: 
2025-12-18T15:26:20.735Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-12-18T15:26:20.735Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Starting the controller scheduler
2025-12-18T15:26:20.738Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic dlq-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:20.742Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(dlq-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(dlq-topic,Some(SaYd6TaKQ7m2RyzY2uKl_g),Map(dlq-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:20.742Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for dlq-topic-0
2025-12-18T15:26:20.742Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition dlq-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:20.742Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.742Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.744Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic object-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:20.744Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition dlq-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:20.744Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:20.744Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:20.745Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.745Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2025-12-18T15:26:20.745Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(dlq-topic-0)
2025-12-18T15:26:20.745Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:20.747Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=dlq-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:20.747Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(object-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(object-topic,Some(lO1xIdNjSh6GZz4z9Qu3zg),Map(object-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:20.747Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for object-topic-0
2025-12-18T15:26:20.747Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition object-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:20.747Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition dlq-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/dlq-topic-0 with properties {}
2025-12-18T15:26:20.748Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.748Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition dlq-topic-0 broker=0] No checkpointed highwatermark is found for partition dlq-topic-0
2025-12-18T15:26:20.748Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition dlq-topic-0 broker=0] Log loaded for partition dlq-topic-0 with initial high watermark 0
2025-12-18T15:26:20.748Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.748Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader dlq-topic-0 with topic id Some(SaYd6TaKQ7m2RyzY2uKl_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:20.748Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic double-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:20.750Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition object-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:20.750Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:20.750Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:20.750Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.752Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(double-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(double-topic,Some(UrgXNBqpQsaTWplOR-5Dsg),Map(double-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:20.752Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for double-topic-0
2025-12-18T15:26:20.752Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition double-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:20.752Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.752Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.753Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 8ms correlationId 1 from controller 0 for 1 partitions
2025-12-18T15:26:20.754Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic string-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:20.754Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-12-18T15:26:20.754Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition double-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:20.754Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 1 partitions
2025-12-18T15:26:20.755Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:20.755Z  INFO 53856 --- [quest-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(object-topic-0)
2025-12-18T15:26:20.755Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:20.755Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:20.755Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.757Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=object-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:20.757Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(string-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(string-topic,Some(gQ0bBD3GRrGB9kU9vWgfNA),Map(string-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:20.757Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for string-topic-0
2025-12-18T15:26:20.757Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition string-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:20.757Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.757Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.757Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition object-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/object-topic-0 with properties {}
2025-12-18T15:26:20.757Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition object-topic-0 broker=0] No checkpointed highwatermark is found for partition object-topic-0
2025-12-18T15:26:20.757Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition object-topic-0 broker=0] Log loaded for partition object-topic-0 with initial high watermark 0
2025-12-18T15:26:20.757Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader object-topic-0 with topic id Some(lO1xIdNjSh6GZz4z9Qu3zg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:20.760Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition string-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:20.760Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:20.760Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:20.760Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:20.762Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 8ms correlationId 3 from controller 0 for 1 partitions
2025-12-18T15:26:20.763Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-12-18T15:26:20.764Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 5 from controller 0 for 1 partitions
2025-12-18T15:26:20.764Z  INFO 53856 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(double-topic-0)
2025-12-18T15:26:20.764Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:20.766Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=double-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:20.767Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition double-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/double-topic-0 with properties {}
2025-12-18T15:26:20.767Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition double-topic-0 broker=0] No checkpointed highwatermark is found for partition double-topic-0
2025-12-18T15:26:20.767Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition double-topic-0 broker=0] Log loaded for partition double-topic-0 with initial high watermark 0
2025-12-18T15:26:20.767Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader double-topic-0 with topic id Some(UrgXNBqpQsaTWplOR-5Dsg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:20.772Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 5 from controller 0 for 1 partitions
2025-12-18T15:26:20.773Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 6
2025-12-18T15:26:20.773Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 7 from controller 0 for 1 partitions
2025-12-18T15:26:20.773Z  INFO 53856 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(string-topic-0)
2025-12-18T15:26:20.773Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 7 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:20.775Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=string-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:20.775Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition string-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/string-topic-0 with properties {}
2025-12-18T15:26:20.775Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition string-topic-0 broker=0] No checkpointed highwatermark is found for partition string-topic-0
2025-12-18T15:26:20.775Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition string-topic-0 broker=0] Log loaded for partition string-topic-0 with initial high watermark 0
2025-12-18T15:26:20.775Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader string-topic-0 with topic id Some(gQ0bBD3GRrGB9kU9vWgfNA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:20.780Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 7 from controller 0 for 1 partitions
2025-12-18T15:26:20.781Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 8
2025-12-18T15:26:20.782Z  INFO 53856 --- [| adminclient-2] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-2 unregistered
2025-12-18T15:26:20.783Z  INFO 53856 --- [| adminclient-2] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:20.783Z  INFO 53856 --- [| adminclient-2] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:20.783Z  INFO 53856 --- [| adminclient-2] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:20.784Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : Starting TypeHandlingIntegrationTest using Java 25.0.1 with PID 53856 (started by sam-o-reilly in /home/sam-o-reilly/Downloads/java-damero)
2025-12-18T15:26:20.784Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : No active profile set, falling back to 1 default profile: "default"
2025-12-18T15:26:20.816Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:46201 (id: 0 rack: null)
2025-12-18T15:26:20.822Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:46201 (id: 0 rack: null)
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'testEventProducerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'testEventProducerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'dlqKafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=dlqKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=dlqKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'consumerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=consumerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=consumerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:20.868Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:20.871Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:20.871Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:20.871Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:20.871Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:20.883Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
2025-12-18T15:26:20.883Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-12-18T15:26:20.885Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 1 ms. Found 0 Redis repository interfaces.
2025-12-18T15:26:20.930Z  WARN 53856 --- [           main] n.d.K.C.CustomKafkaAutoConfiguration     : ==> Redis not available - PluggableRedisCache using Caffeine in-memory cache. This is NOT recommended for multi-instance deployments. Add spring-boot-starter-data-redis dependency and configure Redis for production use.
2025-12-18T15:26:20.930Z  INFO 53856 --- [           main] n.d.Kafka.Config.PluggableRedisCache     : === PluggableRedisCache initialized with Caffeine backend ===
2025-12-18T15:26:20.930Z  INFO 53856 --- [           main] n.d.K.A.D.DuplicationManager             : Initializing DuplicationManager with 10 HOURS window (TTL: PT10H)
2025-12-18T15:26:20.930Z  INFO 53856 --- [           main] n.d.K.A.D.DuplicationManager             : DuplicationManager initialized. Max capacity: 50000000 entries
2025-12-18T15:26:20.931Z  INFO 53856 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : Inconsistent constructor declaration on bean with name 'circuitBreakerService': single autowire-marked constructor flagged as optional - this constructor is effectively required since there is no default constructor to fall back to: public net.damero.Kafka.Resilience.CircuitBreakerService(java.lang.Object)
2025-12-18T15:26:20.933Z  INFO 53856 --- [           main] n.d.K.T.OpenTelemetryTracingService      : OpenTelemetryTracingService initialized - distributed tracing enabled
2025-12-18T15:26:20.957Z  INFO 53856 --- [           main] org.reflections.Reflections              : Reflections took 13 ms to scan 2 urls, producing 20 keys and 496 values
2025-12-18T15:26:21.088Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-dlq-group-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.088Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.091Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.091Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.091Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581091
2025-12-18T15:26:21.091Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Subscribed to topic(s): test-dlq
2025-12-18T15:26:21.092Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-validation-dlq-group-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = validation-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.093Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.094Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.095Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.095Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581094
2025-12-18T15:26:21.095Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Subscribed to topic(s): validation-dlq
2025-12-18T15:26:21.095Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic test-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.096Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-timeout-dlq-group-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = timeout-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.096Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.097Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic validation-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.098Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.098Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.098Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581098
2025-12-18T15:26:21.098Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Subscribed to topic(s): timeout-dlq
2025-12-18T15:26:21.099Z  WARN 53856 --- [ntainer#6-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.099Z  INFO 53856 --- [ntainer#6-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.099Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-default-dlq-group-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = default-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.100Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.100Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(test-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(test-dlq,Some(8NlECgI0RpyfhjWM6wgZFg),Map(test-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.100Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for test-dlq-0
2025-12-18T15:26:21.100Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.100Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.100Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.101Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.101Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.101Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581101
2025-12-18T15:26:21.101Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Subscribed to topic(s): default-dlq
2025-12-18T15:26:21.101Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-12-18T15:26:21.102Z  WARN 53856 --- [ntainer#7-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {validation-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.102Z  INFO 53856 --- [ntainer#7-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.102Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-window-group-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-window-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.102Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.102Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic timeout-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.103Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.103Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.103Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581103
2025-12-18T15:26:21.103Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Subscribed to topic(s): batch-window-topic
2025-12-18T15:26:21.104Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.104Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.104Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:21.104Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.104Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic default-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.104Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 9 from controller 0 for 1 partitions
2025-12-18T15:26:21.104Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-circuit-breaker-group-28
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = circuit-breaker-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.104Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(test-dlq-0)
2025-12-18T15:26:21.105Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 9 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:21.105Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.105Z  WARN 53856 --- [ntainer#8-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {timeout-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.105Z  INFO 53856 --- [ntainer#8-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.106Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.106Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.106Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581106
2025-12-18T15:26:21.106Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Subscribed to topic(s): circuit-breaker-topic
2025-12-18T15:26:21.106Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(validation-dlq, __consumer_offsets, timeout-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(validation-dlq,Some(_B46816WQl23_cN73M_Yig),Map(validation-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(__consumer_offsets,Some(A4aOYDKkSU2AdAsSLfwJuw),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(timeout-dlq,Some(I5OPAiTGQMWfVQSUQCL8RA),Map(timeout-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-3,__consumer_offsets-2,timeout-dlq-0,__consumer_offsets-0,__consumer_offsets-1,validation-dlq-0,__consumer_offsets-4
2025-12-18T15:26:21.107Z  INFO 53856 --- [quest-handler-5] kafka.zk.AdminZkClient                   : Creating topic batch-window-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition timeout-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition validation-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.107Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.107Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=test-dlq-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.107Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-circuit-breaker-dlq-tracker-29
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = circuit-breaker-dlq-tracker
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.107Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.107Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition test-dlq-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/test-dlq-0 with properties {}
2025-12-18T15:26:21.108Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition test-dlq-0 broker=0] No checkpointed highwatermark is found for partition test-dlq-0
2025-12-18T15:26:21.108Z  WARN 53856 --- [ntainer#9-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {default-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.108Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition test-dlq-0 broker=0] Log loaded for partition test-dlq-0 with initial high watermark 0
2025-12-18T15:26:21.108Z  INFO 53856 --- [ntainer#9-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.108Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader test-dlq-0 with topic id Some(8NlECgI0RpyfhjWM6wgZFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.109Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.109Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.109Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581109
2025-12-18T15:26:21.109Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Subscribed to topic(s): circuit-breaker-dlq
2025-12-18T15:26:21.110Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-conditional-test-group-30
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = conditional-test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.110Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.111Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.111Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.111Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581111
2025-12-18T15:26:21.111Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Subscribed to topic(s): conditional-routing-test
2025-12-18T15:26:21.112Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic circuit-breaker-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.113Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.113Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.113Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic circuit-breaker-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.114Z  WARN 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-window-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.114Z  INFO 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.114Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.114Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.114Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581114
2025-12-18T15:26:21.114Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Subscribed to topic(s): replay-source-topic-6
2025-12-18T15:26:21.114Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 10ms correlationId 9 from controller 0 for 1 partitions
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition timeout-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition validation-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.114Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 7 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.115Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 7 partitions
2025-12-18T15:26:21.115Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.115Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 10
2025-12-18T15:26:21.115Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.115Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.116Z  INFO 53856 --- [quest-handler-2] kafka.zk.AdminZkClient                   : Creating topic conditional-routing-test with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.116Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 11 from controller 0 for 7 partitions
2025-12-18T15:26:21.117Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.117Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.117Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581117
2025-12-18T15:26:21.117Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Subscribed to topic(s): replay-source-topic-4
2025-12-18T15:26:21.117Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-3, __consumer_offsets-2, timeout-dlq-0, __consumer_offsets-0, __consumer_offsets-1, validation-dlq-0, __consumer_offsets-4)
2025-12-18T15:26:21.117Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 11 from controller 0 epoch 1 as part of the become-leader transition for 7 partitions
2025-12-18T15:26:21.117Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(batch-window-topic, default-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(default-dlq,Some(QIHIclOoRV6BYw1IRuLgcA),Map(default-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(batch-window-topic,Some(h1cVgXlRRVq_f-IfQgmJ0w),Map(batch-window-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.117Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for default-dlq-0,batch-window-topic-0
2025-12-18T15:26:21.117Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition default-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.117Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-window-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.117Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.117Z  WARN 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {circuit-breaker-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.117Z  WARN 53856 --- [ntainer#4-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {circuit-breaker-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.117Z  INFO 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.117Z  INFO 53856 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.118Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.118Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.119Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.120Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-6 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.120Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-3, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.120Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:21.120Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-12-18T15:26:21.120Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-12-18T15:26:21.120Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-3 with topic id Some(A4aOYDKkSU2AdAsSLfwJuw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.121Z  WARN 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {conditional-routing-test=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.121Z  INFO 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.121Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.121Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.121Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581121
2025-12-18T15:26:21.121Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Subscribed to topic(s): replay-source-topic-5
2025-12-18T15:26:21.122Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition default-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.122Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-window-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.122Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.122Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-4 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.122Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:21.122Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.123Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlq-group-34
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.123Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.125Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.125Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.125Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581125
2025-12-18T15:26:21.125Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Subscribed to topic(s): dlq-topic
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(conditional-routing-test, circuit-breaker-topic, circuit-breaker-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(conditional-routing-test,Some(qDB6wY4nR8Sc4LV18xk7NQ),Map(conditional-routing-test-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(circuit-breaker-topic,Some(lj2cfMOGSL2wK_gnZOgXGw),Map(circuit-breaker-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(circuit-breaker-dlq,Some(7hK681gXSl-m_Wna2ZuFjA),Map(circuit-breaker-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for conditional-routing-test-0,circuit-breaker-topic-0,circuit-breaker-dlq-0
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition conditional-routing-test-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.126Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.126Z  WARN 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-6=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.126Z  INFO 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.127Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-5 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.127Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-double-group-35
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = double-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.127Z  WARN 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-4=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.127Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.127Z  INFO 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.127Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=timeout-dlq-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.128Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition timeout-dlq-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/timeout-dlq-0 with properties {}
2025-12-18T15:26:21.128Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition timeout-dlq-0 broker=0] No checkpointed highwatermark is found for partition timeout-dlq-0
2025-12-18T15:26:21.128Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition timeout-dlq-0 broker=0] Log loaded for partition timeout-dlq-0 with initial high watermark 0
2025-12-18T15:26:21.128Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader timeout-dlq-0 with topic id Some(I5OPAiTGQMWfVQSUQCL8RA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.128Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.128Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.128Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581128
2025-12-18T15:26:21.128Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-double-group-35, groupId=double-group] Subscribed to topic(s): double-topic
2025-12-18T15:26:21.129Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-capacity-group-36
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-capacity-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.130Z  INFO 53856 --- [tainer#11-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.130Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.134Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.134Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.134Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581134
2025-12-18T15:26:21.134Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition conditional-routing-test-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.134Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.134Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.134Z  WARN 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-5=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.134Z  INFO 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.134Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Subscribed to topic(s): batch-capacity-topic
2025-12-18T15:26:21.134Z  INFO 53856 --- [tainer#12-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-double-group-35, groupId=double-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.134Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 3 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.134Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 3 partitions
2025-12-18T15:26:21.134Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.135Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-multi-partition-test-group-37
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = multi-partition-test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.136Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.136Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-4, replay-source-topic-5, replay-source-topic-6)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-5,Some(fL7glRmmQRGgkGnJGSJUbw),Map(replay-source-topic-5-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-4,Some(HibNeh_4Quah7O_v8kpOSA),Map(replay-source-topic-4-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-6,Some(umzeyrT4QZ2bOF9SGCxPHw),Map(replay-source-topic-6-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.137Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-5-0,replay-source-topic-4-0,replay-source-topic-6-0
2025-12-18T15:26:21.137Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.137Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.137Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581137
2025-12-18T15:26:21.137Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-2, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.137Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Subscribed to topic(s): multi-partition-topic
2025-12-18T15:26:21.137Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-5-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.137Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-4-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.137Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-6-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.137Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.137Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.137Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:21.137Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-12-18T15:26:21.137Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-12-18T15:26:21.137Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-2 with topic id Some(A4aOYDKkSU2AdAsSLfwJuw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.138Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-mixed-group-38
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-mixed-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.138Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.139Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic batch-capacity-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.140Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic multi-partition-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.140Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.140Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.140Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581140
2025-12-18T15:26:21.141Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Subscribed to topic(s): batch-mixed-topic
2025-12-18T15:26:21.141Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-5-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.141Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-4-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.141Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-6-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.141Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 3 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.142Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 3 partitions
2025-12-18T15:26:21.142Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.142Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-39
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.142Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.143Z  WARN 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-capacity-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.143Z  INFO 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.143Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.143Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.143Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581143
2025-12-18T15:26:21.143Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-39, groupId=test-group] Subscribed to topic(s): test-topic
2025-12-18T15:26:21.144Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-4, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.144Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic batch-mixed-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.145Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(batch-capacity-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(batch-capacity-topic,Some(mSCulrYaSCqRJopEWrLtmQ),Map(batch-capacity-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.145Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for batch-capacity-topic-0
2025-12-18T15:26:21.145Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-capacity-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.145Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.145Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:21.145Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-12-18T15:26:21.145Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-12-18T15:26:21.145Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.145Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-4 with topic id Some(A4aOYDKkSU2AdAsSLfwJuw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.145Z  WARN 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {multi-partition-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.145Z  INFO 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.148Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic test-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.148Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-capacity-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.148Z  WARN 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-mixed-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.148Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.148Z  INFO 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.149Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:21.149Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.151Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(batch-mixed-topic, multi-partition-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(batch-mixed-topic,Some(dejevcBWRFSRlrIRhnDq_w),Map(batch-mixed-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(multi-partition-topic,Some(DkEwcK0EQWG9bsw2bFtQ9A),Map(multi-partition-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.151Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for batch-mixed-topic-0,multi-partition-topic-0
2025-12-18T15:26:21.152Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-mixed-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.152Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.152Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.152Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=validation-dlq-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.152Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.152Z  WARN 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-39, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.152Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition validation-dlq-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/validation-dlq-0 with properties {}
2025-12-18T15:26:21.152Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition validation-dlq-0 broker=0] No checkpointed highwatermark is found for partition validation-dlq-0
2025-12-18T15:26:21.152Z  INFO 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-39, groupId=test-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.152Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition validation-dlq-0 broker=0] Log loaded for partition validation-dlq-0 with initial high watermark 0
2025-12-18T15:26:21.152Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader validation-dlq-0 with topic id Some(_B46816WQl23_cN73M_Yig) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.155Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-mixed-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.155Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.155Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.155Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:21.155Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.156Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-multi-partition-dlq-collector-40
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = multi-partition-dlq-collector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.156Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.157Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(test-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(test-topic,Some(5Xmcy2gSQMikdpxUR_A2FQ),Map(test-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.157Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for test-topic-0
2025-12-18T15:26:21.157Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.157Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.157Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.158Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.158Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.158Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581158
2025-12-18T15:26:21.158Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Subscribed to topic(s): multi-partition-dlq
2025-12-18T15:26:21.158Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-1, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.159Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:21.159Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-12-18T15:26:21.159Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-12-18T15:26:21.159Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-1 with topic id Some(A4aOYDKkSU2AdAsSLfwJuw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.160Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.160Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.160Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.160Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:21.160Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.160Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.161Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.161Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.161Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581161
2025-12-18T15:26:21.161Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Subscribed to topic(s): replay-source-topic-2
2025-12-18T15:26:21.162Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic multi-partition-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.163Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.163Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.164Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.164Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.164Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581164
2025-12-18T15:26:21.164Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Subscribed to topic(s): replay-source-topic-3
2025-12-18T15:26:21.164Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-2 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.165Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.165Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-string-group-43
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = string-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.165Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:21.165Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.165Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-12-18T15:26:21.166Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-12-18T15:26:21.166Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-0 with topic id Some(A4aOYDKkSU2AdAsSLfwJuw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.166Z  WARN 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {multi-partition-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.166Z  INFO 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.167Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.167Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.167Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581167
2025-12-18T15:26:21.167Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(multi-partition-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(multi-partition-dlq,Some(kCpLsZPcTBSS2axl2oKXYQ),Map(multi-partition-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.167Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for multi-partition-dlq-0
2025-12-18T15:26:21.167Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-string-group-43, groupId=string-group] Subscribed to topic(s): string-topic
2025-12-18T15:26:21.167Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.167Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.167Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.167Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-3 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.168Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46201]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:21.168Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.168Z  WARN 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-2=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.168Z  INFO 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.169Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.169Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.169Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581169
2025-12-18T15:26:21.170Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Subscribed to topic(s): replay-source-topic-1
2025-12-18T15:26:21.170Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.170Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [tainer#13-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-string-group-43, groupId=string-group] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.170Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:21.170Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-12-18T15:26:21.170Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.170Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:21.170Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 54ms correlationId 11 from controller 0 for 7 partitions
2025-12-18T15:26:21.170Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:21.171Z  WARN 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-3=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.171Z  INFO 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.171Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2025-12-18T15:26:21.171Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2025-12-18T15:26:21.172Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 7 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 12
2025-12-18T15:26:21.172Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : Started TypeHandlingIntegrationTest in 0.506 seconds (process running for 5.648)
2025-12-18T15:26:21.172Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 13 from controller 0 for 2 partitions
2025-12-18T15:26:21.172Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-3, replay-source-topic-2)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-3,Some(1mSEChBJSruNxrEhciHPeA),Map(replay-source-topic-3-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-2,Some(hJaU7gvERum1dT-KZ0d01A),Map(replay-source-topic-2-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.172Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-3-0,replay-source-topic-2-0
2025-12-18T15:26:21.172Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-3-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.173Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-2-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.173Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.173Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.173Z  INFO 53856 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(batch-window-topic-0, default-dlq-0)
2025-12-18T15:26:21.173Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 13 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:21.173Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-1 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:21.175Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-window-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.176Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition batch-window-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/batch-window-topic-0 with properties {}
2025-12-18T15:26:21.176Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition batch-window-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-window-topic-0
2025-12-18T15:26:21.176Z  INFO 53856 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2025-12-18T15:26:21.176Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition batch-window-topic-0 broker=0] Log loaded for partition batch-window-topic-0 with initial high watermark 0
2025-12-18T15:26:21.176Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader batch-window-topic-0 with topic id Some(h1cVgXlRRVq_f-IfQgmJ0w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.177Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-3-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.177Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-2-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.177Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.177Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:21.178Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.178Z  WARN 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-1=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.178Z  INFO 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.178Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.179Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] (Re-)joining group
2025-12-18T15:26:21.179Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-1)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-1,Some(y_hczy4FQsuz9g2sxEzjVg),Map(replay-source-topic-1-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:21.179Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-1-0
2025-12-18T15:26:21.179Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-1-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:21.179Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.180Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.180Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac in Empty state. Created a new member id consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475 and request the member to rejoin with this id.
2025-12-18T15:26:21.180Z  INFO 53856 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:46201]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-12-18T15:26:21.181Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475
2025-12-18T15:26:21.181Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] (Re-)joining group
2025-12-18T15:26:21.181Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:21.181Z  INFO 53856 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-2] Instantiated an idempotent producer.
2025-12-18T15:26:21.181Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475)
2025-12-18T15:26:21.182Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-1-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:21.182Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:21.182Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:21.182Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:21.182Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=default-dlq-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.182Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:21.182Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475', protocol='range'}
2025-12-18T15:26:21.182Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition default-dlq-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/default-dlq-0 with properties {}
2025-12-18T15:26:21.182Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition default-dlq-0 broker=0] No checkpointed highwatermark is found for partition default-dlq-0
2025-12-18T15:26:21.182Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition default-dlq-0 broker=0] Log loaded for partition default-dlq-0 with initial high watermark 0
2025-12-18T15:26:21.182Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader default-dlq-0 with topic id Some(QIHIclOoRV6BYw1IRuLgcA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.183Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:21.183Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:21.183Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071581183
2025-12-18T15:26:21.184Z  INFO 53856 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: _n6NJ-LyQ2qniVJvyj2rrA
2025-12-18T15:26:21.187Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=0, firstProducerId=0, size=1000) by writing to Zk with path version 1
2025-12-18T15:26:21.187Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 15ms correlationId 13 from controller 0 for 2 partitions
2025-12-18T15:26:21.188Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 14
2025-12-18T15:26:21.188Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 15 from controller 0 for 3 partitions
2025-12-18T15:26:21.189Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(circuit-breaker-dlq-0, circuit-breaker-topic-0, conditional-routing-test-0)
2025-12-18T15:26:21.189Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 15 from controller 0 epoch 1 as part of the become-leader transition for 3 partitions
2025-12-18T15:26:21.190Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=circuit-breaker-dlq-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.190Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition circuit-breaker-dlq-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/circuit-breaker-dlq-0 with properties {}
2025-12-18T15:26:21.191Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition circuit-breaker-dlq-0 broker=0] No checkpointed highwatermark is found for partition circuit-breaker-dlq-0
2025-12-18T15:26:21.191Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition circuit-breaker-dlq-0 broker=0] Log loaded for partition circuit-breaker-dlq-0 with initial high watermark 0
2025-12-18T15:26:21.191Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader circuit-breaker-dlq-0 with topic id Some(7hK681gXSl-m_Wna2ZuFjA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.197Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=circuit-breaker-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.197Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition circuit-breaker-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/circuit-breaker-topic-0 with properties {}
2025-12-18T15:26:21.197Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition circuit-breaker-topic-0 broker=0] No checkpointed highwatermark is found for partition circuit-breaker-topic-0
2025-12-18T15:26:21.197Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition circuit-breaker-topic-0 broker=0] Log loaded for partition circuit-breaker-topic-0 with initial high watermark 0
2025-12-18T15:26:21.197Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader circuit-breaker-topic-0 with topic id Some(lj2cfMOGSL2wK_gnZOgXGw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.204Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=conditional-routing-test-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.204Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition conditional-routing-test-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/conditional-routing-test-0 with properties {}
2025-12-18T15:26:21.204Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition conditional-routing-test-0 broker=0] No checkpointed highwatermark is found for partition conditional-routing-test-0
2025-12-18T15:26:21.204Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition conditional-routing-test-0 broker=0] Log loaded for partition conditional-routing-test-0 with initial high watermark 0
2025-12-18T15:26:21.204Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader conditional-routing-test-0 with topic id Some(qDB6wY4nR8Sc4LV18xk7NQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.209Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 21ms correlationId 15 from controller 0 for 3 partitions
2025-12-18T15:26:21.210Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 3 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 16
2025-12-18T15:26:21.211Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 17 from controller 0 for 3 partitions
2025-12-18T15:26:21.211Z  INFO 53856 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-5-0, replay-source-topic-6-0, replay-source-topic-4-0)
2025-12-18T15:26:21.211Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 17 from controller 0 epoch 1 as part of the become-leader transition for 3 partitions
2025-12-18T15:26:21.213Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-5-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.213Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition replay-source-topic-5-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/replay-source-topic-5-0 with properties {}
2025-12-18T15:26:21.213Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-5-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-5-0
2025-12-18T15:26:21.213Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-5-0 broker=0] Log loaded for partition replay-source-topic-5-0 with initial high watermark 0
2025-12-18T15:26:21.213Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader replay-source-topic-5-0 with topic id Some(fL7glRmmQRGgkGnJGSJUbw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.216Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.215Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.216Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] (Re-)joining group
2025-12-18T15:26:21.216Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] (Re-)joining group
2025-12-18T15:26:21.217Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-dlq-group in Empty state. Created a new member id consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be and request the member to rejoin with this id.
2025-12-18T15:26:21.217Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group validation-dlq-group in Empty state. Created a new member id consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378 and request the member to rejoin with this id.
2025-12-18T15:26:21.217Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be
2025-12-18T15:26:21.217Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378
2025-12-18T15:26:21.218Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] (Re-)joining group
2025-12-18T15:26:21.218Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] (Re-)joining group
2025-12-18T15:26:21.218Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group validation-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378 with group instance id None; client reason: need to re-join with the given member-id: consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378)
2025-12-18T15:26:21.218Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be with group instance id None; client reason: need to re-join with the given member-id: consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be)
2025-12-18T15:26:21.218Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group validation-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:21.218Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378', protocol='range'}
2025-12-18T15:26:21.219Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group test-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:21.219Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Finished assignment for group at generation 1: {consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378=Assignment(partitions=[validation-dlq-0])}
2025-12-18T15:26:21.219Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be', protocol='range'}
2025-12-18T15:26:21.219Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Finished assignment for group at generation 1: {consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be=Assignment(partitions=[test-dlq-0])}
2025-12-18T15:26:21.219Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378 for group validation-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.220Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-6-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.220Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be for group test-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.220Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition replay-source-topic-6-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/replay-source-topic-6-0 with properties {}
2025-12-18T15:26:21.220Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-6-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-6-0
2025-12-18T15:26:21.220Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-6-0 broker=0] Log loaded for partition replay-source-topic-6-0 with initial high watermark 0
2025-12-18T15:26:21.220Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader replay-source-topic-6-0 with topic id Some(umzeyrT4QZ2bOF9SGCxPHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.220Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378', protocol='range'}
2025-12-18T15:26:21.220Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be', protocol='range'}
2025-12-18T15:26:21.221Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Notifying assignor about the new Assignment(partitions=[validation-dlq-0])
2025-12-18T15:26:21.221Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Notifying assignor about the new Assignment(partitions=[test-dlq-0])
2025-12-18T15:26:21.221Z  INFO 53856 --- [ntainer#7-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Adding newly assigned partitions: validation-dlq-0
2025-12-18T15:26:21.221Z  INFO 53856 --- [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Adding newly assigned partitions: test-dlq-0
2025-12-18T15:26:21.221Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Found no committed offset for partition test-dlq-0
2025-12-18T15:26:21.221Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Found no committed offset for partition validation-dlq-0
2025-12-18T15:26:21.222Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Resetting offset for partition validation-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.222Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Resetting offset for partition test-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.222Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: partitions assigned: [validation-dlq-0]
2025-12-18T15:26:21.222Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: partitions assigned: [test-dlq-0]
2025-12-18T15:26:21.226Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.226Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-4-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.226Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] (Re-)joining group
2025-12-18T15:26:21.226Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition replay-source-topic-4-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/replay-source-topic-4-0 with properties {}
2025-12-18T15:26:21.226Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-4-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-4-0
2025-12-18T15:26:21.226Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition replay-source-topic-4-0 broker=0] Log loaded for partition replay-source-topic-4-0 with initial high watermark 0
2025-12-18T15:26:21.226Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader replay-source-topic-4-0 with topic id Some(HibNeh_4Quah7O_v8kpOSA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.226Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.227Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] (Re-)joining group
2025-12-18T15:26:21.227Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group timeout-dlq-group in Empty state. Created a new member id consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6 and request the member to rejoin with this id.
2025-12-18T15:26:21.227Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6
2025-12-18T15:26:21.227Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] (Re-)joining group
2025-12-18T15:26:21.228Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group conditional-test-group in Empty state. Created a new member id consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789 and request the member to rejoin with this id.
2025-12-18T15:26:21.228Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.228Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group timeout-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6 with group instance id None; client reason: need to re-join with the given member-id: consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6)
2025-12-18T15:26:21.228Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Request joining group due to: need to re-join with the given member-id: consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789
2025-12-18T15:26:21.228Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] (Re-)joining group
2025-12-18T15:26:21.228Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] (Re-)joining group
2025-12-18T15:26:21.228Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group timeout-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:21.228Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group conditional-test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789 with group instance id None; client reason: need to re-join with the given member-id: consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789)
2025-12-18T15:26:21.228Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6', protocol='range'}
2025-12-18T15:26:21.228Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Finished assignment for group at generation 1: {consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6=Assignment(partitions=[timeout-dlq-0])}
2025-12-18T15:26:21.228Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group conditional-test-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:21.229Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789', protocol='range'}
2025-12-18T15:26:21.229Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Finished assignment for group at generation 1: {consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789=Assignment(partitions=[conditional-routing-test-0])}
2025-12-18T15:26:21.229Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6 for group timeout-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.229Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group default-dlq-group in Empty state. Created a new member id consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c and request the member to rejoin with this id.
2025-12-18T15:26:21.229Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789 for group conditional-test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.229Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c
2025-12-18T15:26:21.229Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] (Re-)joining group
2025-12-18T15:26:21.229Z  WARN 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-5=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6', protocol='range'}
2025-12-18T15:26:21.230Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group default-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c with group instance id None; client reason: need to re-join with the given member-id: consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c)
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Notifying assignor about the new Assignment(partitions=[timeout-dlq-0])
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#8-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Adding newly assigned partitions: timeout-dlq-0
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789', protocol='range'}
2025-12-18T15:26:21.230Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.230Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group default-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Notifying assignor about the new Assignment(partitions=[conditional-routing-test-0])
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Adding newly assigned partitions: conditional-routing-test-0
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c', protocol='range'}
2025-12-18T15:26:21.230Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] (Re-)joining group
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Found no committed offset for partition timeout-dlq-0
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Finished assignment for group at generation 1: {consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c=Assignment(partitions=[default-dlq-0])}
2025-12-18T15:26:21.230Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Found no committed offset for partition conditional-routing-test-0
2025-12-18T15:26:21.231Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c for group default-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Resetting offset for partition timeout-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: partitions assigned: [timeout-dlq-0]
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Resetting offset for partition conditional-routing-test-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: partitions assigned: [conditional-routing-test-0]
2025-12-18T15:26:21.231Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 20ms correlationId 17 from controller 0 for 3 partitions
2025-12-18T15:26:21.231Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 in Empty state. Created a new member id consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb and request the member to rejoin with this id.
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c', protocol='range'}
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Notifying assignor about the new Assignment(partitions=[default-dlq-0])
2025-12-18T15:26:21.231Z  INFO 53856 --- [ntainer#9-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Adding newly assigned partitions: default-dlq-0
2025-12-18T15:26:21.232Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb
2025-12-18T15:26:21.232Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] (Re-)joining group
2025-12-18T15:26:21.232Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Found no committed offset for partition default-dlq-0
2025-12-18T15:26:21.232Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 3 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 18
2025-12-18T15:26:21.232Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb)
2025-12-18T15:26:21.232Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Resetting offset for partition default-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.232Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: partitions assigned: [default-dlq-0]
2025-12-18T15:26:21.232Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 19 from controller 0 for 1 partitions
2025-12-18T15:26:21.233Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:21.233Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(batch-capacity-topic-0)
2025-12-18T15:26:21.233Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb', protocol='range'}
2025-12-18T15:26:21.233Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 19 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:21.233Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.234Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] (Re-)joining group
2025-12-18T15:26:21.234Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-capacity-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.235Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition batch-capacity-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/batch-capacity-topic-0 with properties {}
2025-12-18T15:26:21.235Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.235Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition batch-capacity-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-capacity-topic-0
2025-12-18T15:26:21.235Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition batch-capacity-topic-0 broker=0] Log loaded for partition batch-capacity-topic-0 with initial high watermark 0
2025-12-18T15:26:21.235Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader batch-capacity-topic-0 with topic id Some(mSCulrYaSCqRJopEWrLtmQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.235Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-window-group in Empty state. Created a new member id consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63 and request the member to rejoin with this id.
2025-12-18T15:26:21.235Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] (Re-)joining group
2025-12-18T15:26:21.235Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.235Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63
2025-12-18T15:26:21.235Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] (Re-)joining group
2025-12-18T15:26:21.236Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] (Re-)joining group
2025-12-18T15:26:21.236Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-window-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63 with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63)
2025-12-18T15:26:21.236Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-window-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:21.236Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group circuit-breaker-dlq-tracker in Empty state. Created a new member id consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db and request the member to rejoin with this id.
2025-12-18T15:26:21.236Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63', protocol='range'}
2025-12-18T15:26:21.236Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Request joining group due to: need to re-join with the given member-id: consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db
2025-12-18T15:26:21.236Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group double-group in Empty state. Created a new member id consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29 and request the member to rejoin with this id.
2025-12-18T15:26:21.237Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] (Re-)joining group
2025-12-18T15:26:21.237Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Request joining group due to: need to re-join with the given member-id: consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29
2025-12-18T15:26:21.237Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Finished assignment for group at generation 1: {consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63=Assignment(partitions=[batch-window-topic-0])}
2025-12-18T15:26:21.237Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] (Re-)joining group
2025-12-18T15:26:21.237Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63 for group batch-window-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.237Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-dlq-tracker in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db with group instance id None; client reason: need to re-join with the given member-id: consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db)
2025-12-18T15:26:21.237Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group double-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29 with group instance id None; client reason: need to re-join with the given member-id: consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29)
2025-12-18T15:26:21.238Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group circuit-breaker-dlq-tracker generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:21.238Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group double-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:21.238Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Successfully joined group with generation Generation{generationId=1, memberId='consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db', protocol='range'}
2025-12-18T15:26:21.238Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63', protocol='range'}
2025-12-18T15:26:21.238Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Finished assignment for group at generation 1: {consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db=Assignment(partitions=[circuit-breaker-dlq-0])}
2025-12-18T15:26:21.238Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Notifying assignor about the new Assignment(partitions=[batch-window-topic-0])
2025-12-18T15:26:21.238Z  INFO 53856 --- [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Adding newly assigned partitions: batch-window-topic-0
2025-12-18T15:26:21.238Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29', protocol='range'}
2025-12-18T15:26:21.239Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db for group circuit-breaker-dlq-tracker for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.239Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Finished assignment for group at generation 1: {consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29=Assignment(partitions=[double-topic-0])}
2025-12-18T15:26:21.239Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Found no committed offset for partition batch-window-topic-0
2025-12-18T15:26:21.239Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29 for group double-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.239Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 19 from controller 0 for 1 partitions
2025-12-18T15:26:21.240Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.240Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29', protocol='range'}
2025-12-18T15:26:21.240Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Successfully synced group in generation Generation{generationId=1, memberId='consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db', protocol='range'}
2025-12-18T15:26:21.240Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Resetting offset for partition batch-window-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.240Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: partitions assigned: [batch-window-topic-0]
2025-12-18T15:26:21.240Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Notifying assignor about the new Assignment(partitions=[double-topic-0])
2025-12-18T15:26:21.240Z  INFO 53856 --- [tainer#12-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-double-group-35, groupId=double-group] Adding newly assigned partitions: double-topic-0
2025-12-18T15:26:21.240Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Notifying assignor about the new Assignment(partitions=[circuit-breaker-dlq-0])
2025-12-18T15:26:21.240Z  INFO 53856 --- [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Adding newly assigned partitions: circuit-breaker-dlq-0
2025-12-18T15:26:21.240Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] (Re-)joining group
2025-12-18T15:26:21.240Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Found no committed offset for partition double-topic-0
2025-12-18T15:26:21.240Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 20
2025-12-18T15:26:21.240Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Found no committed offset for partition circuit-breaker-dlq-0
2025-12-18T15:26:21.241Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.241Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-double-group-35, groupId=double-group] Resetting offset for partition double-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.241Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: partitions assigned: [double-topic-0]
2025-12-18T15:26:21.241Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 21 from controller 0 for 2 partitions
2025-12-18T15:26:21.241Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Resetting offset for partition circuit-breaker-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.241Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: partitions assigned: [circuit-breaker-dlq-0]
2025-12-18T15:26:21.241Z  INFO 53856 --- [quest-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(batch-mixed-topic-0, multi-partition-topic-0)
2025-12-18T15:26:21.241Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 21 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:21.241Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] (Re-)joining group
2025-12-18T15:26:21.242Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group dlq-group in Empty state. Created a new member id consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f and request the member to rejoin with this id.
2025-12-18T15:26:21.242Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f
2025-12-18T15:26:21.242Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] (Re-)joining group
2025-12-18T15:26:21.242Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group circuit-breaker-group in Empty state. Created a new member id consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc and request the member to rejoin with this id.
2025-12-18T15:26:21.242Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f with group instance id None; client reason: need to re-join with the given member-id: consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f)
2025-12-18T15:26:21.243Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Request joining group due to: need to re-join with the given member-id: consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc
2025-12-18T15:26:21.243Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] (Re-)joining group
2025-12-18T15:26:21.243Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.243Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group dlq-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:21.243Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc with group instance id None; client reason: need to re-join with the given member-id: consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc)
2025-12-18T15:26:21.243Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f', protocol='range'}
2025-12-18T15:26:21.243Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-mixed-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.243Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group circuit-breaker-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:21.243Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] (Re-)joining group
2025-12-18T15:26:21.243Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Finished assignment for group at generation 1: {consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f=Assignment(partitions=[dlq-topic-0])}
2025-12-18T15:26:21.243Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition batch-mixed-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/batch-mixed-topic-0 with properties {}
2025-12-18T15:26:21.243Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition batch-mixed-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-mixed-topic-0
2025-12-18T15:26:21.243Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition batch-mixed-topic-0 broker=0] Log loaded for partition batch-mixed-topic-0 with initial high watermark 0
2025-12-18T15:26:21.244Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader batch-mixed-topic-0 with topic id Some(dejevcBWRFSRlrIRhnDq_w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.244Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc', protocol='range'}
2025-12-18T15:26:21.244Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f for group dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.244Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Finished assignment for group at generation 1: {consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc=Assignment(partitions=[circuit-breaker-topic-0])}
2025-12-18T15:26:21.244Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc for group circuit-breaker-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.244Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 in Empty state. Created a new member id consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff and request the member to rejoin with this id.
2025-12-18T15:26:21.244Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff
2025-12-18T15:26:21.244Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f', protocol='range'}
2025-12-18T15:26:21.245Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] (Re-)joining group
2025-12-18T15:26:21.245Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Notifying assignor about the new Assignment(partitions=[dlq-topic-0])
2025-12-18T15:26:21.245Z  INFO 53856 --- [tainer#11-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Adding newly assigned partitions: dlq-topic-0
2025-12-18T15:26:21.245Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc', protocol='range'}
2025-12-18T15:26:21.245Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Notifying assignor about the new Assignment(partitions=[circuit-breaker-topic-0])
2025-12-18T15:26:21.245Z  INFO 53856 --- [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Adding newly assigned partitions: circuit-breaker-topic-0
2025-12-18T15:26:21.245Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff)
2025-12-18T15:26:21.245Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Found no committed offset for partition dlq-topic-0
2025-12-18T15:26:21.245Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:21.245Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Found no committed offset for partition circuit-breaker-topic-0
2025-12-18T15:26:21.246Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff', protocol='range'}
2025-12-18T15:26:21.246Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Finished assignment for group at generation 1: {consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff=Assignment(partitions=[replay-source-topic-4-0])}
2025-12-18T15:26:21.246Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Resetting offset for partition dlq-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.246Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: partitions assigned: [dlq-topic-0]
2025-12-18T15:26:21.246Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Resetting offset for partition circuit-breaker-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.246Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: partitions assigned: [circuit-breaker-topic-0]
2025-12-18T15:26:21.247Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff for group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.248Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.248Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff', protocol='range'}
2025-12-18T15:26:21.248Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Notifying assignor about the new Assignment(partitions=[replay-source-topic-4-0])
2025-12-18T15:26:21.248Z  INFO 53856 --- [tainer#17-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Adding newly assigned partitions: replay-source-topic-4-0
2025-12-18T15:26:21.248Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] (Re-)joining group
2025-12-18T15:26:21.248Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Found no committed offset for partition replay-source-topic-4-0
2025-12-18T15:26:21.249Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa in Empty state. Created a new member id consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c and request the member to rejoin with this id.
2025-12-18T15:26:21.249Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Resetting offset for partition replay-source-topic-4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.249Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917: partitions assigned: [replay-source-topic-4-0]
2025-12-18T15:26:21.249Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c
2025-12-18T15:26:21.249Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] (Re-)joining group
2025-12-18T15:26:21.250Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c)
2025-12-18T15:26:21.250Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=multi-partition-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.250Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:21.250Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition multi-partition-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/multi-partition-topic-0 with properties {}
2025-12-18T15:26:21.250Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition multi-partition-topic-0 broker=0] No checkpointed highwatermark is found for partition multi-partition-topic-0
2025-12-18T15:26:21.250Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c', protocol='range'}
2025-12-18T15:26:21.250Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition multi-partition-topic-0 broker=0] Log loaded for partition multi-partition-topic-0 with initial high watermark 0
2025-12-18T15:26:21.250Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader multi-partition-topic-0 with topic id Some(DkEwcK0EQWG9bsw2bFtQ9A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.250Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Finished assignment for group at generation 1: {consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c=Assignment(partitions=[replay-source-topic-6-0])}
2025-12-18T15:26:21.251Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c for group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.251Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c', protocol='range'}
2025-12-18T15:26:21.252Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Notifying assignor about the new Assignment(partitions=[replay-source-topic-6-0])
2025-12-18T15:26:21.252Z  INFO 53856 --- [tainer#19-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Adding newly assigned partitions: replay-source-topic-6-0
2025-12-18T15:26:21.252Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Found no committed offset for partition replay-source-topic-6-0
2025-12-18T15:26:21.253Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Resetting offset for partition replay-source-topic-6-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.253Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa: partitions assigned: [replay-source-topic-6-0]
2025-12-18T15:26:21.254Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.255Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] (Re-)joining group
2025-12-18T15:26:21.255Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 14ms correlationId 21 from controller 0 for 2 partitions
2025-12-18T15:26:21.255Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 22
2025-12-18T15:26:21.256Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 23 from controller 0 for 1 partitions
2025-12-18T15:26:21.256Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-capacity-group in Empty state. Created a new member id consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea and request the member to rejoin with this id.
2025-12-18T15:26:21.256Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea
2025-12-18T15:26:21.256Z  INFO 53856 --- [quest-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(test-topic-0)
2025-12-18T15:26:21.256Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 23 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:21.256Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] (Re-)joining group
2025-12-18T15:26:21.257Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-capacity-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea)
2025-12-18T15:26:21.257Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-capacity-group generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:21.257Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea', protocol='range'}
2025-12-18T15:26:21.257Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Finished assignment for group at generation 1: {consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea=Assignment(partitions=[batch-capacity-topic-0])}
2025-12-18T15:26:21.258Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea for group batch-capacity-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.258Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=test-topic-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.258Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition test-topic-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/test-topic-0 with properties {}
2025-12-18T15:26:21.258Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition test-topic-0 broker=0] No checkpointed highwatermark is found for partition test-topic-0
2025-12-18T15:26:21.258Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0
2025-12-18T15:26:21.259Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader test-topic-0 with topic id Some(5Xmcy2gSQMikdpxUR_A2FQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.259Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea', protocol='range'}
2025-12-18T15:26:21.259Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Notifying assignor about the new Assignment(partitions=[batch-capacity-topic-0])
2025-12-18T15:26:21.259Z  INFO 53856 --- [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Adding newly assigned partitions: batch-capacity-topic-0
2025-12-18T15:26:21.260Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Found no committed offset for partition batch-capacity-topic-0
2025-12-18T15:26:21.260Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Resetting offset for partition batch-capacity-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.260Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: partitions assigned: [batch-capacity-topic-0]
2025-12-18T15:26:21.263Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 23 from controller 0 for 1 partitions
2025-12-18T15:26:21.263Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 24
2025-12-18T15:26:21.264Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 25 from controller 0 for 1 partitions
2025-12-18T15:26:21.264Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-partition-dlq-0)
2025-12-18T15:26:21.264Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 25 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:21.265Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.266Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=multi-partition-dlq-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.266Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] (Re-)joining group
2025-12-18T15:26:21.266Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition multi-partition-dlq-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/multi-partition-dlq-0 with properties {}
2025-12-18T15:26:21.266Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition multi-partition-dlq-0 broker=0] No checkpointed highwatermark is found for partition multi-partition-dlq-0
2025-12-18T15:26:21.266Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition multi-partition-dlq-0 broker=0] Log loaded for partition multi-partition-dlq-0 with initial high watermark 0
2025-12-18T15:26:21.266Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader multi-partition-dlq-0 with topic id Some(kCpLsZPcTBSS2axl2oKXYQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.267Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group multi-partition-test-group in Empty state. Created a new member id consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2 and request the member to rejoin with this id.
2025-12-18T15:26:21.267Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Request joining group due to: need to re-join with the given member-id: consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2
2025-12-18T15:26:21.267Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] (Re-)joining group
2025-12-18T15:26:21.268Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2 with group instance id None; client reason: need to re-join with the given member-id: consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2)
2025-12-18T15:26:21.268Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group multi-partition-test-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:21.268Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2', protocol='range'}
2025-12-18T15:26:21.268Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Finished assignment for group at generation 1: {consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2=Assignment(partitions=[multi-partition-topic-0])}
2025-12-18T15:26:21.269Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.269Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.269Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2 for group multi-partition-test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.269Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] (Re-)joining group
2025-12-18T15:26:21.269Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] (Re-)joining group
2025-12-18T15:26:21.270Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2', protocol='range'}
2025-12-18T15:26:21.270Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Notifying assignor about the new Assignment(partitions=[multi-partition-topic-0])
2025-12-18T15:26:21.270Z  INFO 53856 --- [tainer#20-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Adding newly assigned partitions: multi-partition-topic-0
2025-12-18T15:26:21.270Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-group in Empty state. Created a new member id consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef and request the member to rejoin with this id.
2025-12-18T15:26:21.270Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-mixed-group in Empty state. Created a new member id consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a and request the member to rejoin with this id.
2025-12-18T15:26:21.270Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Found no committed offset for partition multi-partition-topic-0
2025-12-18T15:26:21.271Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef
2025-12-18T15:26:21.271Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 25 from controller 0 for 1 partitions
2025-12-18T15:26:21.271Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a
2025-12-18T15:26:21.271Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] (Re-)joining group
2025-12-18T15:26:21.271Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] (Re-)joining group
2025-12-18T15:26:21.271Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Resetting offset for partition multi-partition-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.271Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: partitions assigned: [multi-partition-topic-0]
2025-12-18T15:26:21.271Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef with group instance id None; client reason: need to re-join with the given member-id: consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef)
2025-12-18T15:26:21.271Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-mixed-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a)
2025-12-18T15:26:21.272Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 26
2025-12-18T15:26:21.272Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group test-group generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:21.272Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-mixed-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:21.272Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef', protocol='range'}
2025-12-18T15:26:21.272Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a', protocol='range'}
2025-12-18T15:26:21.272Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef=Assignment(partitions=[test-topic-0])}
2025-12-18T15:26:21.272Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 27 from controller 0 for 2 partitions
2025-12-18T15:26:21.272Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Finished assignment for group at generation 1: {consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a=Assignment(partitions=[batch-mixed-topic-0])}
2025-12-18T15:26:21.273Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-3-0, replay-source-topic-2-0)
2025-12-18T15:26:21.273Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 27 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:21.273Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a for group batch-mixed-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.273Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef for group test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.273Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a', protocol='range'}
2025-12-18T15:26:21.273Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef', protocol='range'}
2025-12-18T15:26:21.273Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Notifying assignor about the new Assignment(partitions=[batch-mixed-topic-0])
2025-12-18T15:26:21.274Z  INFO 53856 --- [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Adding newly assigned partitions: batch-mixed-topic-0
2025-12-18T15:26:21.274Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Notifying assignor about the new Assignment(partitions=[test-topic-0])
2025-12-18T15:26:21.274Z  INFO 53856 --- [tainer#10-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-39, groupId=test-group] Adding newly assigned partitions: test-topic-0
2025-12-18T15:26:21.274Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Found no committed offset for partition batch-mixed-topic-0
2025-12-18T15:26:21.274Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Found no committed offset for partition test-topic-0
2025-12-18T15:26:21.274Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-3-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.274Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Resetting offset for partition batch-mixed-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.275Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: partitions assigned: [batch-mixed-topic-0]
2025-12-18T15:26:21.275Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-39, groupId=test-group] Resetting offset for partition test-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.275Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [test-topic-0]
2025-12-18T15:26:21.275Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition replay-source-topic-3-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/replay-source-topic-3-0 with properties {}
2025-12-18T15:26:21.275Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-3-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-3-0
2025-12-18T15:26:21.275Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-3-0 broker=0] Log loaded for partition replay-source-topic-3-0 with initial high watermark 0
2025-12-18T15:26:21.275Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader replay-source-topic-3-0 with topic id Some(1mSEChBJSruNxrEhciHPeA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.280Z  WARN 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-2=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:21.280Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-2-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.281Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition replay-source-topic-2-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/replay-source-topic-2-0 with properties {}
2025-12-18T15:26:21.281Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-2-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-2-0
2025-12-18T15:26:21.281Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-2-0 broker=0] Log loaded for partition replay-source-topic-2-0 with initial high watermark 0
2025-12-18T15:26:21.281Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader replay-source-topic-2-0 with topic id Some(hJaU7gvERum1dT-KZ0d01A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.281Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.281Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] (Re-)joining group
2025-12-18T15:26:21.282Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e in Empty state. Created a new member id consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a and request the member to rejoin with this id.
2025-12-18T15:26:21.283Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a
2025-12-18T15:26:21.283Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] (Re-)joining group
2025-12-18T15:26:21.283Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a)
2025-12-18T15:26:21.283Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.284Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e generation 1 (__consumer_offsets-3) with 1 members
2025-12-18T15:26:21.284Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] (Re-)joining group
2025-12-18T15:26:21.287Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a', protocol='range'}
2025-12-18T15:26:21.287Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 15ms correlationId 27 from controller 0 for 2 partitions
2025-12-18T15:26:21.287Z  INFO 53856 --- [ad | producer-2] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-2] ProducerId set to 0 with epoch 0
2025-12-18T15:26:21.288Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group multi-partition-dlq-collector in Empty state. Created a new member id consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c and request the member to rejoin with this id.
2025-12-18T15:26:21.288Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 28
2025-12-18T15:26:21.288Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Request joining group due to: need to re-join with the given member-id: consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c
2025-12-18T15:26:21.288Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] (Re-)joining group
2025-12-18T15:26:21.288Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 29 from controller 0 for 1 partitions
2025-12-18T15:26:21.289Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-1-0)
2025-12-18T15:26:21.289Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-dlq-collector in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c with group instance id None; client reason: need to re-join with the given member-id: consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c)
2025-12-18T15:26:21.289Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 29 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:21.289Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group multi-partition-dlq-collector generation 1 (__consumer_offsets-3) with 1 members
2025-12-18T15:26:21.289Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Successfully joined group with generation Generation{generationId=1, memberId='consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c', protocol='range'}
2025-12-18T15:26:21.289Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Finished assignment for group at generation 1: {consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c=Assignment(partitions=[multi-partition-dlq-0])}
2025-12-18T15:26:21.290Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.290Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c for group multi-partition-dlq-collector for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.290Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] (Re-)joining group
2025-12-18T15:26:21.290Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-1-0, dir=/tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:21.290Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition replay-source-topic-1-0 in /tmp/spring.kafka.604b0fec-335c-47a8-bbcb-37659e8ccd3c14064004736896207277/replay-source-topic-1-0 with properties {}
2025-12-18T15:26:21.291Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition replay-source-topic-1-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-1-0
2025-12-18T15:26:21.291Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition replay-source-topic-1-0 broker=0] Log loaded for partition replay-source-topic-1-0 with initial high watermark 0
2025-12-18T15:26:21.291Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader replay-source-topic-1-0 with topic id Some(y_hczy4FQsuz9g2sxEzjVg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:21.291Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group string-group in Empty state. Created a new member id consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2 and request the member to rejoin with this id.
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Request joining group due to: need to re-join with the given member-id: consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Discovered group coordinator localhost:46201 (id: 2147483647 rack: null)
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Successfully synced group in generation Generation{generationId=1, memberId='consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c', protocol='range'}
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] (Re-)joining group
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Notifying assignor about the new Assignment(partitions=[multi-partition-dlq-0])
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#21-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Adding newly assigned partitions: multi-partition-dlq-0
2025-12-18T15:26:21.291Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] (Re-)joining group
2025-12-18T15:26:21.292Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group string-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2 with group instance id None; client reason: need to re-join with the given member-id: consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2)
2025-12-18T15:26:21.292Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Found no committed offset for partition multi-partition-dlq-0
2025-12-18T15:26:21.292Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group string-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:21.292Z  INFO 53856 --- [tainer#12-0-C-1] n.d.Kafka.RetryScheduler.RetrySched      : scheduled retry for event: 999.99 to topic: double-topic
2025-12-18T15:26:21.292Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 in Empty state. Created a new member id consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067 and request the member to rejoin with this id.
2025-12-18T15:26:21.292Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2', protocol='range'}
2025-12-18T15:26:21.292Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067
2025-12-18T15:26:21.293Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Finished assignment for group at generation 1: {consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2=Assignment(partitions=[string-topic-0])}
2025-12-18T15:26:21.293Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] (Re-)joining group
2025-12-18T15:26:21.293Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Resetting offset for partition multi-partition-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.293Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: partitions assigned: [multi-partition-dlq-0]
2025-12-18T15:26:21.293Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2 for group string-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.293Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067)
2025-12-18T15:26:21.293Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:21.293Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2', protocol='range'}
2025-12-18T15:26:21.293Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067', protocol='range'}
2025-12-18T15:26:21.294Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Notifying assignor about the new Assignment(partitions=[string-topic-0])
2025-12-18T15:26:21.294Z  INFO 53856 --- [tainer#13-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-string-group-43, groupId=string-group] Adding newly assigned partitions: string-topic-0
2025-12-18T15:26:21.294Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Finished assignment for group at generation 1: {consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067=Assignment(partitions=[replay-source-topic-3-0])}
2025-12-18T15:26:21.294Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067 for group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.294Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Found no committed offset for partition string-topic-0
2025-12-18T15:26:21.295Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-string-group-43, groupId=string-group] Resetting offset for partition string-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.295Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067', protocol='range'}
2025-12-18T15:26:21.295Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: partitions assigned: [string-topic-0]
2025-12-18T15:26:21.295Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Notifying assignor about the new Assignment(partitions=[replay-source-topic-3-0])
2025-12-18T15:26:21.295Z  INFO 53856 --- [tainer#16-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Adding newly assigned partitions: replay-source-topic-3-0
2025-12-18T15:26:21.295Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 29 from controller 0 for 1 partitions
2025-12-18T15:26:21.295Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Found no committed offset for partition replay-source-topic-3-0
2025-12-18T15:26:21.296Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 30
2025-12-18T15:26:21.296Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Resetting offset for partition replay-source-topic-3-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.296Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5: partitions assigned: [replay-source-topic-3-0]
2025-12-18T15:26:21.297Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Finished assignment for group at generation 1: {consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475=Assignment(partitions=[replay-source-topic-1-0])}
2025-12-18T15:26:21.297Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475 for group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.298Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475', protocol='range'}
2025-12-18T15:26:21.298Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Notifying assignor about the new Assignment(partitions=[replay-source-topic-1-0])
2025-12-18T15:26:21.298Z  INFO 53856 --- [tainer#14-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Adding newly assigned partitions: replay-source-topic-1-0
2025-12-18T15:26:21.299Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Found no committed offset for partition replay-source-topic-1-0
2025-12-18T15:26:21.300Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Resetting offset for partition replay-source-topic-1-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.300Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac: partitions assigned: [replay-source-topic-1-0]
2025-12-18T15:26:21.435Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Finished assignment for group at generation 1: {consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb=Assignment(partitions=[replay-source-topic-5-0])}
2025-12-18T15:26:21.435Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb for group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.436Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb', protocol='range'}
2025-12-18T15:26:21.436Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Notifying assignor about the new Assignment(partitions=[replay-source-topic-5-0])
2025-12-18T15:26:21.436Z  INFO 53856 --- [tainer#18-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Adding newly assigned partitions: replay-source-topic-5-0
2025-12-18T15:26:21.436Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Found no committed offset for partition replay-source-topic-5-0
2025-12-18T15:26:21.437Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Resetting offset for partition replay-source-topic-5-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.437Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576: partitions assigned: [replay-source-topic-5-0]
2025-12-18T15:26:21.484Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Finished assignment for group at generation 1: {consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a=Assignment(partitions=[replay-source-topic-2-0])}
2025-12-18T15:26:21.485Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a for group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:21.486Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a', protocol='range'}
2025-12-18T15:26:21.486Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Notifying assignor about the new Assignment(partitions=[replay-source-topic-2-0])
2025-12-18T15:26:21.486Z  INFO 53856 --- [tainer#15-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Adding newly assigned partitions: replay-source-topic-2-0
2025-12-18T15:26:21.486Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Found no committed offset for partition replay-source-topic-2-0
2025-12-18T15:26:21.487Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Resetting offset for partition replay-source-topic-2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46201 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:21.487Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e: partitions assigned: [replay-source-topic-2-0]
2025-12-18T15:26:21.492Z  INFO 53856 --- [try-scheduler-1] n.d.Kafka.RetryScheduler.RetrySched      : retried event: 999.99 to topic: double-topic
2025-12-18T15:26:21.496Z  INFO 53856 --- [tainer#12-0-C-1] n.d.Kafka.Aspect.KafkaListenerAspect     : max attempts reached (2) for event in topic: double-topic
2025-12-18T15:26:21.504Z  INFO 53856 --- [tainer#12-0-C-1] n.damero.Kafka.KafkaServices.KafkaDLQ    : successfully sent to dlq topic: dlq-topic
2025-12-18T15:26:21.504Z  INFO 53856 --- [tainer#12-0-C-1] n.d.Kafka.Aspect.Components.DLQRouter    : sent event to custom dlq 'dlq-topic' after 2 attempts for topic: double-topic
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#7-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Revoke previously assigned partitions validation-dlq-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Revoke previously assigned partitions circuit-breaker-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#8-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Revoke previously assigned partitions timeout-dlq-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Revoke previously assigned partitions replay-source-topic-6-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: partitions revoked: [circuit-breaker-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Revoke previously assigned partitions conditional-routing-test-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-double-group-35, groupId=double-group] Revoke previously assigned partitions double-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#11-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Revoke previously assigned partitions dlq-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Revoke previously assigned partitions batch-window-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Member consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: partitions revoked: [batch-window-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: partitions revoked: [dlq-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Member consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Member consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#20-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Revoke previously assigned partitions multi-partition-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#9-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Revoke previously assigned partitions default-dlq-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: partitions revoked: [multi-partition-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Revoke previously assigned partitions test-dlq-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Revoke previously assigned partitions circuit-breaker-dlq-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: partitions revoked: [test-dlq-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: partitions revoked: [circuit-breaker-dlq-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: partitions revoked: [validation-dlq-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#16-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Revoke previously assigned partitions replay-source-topic-3-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Member consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Member consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5: partitions revoked: [replay-source-topic-3-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#15-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Revoke previously assigned partitions replay-source-topic-2-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: partitions revoked: [timeout-dlq-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e: partitions revoked: [replay-source-topic-2-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa: partitions revoked: [replay-source-topic-6-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#13-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-string-group-43, groupId=string-group] Revoke previously assigned partitions string-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: partitions revoked: [conditional-routing-test-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: partitions revoked: [double-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Member consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#17-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Revoke previously assigned partitions replay-source-topic-4-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#18-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Revoke previously assigned partitions replay-source-topic-5-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-window-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Member consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Revoke previously assigned partitions batch-capacity-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#21-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Revoke previously assigned partitions multi-partition-dlq-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576: partitions revoked: [replay-source-topic-5-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: partitions revoked: [batch-capacity-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: partitions revoked: [multi-partition-dlq-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Member consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Member consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-double-group-35, groupId=double-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group dlq-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917: partitions revoked: [replay-source-topic-4-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Member consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: partitions revoked: [default-dlq-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Member consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Member consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#14-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Revoke previously assigned partitions replay-source-topic-1-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Member consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Member consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac: partitions revoked: [replay-source-topic-1-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Member consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Revoke previously assigned partitions batch-mixed-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Member consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: partitions revoked: [batch-mixed-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Member consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: partitions revoked: [string-topic-0]
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Member consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Member consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-capacity-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group circuit-breaker-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-dlq-group-34-8caa4c35-5549-4189-a41b-bf611aa8ac5f, groupInstanceId=None, clientId=consumer-dlq-group-34, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-capacity-group with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-window-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Member consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.594Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-dlq-tracker in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group test-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#10-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-39, groupId=test-group] Revoke previously assigned partitions test-topic-0
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: [test-topic-0]
2025-12-18T15:26:21.594Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Member consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-39, groupId=test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-39, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-34, groupId=dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Member consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2 sending LeaveGroup request to coordinator localhost:46201 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group circuit-breaker-dlq-tracker with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-35, groupId=double-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-capacity-group-36-2fb80464-79bd-4581-b329-bbd8d4fb7dea, groupInstanceId=None, clientId=consumer-batch-capacity-group-36, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-capacity-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-window-group-27-0f795250-d27d-4ac2-a7de-cf01d8129e63, groupInstanceId=None, clientId=consumer-batch-window-group-27, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-window-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.595Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-dlq-group-23-9de529a3-0a63-4afb-93d7-1e9b5d1dd1be, groupInstanceId=None, clientId=consumer-test-dlq-group-23, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group double-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33-014d9a82-b470-402d-945a-d7c20a0b1ddb, groupInstanceId=None, clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group double-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-circuit-breaker-dlq-tracker-29-21981e35-3c45-47c8-88bc-e2010cdcb0db, groupInstanceId=None, clientId=consumer-circuit-breaker-dlq-tracker-29, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group circuit-breaker-dlq-tracker through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group default-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group default-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:21.596Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-string-group-43, groupId=string-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group validation-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group validation-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-double-group-35-aaa75f25-b59d-4cf2-a225-6eed8dd1aa29, groupInstanceId=None, clientId=consumer-double-group-35, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group double-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-default-dlq-group-26-67a4b376-f215-43b8-9686-7ca81064e47c, groupInstanceId=None, clientId=consumer-default-dlq-group-26, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group default-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31-ed3369b7-0416-4c4b-94fc-b26248eac39c, groupInstanceId=None, clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.597Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.597Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-43, groupId=string-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.597Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.597Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-validation-dlq-group-24-e0ba529c-cc13-412b-a3d2-d1396834f378, groupInstanceId=None, clientId=consumer-validation-dlq-group-24, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group validation-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42-22a1fc98-e25a-4d3c-977e-4681a1459067, groupInstanceId=None, clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Removing member consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group conditional-test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e with generation 2 is now empty (__consumer_offsets-3)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group conditional-test-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41-811febae-4959-4a91-9954-4f2feaa2fb6a, groupInstanceId=None, clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-circuit-breaker-group-28-7d7f6d8b-bf71-4bd4-8467-555aa467abcc, groupInstanceId=None, clientId=consumer-circuit-breaker-group-28, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group circuit-breaker-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.596Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group multi-partition-test-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32-6ca7c63c-c73f-48ea-b025-5510b6bb3aff, groupInstanceId=None, clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group timeout-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-mixed-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-conditional-test-group-30-033a522d-c8ce-42d2-bda7-f7a267e4e789, groupInstanceId=None, clientId=consumer-conditional-test-group-30, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group conditional-test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-dlq-collector in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Removing member consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-mixed-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group string-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group string-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group multi-partition-dlq-collector with generation 2 is now empty (__consumer_offsets-3)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group test-group with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-multi-partition-test-group-37-ad94e274-47a0-4115-a80c-a24311e87ac2, groupInstanceId=None, clientId=consumer-multi-partition-test-group-37, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group multi-partition-test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.597Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44-3193566c-8ee6-4703-91ee-a4c09b38f475, groupInstanceId=None, clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.598Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-string-group-43-56fa6580-0764-4b4b-8517-6abec8e0fcc2, groupInstanceId=None, clientId=consumer-string-group-43, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group string-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.598Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-multi-partition-dlq-collector-40-962542ed-36b6-4c52-9eca-793dbb08a75c, groupInstanceId=None, clientId=consumer-multi-partition-dlq-collector-40, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group multi-partition-dlq-collector through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.598Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group timeout-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:21.598Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-group-39-49757e99-7398-4046-ae29-66a73bce34ef, groupInstanceId=None, clientId=consumer-test-group-39, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.598Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-timeout-dlq-group-25-a6b2d2c7-0e89-47d6-9965-fafb679347c6, groupInstanceId=None, clientId=consumer-timeout-dlq-group-25, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group timeout-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.598Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-mixed-group-38-f91fdfe2-f093-4f6a-b24d-6f65f506a75a, groupInstanceId=None, clientId=consumer-batch-mixed-group-38, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-mixed-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-test-dlq-group-23, groupId=test-dlq-group] Node 0 sent an invalid full fetch response with extraIds=(8NlECgI0RpyfhjWM6wgZFg), response=()
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-validation-dlq-group-24, groupId=validation-dlq-group] Node 0 sent an invalid full fetch response with extraIds=(_B46816WQl23_cN73M_Yig), response=()
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.724Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.725Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-test-dlq-group-23 unregistered
2025-12-18T15:26:21.725Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: Consumer stopped
2025-12-18T15:26:21.725Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-validation-dlq-group-24 unregistered
2025-12-18T15:26:21.725Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: Consumer stopped
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-timeout-dlq-group-25, groupId=timeout-dlq-group] Node 0 sent an invalid full fetch response with extraIds=(I5OPAiTGQMWfVQSUQCL8RA), response=()
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-conditional-test-group-30, groupId=conditional-test-group] Node 0 sent an invalid full fetch response with extraIds=(qDB6wY4nR8Sc4LV18xk7NQ), response=()
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.733Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-default-dlq-group-26, groupId=default-dlq-group] Node 0 sent an invalid full fetch response with extraIds=(QIHIclOoRV6BYw1IRuLgcA), response=()
2025-12-18T15:26:21.734Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.734Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.734Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.734Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.734Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-conditional-test-group-30 unregistered
2025-12-18T15:26:21.734Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: Consumer stopped
2025-12-18T15:26:21.735Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-timeout-dlq-group-25 unregistered
2025-12-18T15:26:21.735Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: Consumer stopped
2025-12-18T15:26:21.735Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-default-dlq-group-26 unregistered
2025-12-18T15:26:21.735Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: Consumer stopped
2025-12-18T15:26:21.742Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-29, groupId=circuit-breaker-dlq-tracker] Node 0 sent an invalid full fetch response with extraIds=(7hK681gXSl-m_Wna2ZuFjA), response=()
2025-12-18T15:26:21.742Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-batch-window-group-27, groupId=batch-window-group] Node 0 sent an invalid full fetch response with extraIds=(h1cVgXlRRVq_f-IfQgmJ0w), response=()
2025-12-18T15:26:21.742Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.742Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.742Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.742Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.743Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.743Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.743Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.743Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.743Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-circuit-breaker-dlq-tracker-29 unregistered
2025-12-18T15:26:21.743Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: Consumer stopped
2025-12-18T15:26:21.744Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-window-group-27 unregistered
2025-12-18T15:26:21.744Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: Consumer stopped
2025-12-18T15:26:21.748Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-circuit-breaker-group-28, groupId=circuit-breaker-group] Node 0 sent an invalid full fetch response with extraIds=(lj2cfMOGSL2wK_gnZOgXGw), response=()
2025-12-18T15:26:21.749Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.749Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.749Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.749Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.749Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-circuit-breaker-group-28 unregistered
2025-12-18T15:26:21.749Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: Consumer stopped
2025-12-18T15:26:21.750Z  INFO 53856 --- [tainer#17-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32, groupId=replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917] Node 0 sent an invalid full fetch response with extraIds=(HibNeh_4Quah7O_v8kpOSA), response=()
2025-12-18T15:26:21.750Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.750Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.750Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.750Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.751Z  INFO 53856 --- [tainer#17-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917-32 unregistered
2025-12-18T15:26:21.751Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-39ee696a-8bc5-433a-a2b1-01d0c5ca0917: Consumer stopped
2025-12-18T15:26:21.754Z  INFO 53856 --- [tainer#19-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31, groupId=replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa] Node 0 sent an invalid full fetch response with extraIds=(umzeyrT4QZ2bOF9SGCxPHw), response=()
2025-12-18T15:26:21.755Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.755Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.755Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.755Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.756Z  INFO 53856 --- [tainer#19-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa-31 unregistered
2025-12-18T15:26:21.756Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-54cc8a34-0f54-4a88-be7f-9e2095e8d5aa: Consumer stopped
2025-12-18T15:26:21.762Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-batch-capacity-group-36, groupId=batch-capacity-group] Node 0 sent an invalid full fetch response with extraIds=(mSCulrYaSCqRJopEWrLtmQ), response=()
2025-12-18T15:26:21.762Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.762Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.762Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.762Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.763Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-capacity-group-36 unregistered
2025-12-18T15:26:21.763Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: Consumer stopped
2025-12-18T15:26:21.773Z  INFO 53856 --- [tainer#20-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-multi-partition-test-group-37, groupId=multi-partition-test-group] Node 0 sent an invalid full fetch response with extraIds=(DkEwcK0EQWG9bsw2bFtQ9A), response=()
2025-12-18T15:26:21.773Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.773Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.773Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.773Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.774Z  INFO 53856 --- [tainer#20-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-multi-partition-test-group-37 unregistered
2025-12-18T15:26:21.774Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: Consumer stopped
2025-12-18T15:26:21.777Z  INFO 53856 --- [tainer#10-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-test-group-39, groupId=test-group] Node 0 sent an invalid full fetch response with extraIds=(5Xmcy2gSQMikdpxUR_A2FQ), response=()
2025-12-18T15:26:21.777Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-batch-mixed-group-38, groupId=batch-mixed-group] Node 0 sent an invalid full fetch response with extraIds=(dejevcBWRFSRlrIRhnDq_w), response=()
2025-12-18T15:26:21.777Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.777Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.777Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.777Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.777Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.777Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.777Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.777Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.778Z  INFO 53856 --- [tainer#10-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-test-group-39 unregistered
2025-12-18T15:26:21.778Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: Consumer stopped
2025-12-18T15:26:21.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-mixed-group-38 unregistered
2025-12-18T15:26:21.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: Consumer stopped
2025-12-18T15:26:21.795Z  INFO 53856 --- [tainer#21-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-multi-partition-dlq-collector-40, groupId=multi-partition-dlq-collector] Node 0 sent an invalid full fetch response with extraIds=(kCpLsZPcTBSS2axl2oKXYQ), response=()
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#13-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-string-group-43, groupId=string-group] Node 0 sent an invalid full fetch response with extraIds=(gQ0bBD3GRrGB9kU9vWgfNA), response=()
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.796Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#16-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42, groupId=replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5] Node 0 sent an invalid full fetch response with extraIds=(1mSEChBJSruNxrEhciHPeA), response=()
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#21-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-multi-partition-dlq-collector-40 unregistered
2025-12-18T15:26:21.797Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: Consumer stopped
2025-12-18T15:26:21.798Z  INFO 53856 --- [tainer#13-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-string-group-43 unregistered
2025-12-18T15:26:21.798Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: Consumer stopped
2025-12-18T15:26:21.798Z  INFO 53856 --- [tainer#16-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5-42 unregistered
2025-12-18T15:26:21.798Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-db14d6ac-58af-46f2-9808-423739d6d6b5: Consumer stopped
2025-12-18T15:26:21.801Z  INFO 53856 --- [tainer#14-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44, groupId=replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac] Node 0 sent an invalid full fetch response with extraIds=(y_hczy4FQsuz9g2sxEzjVg), response=()
2025-12-18T15:26:21.802Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.802Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.802Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.802Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.803Z  INFO 53856 --- [tainer#14-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac-44 unregistered
2025-12-18T15:26:21.803Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-d2ffcf0b-8900-4be9-849e-1298c3c51fac: Consumer stopped
2025-12-18T15:26:21.939Z  INFO 53856 --- [tainer#18-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33, groupId=replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576] Node 0 sent an invalid full fetch response with extraIds=(fL7glRmmQRGgkGnJGSJUbw), response=()
2025-12-18T15:26:21.939Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.939Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.939Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.939Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.941Z  INFO 53856 --- [tainer#18-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576-33 unregistered
2025-12-18T15:26:21.941Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-fd93a941-ae18-41b7-88f6-e0516e8d7576: Consumer stopped
2025-12-18T15:26:21.989Z  INFO 53856 --- [tainer#15-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41, groupId=replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e] Node 0 sent an invalid full fetch response with extraIds=(hJaU7gvERum1dT-KZ0d01A), response=()
2025-12-18T15:26:21.989Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.989Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.989Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.989Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.990Z  INFO 53856 --- [tainer#15-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e-41 unregistered
2025-12-18T15:26:21.990Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-4b4924bd-3932-40cc-9e83-a5b53473508e: Consumer stopped
2025-12-18T15:26:21.997Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:21.997Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:21.997Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:21.997Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:21.998Z  INFO 53856 --- [tainer#12-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-double-group-35 unregistered
2025-12-18T15:26:21.998Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: Consumer stopped
2025-12-18T15:26:22.015Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:22.015Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:22.015Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:22.015Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:22.017Z  INFO 53856 --- [tainer#11-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-dlq-group-34 unregistered
2025-12-18T15:26:22.017Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: Consumer stopped
2025-12-18T15:26:22.017Z  INFO 53856 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-12-18T15:26:22.018Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:22.018Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:22.018Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:22.018Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:22.018Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-2 unregistered
2025-12-18T15:26:22.020Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2025-12-18T15:26:22.020Z  INFO 53856 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2025-12-18T15:26:22.020Z  INFO 53856 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2025-12-18T15:26:22.020Z  INFO 53856 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2025-12-18T15:26:22.020Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-12-18T15:26:22.021Z  INFO 53856 --- [channel-manager] org.apache.kafka.clients.NetworkClient   : [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected.
2025-12-18T15:26:22.021Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-12-18T15:26:22.021Z  INFO 53856 --- [           main] kafka.server.KafkaRequestHandlerPool     : [data-plane Kafka Request Handler on Broker 0], shutting down
2025-12-18T15:26:22.021Z  INFO 53856 --- [           main] kafka.server.KafkaRequestHandlerPool     : [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-12-18T15:26:22.021Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Shutting down
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-12-18T15:26:22.022Z  INFO 53856 --- [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Stopped
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2025-12-18T15:26:22.022Z  INFO 53856 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Shutting down
2025-12-18T15:26:22.022Z  INFO 53856 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Stopped
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Shutdown completed
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2025-12-18T15:26:22.022Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-12-18T15:26:22.022Z  INFO 53856 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] k.server.ReplicaAlterLogDirsManager      : [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] k.server.ReplicaAlterLogDirsManager      : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-12-18T15:26:22.023Z  INFO 53856 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-12-18T15:26:22.023Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Shutting down
2025-12-18T15:26:22.024Z  INFO 53856 --- [r-0-ElectLeader] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Stopped
2025-12-18T15:26:22.024Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-12-18T15:26:22.027Z  INFO 53856 --- [           main] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Shutting down
2025-12-18T15:26:22.027Z  INFO 53856 --- [nSenderThread-0] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Stopped
2025-12-18T15:26:22.027Z  INFO 53856 --- [           main] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Shutdown completed
2025-12-18T15:26:22.027Z  INFO 53856 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2025-12-18T15:26:22.027Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down
2025-12-18T15:26:22.028Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] k.s.NodeToControllerChannelManagerImpl   : Node to controller channel manager for alter-partition shutdown
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed
2025-12-18T15:26:22.028Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] k.s.NodeToControllerChannelManagerImpl   : Node to controller channel manager for forwarding shutdown
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Shutting down.
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Shutting down
2025-12-18T15:26:22.028Z  INFO 53856 --- [           main] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Shutdown completed
2025-12-18T15:26:22.028Z  INFO 53856 --- [leaner-thread-0] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Stopped
2025-12-18T15:26:22.034Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-0] Wrote producer snapshot at offset 15 with 0 producer ids in 1 ms.
2025-12-18T15:26:22.040Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=double-topic-0] Wrote producer snapshot at offset 2 with 1 producer ids in 2 ms.
2025-12-18T15:26:22.084Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-3] Wrote producer snapshot at offset 4 with 0 producer ids in 1 ms.
2025-12-18T15:26:22.103Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=dlq-topic-0] Wrote producer snapshot at offset 1 with 1 producer ids in 2 ms.
2025-12-18T15:26:22.107Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 1 ms.
2025-12-18T15:26:22.119Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-1] Wrote producer snapshot at offset 10 with 0 producer ids in 1 ms.
2025-12-18T15:26:22.124Z  INFO 53856 --- [004736896207277] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-4] Wrote producer snapshot at offset 12 with 0 producer ids in 1 ms.
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2025-12-18T15:26:22.142Z  INFO 53856 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2025-12-18T15:26:22.142Z  INFO 53856 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2025-12-18T15:26:22.142Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2025-12-18T15:26:22.143Z  INFO 53856 --- [           main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2025-12-18T15:26:22.143Z  INFO 53856 --- [           main] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Shutting down
2025-12-18T15:26:22.143Z  INFO 53856 --- [-process-thread] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Stopped
2025-12-18T15:26:22.143Z  INFO 53856 --- [           main] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Shutdown completed
2025-12-18T15:26:22.143Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Closing.
2025-12-18T15:26:22.244Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000070def00000 closed
2025-12-18T15:26:22.244Z  INFO 53856 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000070def00000
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Closed.
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2025-12-18T15:26:22.245Z  INFO 53856 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2025-12-18T15:26:22.245Z  INFO 53856 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2025-12-18T15:26:22.245Z  INFO 53856 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-12-18T15:26:22.245Z  INFO 53856 --- [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-12-18T15:26:22.245Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] kafka.server.BrokerTopicStats            : Broker and topic stats closed
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.server for 0 unregistered
2025-12-18T15:26:22.249Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2025-12-18T15:26:22.251Z  INFO 53856 --- [nnectionExpirer] o.a.z.server.NIOServerCnxnFactory        : ConnnectionExpirerThread interrupted
2025-12-18T15:26:22.251Z  INFO 53856 --- [electorThread-1] o.a.z.server.NIOServerCnxnFactory        : selector thread exitted run method
2025-12-18T15:26:22.251Z  INFO 53856 --- [ad:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : accept thread exitted run method
2025-12-18T15:26:22.251Z  INFO 53856 --- [electorThread-0] o.a.z.server.NIOServerCnxnFactory        : selector thread exitted run method
2025-12-18T15:26:22.251Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2025-12-18T15:26:22.251Z  INFO 53856 --- [           main] o.a.zookeeper.server.RequestThrottler    : Shutting down
2025-12-18T15:26:22.251Z  INFO 53856 --- [equestThrottler] o.a.zookeeper.server.RequestThrottler    : Draining request throttler queue
2025-12-18T15:26:22.251Z  INFO 53856 --- [equestThrottler] o.a.zookeeper.server.RequestThrottler    : RequestThrottler shutdown. Dropped 0 requests
2025-12-18T15:26:22.251Z  INFO 53856 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2025-12-18T15:26:22.251Z  INFO 53856 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2025-12-18T15:26:22.252Z  INFO 53856 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2025-12-18T15:26:22.252Z  INFO 53856 --- [0 cport:40937):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2025-12-18T15:26:22.252Z  INFO 53856 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2025-12-18T15:26:22.252Z  INFO 53856 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.7)

2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : zookeeper.snapshot.trust.empty : false
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.watch.WatchManagerFactory   : Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.watch.WatchManagerFactory   : Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : zookeeper.snapshotSizeFactor = 0.33
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : zookeeper.commitLogCount=500
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to 1600 ms
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to 16000 ms
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.apache.zookeeper.server.ResponseCache  : getData response cache size is initialized with value 400.
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.apache.zookeeper.server.ResponseCache  : getChildren response cache size is initialized with value 400.
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.slotCapacity = 60
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.slotDuration = 15
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.maxDepth = 6
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.initialDelay = 5
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.delay = 5
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.s.u.RequestPathMetricsCollector    : zookeeper.pathStats.enabled = false
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : The max bytes for all large requests are set to 104857600
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : The large request threshold is set to -1
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.AuthenticationHelper        : zookeeper.enforce.auth.enabled = false
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.AuthenticationHelper        : zookeeper.enforce.auth.schemes = []
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Created server with tickTime 800 ms minSessionTimeout 1600 ms maxSessionTimeout 16000 ms clientPortListenBacklog -1 datadir /tmp/kafka-3611343496011690408/version-2 snapdir /tmp/kafka-9788194278031089158/version-2
2025-12-18T15:26:22.267Z  WARN 53856 --- [           main] o.a.zookeeper.server.ServerCnxnFactory   : maxCnxns is not configured, using default value 0.
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.NIOServerCnxnFactory        : Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.NIOServerCnxnFactory        : binding to port /127.0.0.1:0
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : Snapshotting: 0x0 to /tmp/kafka-9788194278031089158/version-2/snapshot.0
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] org.apache.zookeeper.server.ZKDatabase   : Snapshot loaded in 0 ms, highest zxid is 0x0, digest is 1371985504
2025-12-18T15:26:22.267Z  INFO 53856 --- [           main] o.a.z.server.persistence.FileTxnSnapLog  : Snapshotting: 0x0 to /tmp/kafka-9788194278031089158/version-2/snapshot.0
2025-12-18T15:26:22.268Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : Snapshot taken in 0 ms
2025-12-18T15:26:22.268Z  INFO 53856 --- [0 cport:43887):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-12-18T15:26:22.269Z  INFO 53856 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 100
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:43887
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : starting
2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:43887
2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:43887.
2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:43887 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@119d21ce
2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] org.apache.zookeeper.ClientCnxnSocket    : jute.maxbuffer value is 4194304 Bytes
2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] org.apache.zookeeper.ClientCnxn          : zookeeper.request.timeout value is 0. feature enabled=false
2025-12-18T15:26:22.270Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Waiting until connected.
2025-12-18T15:26:22.270Z  INFO 53856 --- [27.0.0.1:43887)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server /127.0.0.1:43887.
2025-12-18T15:26:22.270Z  INFO 53856 --- [27.0.0.1:43887)] org.apache.zookeeper.ClientCnxn          : Socket connection established, initiating session, client: /127.0.0.1:48278, server: /127.0.0.1:43887
2025-12-18T15:26:22.271Z  INFO 53856 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2025-12-18T15:26:22.272Z  INFO 53856 --- [27.0.0.1:43887)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server /127.0.0.1:43887, session id = 0x1000070e5240000, negotiated timeout = 16000
2025-12-18T15:26:22.272Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Connected.
2025-12-18T15:26:22.284Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : Cluster ID = q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.286Z  INFO 53856 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 100
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:43887
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-12-18T15:26:22.289Z  INFO 53856 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Starting
2025-12-18T15:26:22.289Z  INFO 53856 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Starting
2025-12-18T15:26:22.289Z  INFO 53856 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Starting
2025-12-18T15:26:22.290Z  INFO 53856 --- [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Starting
2025-12-18T15:26:22.290Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Rewriting /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/meta.properties
2025-12-18T15:26:22.294Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Loading logs from log dirs ArrayBuffer(/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163)
2025-12-18T15:26:22.294Z  INFO 53856 --- [           main] kafka.log.LogManager                     : No logs found to be loaded in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163
2025-12-18T15:26:22.295Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Loaded 0 logs in 0ms
2025-12-18T15:26:22.295Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2025-12-18T15:26:22.295Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2025-12-18T15:26:22.296Z  INFO 53856 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2025-12-18T15:26:22.296Z  INFO 53856 --- [leaner-thread-0] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Starting
2025-12-18T15:26:22.297Z  INFO 53856 --- [-process-thread] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Starting
2025-12-18T15:26:22.297Z  INFO 53856 --- [-process-thread] k.server.FinalizedFeatureChangeListener  : Feature ZK node at path: /feature does not exist
2025-12-18T15:26:22.298Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Starting
2025-12-18T15:26:22.309Z  INFO 53856 --- [           main] kafka.network.ConnectionQuotas           : Updated connection-accept-rate max connection creation rate to 2147483647
2025-12-18T15:26:22.309Z  INFO 53856 --- [           main] kafka.network.DataPlaneAcceptor          : Awaiting socket connections on localhost:46137.
2025-12-18T15:26:22.309Z  INFO 53856 --- [           main] kafka.network.DataPlaneAcceptor          : Opened wildcard endpoint localhost:46137
2025-12-18T15:26:22.310Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-12-18T15:26:22.310Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting
2025-12-18T15:26:22.311Z  INFO 53856 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Starting
2025-12-18T15:26:22.311Z  INFO 53856 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Starting
2025-12-18T15:26:22.311Z  INFO 53856 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Starting
2025-12-18T15:26:22.312Z  INFO 53856 --- [r-0-ElectLeader] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Starting
2025-12-18T15:26:22.312Z  INFO 53856 --- [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Starting
2025-12-18T15:26:22.312Z  INFO 53856 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2025-12-18T15:26:22.312Z  INFO 53856 --- [nSenderThread-0] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Starting
2025-12-18T15:26:22.313Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/0 (is it secure? false)
2025-12-18T15:26:22.314Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Stat of the created znode at /brokers/ids/0 is: 25,25,1766071582314,1766071582314,1,0,0,72058078918606848,204,0,25

2025-12-18T15:26:22.314Z  INFO 53856 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:46137, czxid (broker epoch): 25
2025-12-18T15:26:22.314Z  INFO 53856 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Starting
2025-12-18T15:26:22.315Z  INFO 53856 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Starting
2025-12-18T15:26:22.315Z  INFO 53856 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Starting
2025-12-18T15:26:22.315Z  INFO 53856 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Starting
2025-12-18T15:26:22.315Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Starting up.
2025-12-18T15:26:22.315Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Startup complete.
2025-12-18T15:26:22.316Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Starting up.
2025-12-18T15:26:22.316Z  INFO 53856 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Successfully created /controller_epoch with initial epoch 0
2025-12-18T15:26:22.316Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Startup complete.
2025-12-18T15:26:22.316Z  INFO 53856 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Starting
2025-12-18T15:26:22.316Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-12-18T15:26:22.317Z  INFO 53856 --- [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Starting
2025-12-18T15:26:22.317Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-12-18T15:26:22.317Z  INFO 53856 --- [ain-EventThread] k.server.FinalizedFeatureChangeListener  : Feature ZK node created at path: /feature
2025-12-18T15:26:22.318Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Registering handlers
2025-12-18T15:26:22.318Z  INFO 53856 --- [-process-thread] kafka.server.metadata.ZkMetadataCache    : [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0).
2025-12-18T15:26:22.318Z  INFO 53856 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2025-12-18T15:26:22.318Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Deleting log dir event notifications
2025-12-18T15:26:22.319Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Deleting isr change notifications
2025-12-18T15:26:22.319Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initializing controller context
2025-12-18T15:26:22.319Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-12-18T15:26:22.320Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Start processing authorizer futures
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] End processing authorizer futures
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Start processing enable request processing future
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] End processing enable request processing future
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582320
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] started
2025-12-18T15:26:22.320Z  INFO 53856 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [127.0.0.1:46137]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-12-18T15:26:22.321Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Starting
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Current list of topics in the cluster: HashSet()
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Fetching topic deletions in progress
2025-12-18T15:26:22.321Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.321Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.321Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582321
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] List of topics to be deleted: 
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] List of topics ineligible for deletion: 
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Initializing topic deletion manager
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.TopicDeletionManager    : [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Sending update metadata request
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Initializing replica state
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Initializing partition state
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-12-18T15:26:22.321Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Ready to serve as the new controller with epoch 1
2025-12-18T15:26:22.321Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Controller 0 connected to localhost:46137 (id: 0 rack: null) for sending state change requests
2025-12-18T15:26:22.322Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Partitions undergoing preferred replica election: 
2025-12-18T15:26:22.322Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Partitions that completed preferred replica election: 
2025-12-18T15:26:22.322Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-12-18T15:26:22.322Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Resuming preferred replica election for partitions: 
2025-12-18T15:26:22.322Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-12-18T15:26:22.322Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Starting the controller scheduler
2025-12-18T15:26:22.325Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic dlq-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.327Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(dlq-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(dlq-topic,Some(lJQMwcLtTnqAtmiIugB6sQ),Map(dlq-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.328Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for dlq-topic-0
2025-12-18T15:26:22.328Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition dlq-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.328Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.328Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.328Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic object-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.329Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition dlq-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.329Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.329Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.329Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.329Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2025-12-18T15:26:22.329Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(dlq-topic-0)
2025-12-18T15:26:22.329Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.331Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(object-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(object-topic,Some(Djrma0V1ST-mKHC25Apn0A),Map(object-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.331Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for object-topic-0
2025-12-18T15:26:22.331Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=dlq-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.331Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition object-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.331Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.331Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.331Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition dlq-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/dlq-topic-0 with properties {}
2025-12-18T15:26:22.331Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition dlq-topic-0 broker=0] No checkpointed highwatermark is found for partition dlq-topic-0
2025-12-18T15:26:22.331Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition dlq-topic-0 broker=0] Log loaded for partition dlq-topic-0 with initial high watermark 0
2025-12-18T15:26:22.331Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader dlq-topic-0 with topic id Some(lJQMwcLtTnqAtmiIugB6sQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.331Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic double-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.332Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition object-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.332Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.333Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.333Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.334Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(double-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(double-topic,Some(PMulsE5eQJy0iM_mHpdYHg),Map(double-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.334Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for double-topic-0
2025-12-18T15:26:22.334Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition double-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.334Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.334Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.334Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 5ms correlationId 1 from controller 0 for 1 partitions
2025-12-18T15:26:22.335Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic string-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.335Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-12-18T15:26:22.335Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 1 partitions
2025-12-18T15:26:22.336Z  INFO 53856 --- [quest-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(object-topic-0)
2025-12-18T15:26:22.336Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.336Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition double-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.336Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.336Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.336Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.337Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(string-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(string-topic,Some(UTbeNjIASAun7w4Jk6A4Iw),Map(string-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.337Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for string-topic-0
2025-12-18T15:26:22.337Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition string-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.337Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.337Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.337Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=object-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.338Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition object-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/object-topic-0 with properties {}
2025-12-18T15:26:22.338Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition object-topic-0 broker=0] No checkpointed highwatermark is found for partition object-topic-0
2025-12-18T15:26:22.338Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition object-topic-0 broker=0] Log loaded for partition object-topic-0 with initial high watermark 0
2025-12-18T15:26:22.338Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader object-topic-0 with topic id Some(Djrma0V1ST-mKHC25Apn0A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.340Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition string-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.340Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.340Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.341Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.342Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 3 from controller 0 for 1 partitions
2025-12-18T15:26:22.343Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-12-18T15:26:22.343Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 5 from controller 0 for 1 partitions
2025-12-18T15:26:22.344Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(double-topic-0)
2025-12-18T15:26:22.344Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.345Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=double-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.346Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition double-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/double-topic-0 with properties {}
2025-12-18T15:26:22.346Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition double-topic-0 broker=0] No checkpointed highwatermark is found for partition double-topic-0
2025-12-18T15:26:22.346Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition double-topic-0 broker=0] Log loaded for partition double-topic-0 with initial high watermark 0
2025-12-18T15:26:22.346Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader double-topic-0 with topic id Some(PMulsE5eQJy0iM_mHpdYHg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.350Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 5 from controller 0 for 1 partitions
2025-12-18T15:26:22.351Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 6
2025-12-18T15:26:22.351Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 7 from controller 0 for 1 partitions
2025-12-18T15:26:22.352Z  INFO 53856 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(string-topic-0)
2025-12-18T15:26:22.352Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 7 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.353Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=string-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.353Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition string-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/string-topic-0 with properties {}
2025-12-18T15:26:22.353Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition string-topic-0 broker=0] No checkpointed highwatermark is found for partition string-topic-0
2025-12-18T15:26:22.353Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition string-topic-0 broker=0] Log loaded for partition string-topic-0 with initial high watermark 0
2025-12-18T15:26:22.353Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader string-topic-0 with topic id Some(UTbeNjIASAun7w4Jk6A4Iw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.359Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 8ms correlationId 7 from controller 0 for 1 partitions
2025-12-18T15:26:22.359Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 8
2025-12-18T15:26:22.360Z  INFO 53856 --- [| adminclient-3] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-3 unregistered
2025-12-18T15:26:22.361Z  INFO 53856 --- [| adminclient-3] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:22.361Z  INFO 53856 --- [| adminclient-3] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:22.361Z  INFO 53856 --- [| adminclient-3] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:22.361Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : Starting TypeHandlingIntegrationTest using Java 25.0.1 with PID 53856 (started by sam-o-reilly in /home/sam-o-reilly/Downloads/java-damero)
2025-12-18T15:26:22.361Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : No active profile set, falling back to 1 default profile: "default"
2025-12-18T15:26:22.398Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:46137 (id: 0 rack: null)
2025-12-18T15:26:22.411Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:46137 (id: 0 rack: null)
2025-12-18T15:26:22.428Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'testEventProducerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=batchProcessingIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/BatchProcessingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'testEventProducerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testEventProducerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=conditionalDLQRoutingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/ConditionalDLQRoutingIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'dlqKafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=circuitBreakerIntegrationTest.TestConfig; factoryMethodName=dlqKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/CircuitBreakerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=dlqKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'consumerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=DLQReplayIntegrationTest.TestConfig; factoryMethodName=consumerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DLQReplayIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=consumerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:22.429Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=testKafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]]
2025-12-18T15:26:22.432Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'producerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=producerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:22.432Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=kafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:22.432Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'kafkaListenerContainerFactory' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=standaloneMultiPartitionTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/StandaloneMultiPartitionTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=kafkaListenerContainerFactory; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:22.432Z  INFO 53856 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'defaultKafkaTemplate' with a different definition: replacing [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=dameroKafkaListenerIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [net/damero/DameroKafkaListenerIntegrationTest$TestConfig.class]] with [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=typeHandlingIntegrationTest.TestConfig; factoryMethodName=defaultKafkaTemplate; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in net.damero.TypeHandlingIntegrationTest$TestConfig]
2025-12-18T15:26:22.439Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
2025-12-18T15:26:22.439Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-12-18T15:26:22.441Z  INFO 53856 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 1 ms. Found 0 Redis repository interfaces.
2025-12-18T15:26:22.473Z  WARN 53856 --- [           main] n.d.K.C.CustomKafkaAutoConfiguration     : ==> Redis not available - PluggableRedisCache using Caffeine in-memory cache. This is NOT recommended for multi-instance deployments. Add spring-boot-starter-data-redis dependency and configure Redis for production use.
2025-12-18T15:26:22.473Z  INFO 53856 --- [           main] n.d.Kafka.Config.PluggableRedisCache     : === PluggableRedisCache initialized with Caffeine backend ===
2025-12-18T15:26:22.473Z  INFO 53856 --- [           main] n.d.K.A.D.DuplicationManager             : Initializing DuplicationManager with 10 HOURS window (TTL: PT10H)
2025-12-18T15:26:22.473Z  INFO 53856 --- [           main] n.d.K.A.D.DuplicationManager             : DuplicationManager initialized. Max capacity: 50000000 entries
2025-12-18T15:26:22.474Z  INFO 53856 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : Inconsistent constructor declaration on bean with name 'circuitBreakerService': single autowire-marked constructor flagged as optional - this constructor is effectively required since there is no default constructor to fall back to: public net.damero.Kafka.Resilience.CircuitBreakerService(java.lang.Object)
2025-12-18T15:26:22.476Z  INFO 53856 --- [           main] n.d.K.T.OpenTelemetryTracingService      : OpenTelemetryTracingService initialized - distributed tracing enabled
2025-12-18T15:26:22.491Z  INFO 53856 --- [           main] org.reflections.Reflections              : Reflections took 6 ms to scan 2 urls, producing 20 keys and 496 values
2025-12-18T15:26:22.568Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-dlq-group-45
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.569Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.569Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.569Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.569Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582569
2025-12-18T15:26:22.570Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Subscribed to topic(s): test-dlq
2025-12-18T15:26:22.570Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-validation-dlq-group-46
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = validation-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.571Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.571Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.571Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.571Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582571
2025-12-18T15:26:22.571Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Subscribed to topic(s): validation-dlq
2025-12-18T15:26:22.572Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-timeout-dlq-group-47
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = timeout-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.572Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.573Z  INFO 53856 --- [quest-handler-4] kafka.zk.AdminZkClient                   : Creating topic test-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.573Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.573Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.573Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582573
2025-12-18T15:26:22.573Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Subscribed to topic(s): timeout-dlq
2025-12-18T15:26:22.574Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic validation-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.574Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-default-dlq-group-48
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = default-dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.574Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.575Z  WARN 53856 --- [ntainer#6-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.575Z  INFO 53856 --- [ntainer#6-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.575Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.575Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.575Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582575
2025-12-18T15:26:22.575Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Subscribed to topic(s): default-dlq
2025-12-18T15:26:22.576Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(test-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(test-dlq,Some(t-2m76HNSvOV2UUoljKd_w),Map(test-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.576Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for test-dlq-0
2025-12-18T15:26:22.576Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.576Z  INFO 53856 --- [quest-handler-2] kafka.zk.AdminZkClient                   : Creating topic timeout-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.576Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.576Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.576Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-window-group-49
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-window-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.576Z  WARN 53856 --- [ntainer#7-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {validation-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.576Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.576Z  INFO 53856 --- [ntainer#7-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.577Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-12-18T15:26:22.577Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.577Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.577Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582577
2025-12-18T15:26:22.577Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Subscribed to topic(s): batch-window-topic
2025-12-18T15:26:22.578Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic default-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.578Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.578Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.578Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.578Z  WARN 53856 --- [ntainer#8-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {timeout-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.578Z  INFO 53856 --- [ntainer#8-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.578Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.578Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 9 from controller 0 for 1 partitions
2025-12-18T15:26:22.578Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(test-dlq-0)
2025-12-18T15:26:22.578Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 9 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.578Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-circuit-breaker-group-50
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = circuit-breaker-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.579Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.580Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.580Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.580Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582580
2025-12-18T15:26:22.580Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(validation-dlq, timeout-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(validation-dlq,Some(p2R0ZcQURR-FMWrrKXs86w),Map(validation-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(timeout-dlq,Some(8JdRWC3XQIadKRmrzuwNiA),Map(timeout-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.580Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for validation-dlq-0,timeout-dlq-0
2025-12-18T15:26:22.580Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Subscribed to topic(s): circuit-breaker-topic
2025-12-18T15:26:22.580Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition validation-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.580Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition timeout-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.580Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.580Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.580Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=test-dlq-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.580Z  WARN 53856 --- [ntainer#9-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {default-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.580Z  INFO 53856 --- [ntainer#9-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.580Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition test-dlq-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/test-dlq-0 with properties {}
2025-12-18T15:26:22.580Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition test-dlq-0 broker=0] No checkpointed highwatermark is found for partition test-dlq-0
2025-12-18T15:26:22.581Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition test-dlq-0 broker=0] Log loaded for partition test-dlq-0 with initial high watermark 0
2025-12-18T15:26:22.581Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader test-dlq-0 with topic id Some(t-2m76HNSvOV2UUoljKd_w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.581Z  INFO 53856 --- [quest-handler-6] kafka.zk.AdminZkClient                   : Creating topic batch-window-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.581Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-circuit-breaker-dlq-tracker-51
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = circuit-breaker-dlq-tracker
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.581Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.582Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.583Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.583Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582582
2025-12-18T15:26:22.583Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Subscribed to topic(s): circuit-breaker-dlq
2025-12-18T15:26:22.583Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition validation-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.583Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition timeout-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.583Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.583Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic circuit-breaker-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.583Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:22.583Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.584Z  WARN 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-window-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.584Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-conditional-test-group-52
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = conditional-test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.584Z  INFO 53856 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.584Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.585Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 9 from controller 0 for 1 partitions
2025-12-18T15:26:22.585Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.585Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.585Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582585
2025-12-18T15:26:22.585Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Subscribed to topic(s): conditional-routing-test
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(__consumer_offsets, batch-window-topic, default-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(default-dlq,Some(iO3c8FF7RSeTA_wcXxLyLg),Map(default-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(__consumer_offsets,Some(6W5UTbEiTzar39O_JOA15w),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(batch-window-topic,Some(8IX-rd9sRqevd4nsC2ugaQ),Map(batch-window-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,default-dlq-0,__consumer_offsets-3,batch-window-topic-0,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition default-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-window-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.585Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic circuit-breaker-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.585Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 10
2025-12-18T15:26:22.585Z  WARN 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {circuit-breaker-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.585Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.585Z  INFO 53856 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.586Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 11 from controller 0 for 2 partitions
2025-12-18T15:26:22.586Z  INFO 53856 --- [quest-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(timeout-dlq-0, validation-dlq-0)
2025-12-18T15:26:22.586Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 11 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:22.586Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.586Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.587Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.587Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.587Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582587
2025-12-18T15:26:22.587Z  WARN 53856 --- [ntainer#4-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {circuit-breaker-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.587Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Subscribed to topic(s): replay-source-topic-6
2025-12-18T15:26:22.587Z  INFO 53856 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.588Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic conditional-routing-test with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.588Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=timeout-dlq-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.588Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition timeout-dlq-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/timeout-dlq-0 with properties {}
2025-12-18T15:26:22.588Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition timeout-dlq-0 broker=0] No checkpointed highwatermark is found for partition timeout-dlq-0
2025-12-18T15:26:22.588Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition timeout-dlq-0 broker=0] Log loaded for partition timeout-dlq-0 with initial high watermark 0
2025-12-18T15:26:22.588Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.588Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader timeout-dlq-0 with topic id Some(8JdRWC3XQIadKRmrzuwNiA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.589Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition default-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-window-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 7 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 7 partitions
2025-12-18T15:26:22.589Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.590Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.590Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.590Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582590
2025-12-18T15:26:22.590Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Subscribed to topic(s): replay-source-topic-4
2025-12-18T15:26:22.590Z  INFO 53856 --- [quest-handler-2] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-6 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.591Z  WARN 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {conditional-routing-test=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.591Z  INFO 53856 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.591Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(circuit-breaker-topic, circuit-breaker-dlq)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(circuit-breaker-topic,Some(6gPv_MqvRz6Q7bSZFV3Ybw),Map(circuit-breaker-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(circuit-breaker-dlq,Some(qzhLbQ6RS96bclhJleXNmQ),Map(circuit-breaker-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.591Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.591Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for circuit-breaker-topic-0,circuit-breaker-dlq-0
2025-12-18T15:26:22.591Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.591Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.591Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.591Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.591Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.592Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.592Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.592Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582592
2025-12-18T15:26:22.592Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Subscribed to topic(s): replay-source-topic-5
2025-12-18T15:26:22.592Z  WARN 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-6=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.592Z  INFO 53856 --- [tainer#19-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.593Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-4 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.593Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.593Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition circuit-breaker-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.593Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.593Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:22.593Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.593Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlq-group-56
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlq-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.593Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.594Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=validation-dlq-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.594Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(conditional-routing-test, replay-source-topic-6)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(conditional-routing-test,Some(znQmjjTxQhmwhBNaqVHKdg),Map(conditional-routing-test-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-6,Some(D9A8GAvdTMqoZ2RmBU8z_Q),Map(replay-source-topic-6-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.594Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for conditional-routing-test-0,replay-source-topic-6-0
2025-12-18T15:26:22.594Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition validation-dlq-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/validation-dlq-0 with properties {}
2025-12-18T15:26:22.594Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition conditional-routing-test-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.594Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition validation-dlq-0 broker=0] No checkpointed highwatermark is found for partition validation-dlq-0
2025-12-18T15:26:22.594Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-6-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.594Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.594Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.594Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-5 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.594Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition validation-dlq-0 broker=0] Log loaded for partition validation-dlq-0 with initial high watermark 0
2025-12-18T15:26:22.594Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.594Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582594
2025-12-18T15:26:22.594Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader validation-dlq-0 with topic id Some(p2R0ZcQURR-FMWrrKXs86w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.594Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.594Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Subscribed to topic(s): dlq-topic
2025-12-18T15:26:22.594Z  WARN 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-4=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.594Z  INFO 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.595Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-double-group-57
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = double-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.595Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.596Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition conditional-routing-test-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.596Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-6-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.596Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.596Z  WARN 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-5=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.596Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:22.596Z  INFO 53856 --- [tainer#18-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.596Z  INFO 53856 --- [tainer#11-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.596Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.596Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.596Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.596Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582596
2025-12-18T15:26:22.596Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-double-group-57, groupId=double-group] Subscribed to topic(s): double-topic
2025-12-18T15:26:22.597Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-4, replay-source-topic-5)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-5,Some(x9ErRYL5QW63oJyAvD-FoA),Map(replay-source-topic-5-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(replay-source-topic-4,Some(y2qyW70dQySL8FctBK30cQ),Map(replay-source-topic-4-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.597Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-5-0,replay-source-topic-4-0
2025-12-18T15:26:22.597Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-5-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.597Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-4-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.597Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.597Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-capacity-group-58
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-capacity-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.597Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.597Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.598Z  INFO 53856 --- [tainer#12-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-double-group-57, groupId=double-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.598Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.598Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.598Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582598
2025-12-18T15:26:22.598Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Subscribed to topic(s): batch-capacity-topic
2025-12-18T15:26:22.598Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 12ms correlationId 11 from controller 0 for 2 partitions
2025-12-18T15:26:22.599Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 12
2025-12-18T15:26:22.599Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-5-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.599Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-4-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.599Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.599Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:22.599Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-multi-partition-test-group-59
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = multi-partition-test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.599Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.599Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 13 from controller 0 for 7 partitions
2025-12-18T15:26:22.599Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.600Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.600Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.600Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582600
2025-12-18T15:26:22.600Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, default-dlq-0, __consumer_offsets-3, batch-window-topic-0, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2025-12-18T15:26:22.600Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 13 from controller 0 epoch 1 as part of the become-leader transition for 7 partitions
2025-12-18T15:26:22.600Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Subscribed to topic(s): multi-partition-topic
2025-12-18T15:26:22.601Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic batch-capacity-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.601Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-mixed-group-60
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-mixed-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.601Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.602Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-3, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.602Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.602Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.602Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582602
2025-12-18T15:26:22.602Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Subscribed to topic(s): batch-mixed-topic
2025-12-18T15:26:22.602Z  INFO 53856 --- [quest-handler-5] kafka.zk.AdminZkClient                   : Creating topic multi-partition-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.603Z  WARN 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-capacity-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.603Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:22.603Z  INFO 53856 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.603Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-12-18T15:26:22.603Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-12-18T15:26:22.603Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-3 with topic id Some(6W5UTbEiTzar39O_JOA15w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.603Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(batch-capacity-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(batch-capacity-topic,Some(SZVfIZVASLOCGY5j4PCb5w),Map(batch-capacity-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.603Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for batch-capacity-topic-0
2025-12-18T15:26:22.603Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-capacity-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.603Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.604Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.604Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-61
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.604Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.605Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.605Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.605Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582605
2025-12-18T15:26:22.605Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-61, groupId=test-group] Subscribed to topic(s): test-topic
2025-12-18T15:26:22.605Z  WARN 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {multi-partition-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.605Z  INFO 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.605Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-capacity-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.605Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.605Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.606Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.606Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic batch-mixed-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.607Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(multi-partition-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(multi-partition-topic,Some(8YnfQfAGQKOgdgiYW0xUOw),Map(multi-partition-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.607Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for multi-partition-topic-0
2025-12-18T15:26:22.607Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.607Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.607Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.607Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-multi-partition-dlq-collector-62
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = multi-partition-dlq-collector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.607Z  INFO 53856 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Creating topic test-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.607Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.608Z  WARN 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {batch-mixed-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.608Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.608Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.608Z  INFO 53856 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.608Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.608Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.608Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.608Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582608
2025-12-18T15:26:22.608Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.608Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Subscribed to topic(s): multi-partition-dlq
2025-12-18T15:26:22.609Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-2, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.609Z  WARN 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-61, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.609Z  INFO 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-61, groupId=test-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.609Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(batch-mixed-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(batch-mixed-topic,Some(LoAxAwZwTXqQwEX8H-HEvA),Map(batch-mixed-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.610Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for batch-mixed-topic-0
2025-12-18T15:26:22.610Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.610Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-mixed-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.610Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.610Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:22.610Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-12-18T15:26:22.610Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.610Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-12-18T15:26:22.610Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.610Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-2 with topic id Some(6W5UTbEiTzar39O_JOA15w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.611Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.611Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.611Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582611
2025-12-18T15:26:22.611Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Subscribed to topic(s): replay-source-topic-2
2025-12-18T15:26:22.611Z  INFO 53856 --- [quest-handler-7] kafka.zk.AdminZkClient                   : Creating topic multi-partition-dlq with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.611Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition batch-mixed-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.611Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.612Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.612Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.612Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.612Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.613Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.613Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.613Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582613
2025-12-18T15:26:22.613Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Subscribed to topic(s): replay-source-topic-3
2025-12-18T15:26:22.613Z  WARN 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {multi-partition-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.613Z  INFO 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.613Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(test-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(test-topic,Some(_GFIrNtDStOQpRbDofgQKw),Map(test-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.613Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for test-topic-0
2025-12-18T15:26:22.613Z  INFO 53856 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-2 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.613Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.613Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.614Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.614Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-string-group-65
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = string-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.614Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.619Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-4, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.619Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.619Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition test-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.619Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.619Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582619
2025-12-18T15:26:22.619Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.619Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-string-group-65, groupId=string-group] Subscribed to topic(s): string-topic
2025-12-18T15:26:22.619Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.619Z  WARN 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-2=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.619Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.619Z  INFO 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.619Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:22.620Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-12-18T15:26:22.620Z  INFO 53856 --- [quest-handler-5] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-3 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.620Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-12-18T15:26:22.620Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-4 with topic id Some(6W5UTbEiTzar39O_JOA15w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.621Z  INFO 53856 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46137]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-12-18T15:26:22.621Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.622Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(multi-partition-dlq, replay-source-topic-2)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-2,Some(HG8Q35XOS5S4RE15QbuWiQ),Map(replay-source-topic-2-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(multi-partition-dlq,Some(lt03hjY1Ty6zThbFc9yDmw),Map(multi-partition-dlq-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.622Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-2-0,multi-partition-dlq-0
2025-12-18T15:26:22.622Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-2-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.622Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-dlq-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.622Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.622Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.622Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.622Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582622
2025-12-18T15:26:22.622Z  INFO 53856 --- [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Subscribed to topic(s): replay-source-topic-1
2025-12-18T15:26:22.622Z  INFO 53856 --- [tainer#13-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-string-group-65, groupId=string-group] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.622Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.624Z  WARN 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-3=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.624Z  INFO 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.624Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-2-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.624Z  INFO 53856 --- [           main] net.damero.TypeHandlingIntegrationTest   : Started TypeHandlingIntegrationTest in 0.369 seconds (process running for 7.1)
2025-12-18T15:26:22.624Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition multi-partition-dlq-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.625Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.625Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-12-18T15:26:22.625Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.625Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-window-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.626Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition batch-window-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/batch-window-topic-0 with properties {}
2025-12-18T15:26:22.626Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition batch-window-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-window-topic-0
2025-12-18T15:26:22.626Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition batch-window-topic-0 broker=0] Log loaded for partition batch-window-topic-0 with initial high watermark 0
2025-12-18T15:26:22.626Z  INFO 53856 --- [quest-handler-3] kafka.zk.AdminZkClient                   : Creating topic replay-source-topic-1 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-12-18T15:26:22.626Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader batch-window-topic-0 with topic id Some(8IX-rd9sRqevd4nsC2ugaQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.626Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-3)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-3,Some(c6Cb20MURQKFpMaEiAknIA),Map(replay-source-topic-3-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.626Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-3-0
2025-12-18T15:26:22.626Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-3-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.626Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.627Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.628Z  WARN 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {replay-source-topic-1=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.628Z  INFO 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.628Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-3-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.628Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.628Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.628Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.629Z  INFO 53856 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:46137]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-12-18T15:26:22.629Z  INFO 53856 --- [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-12-18T15:26:22.629Z  INFO 53856 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-3] Instantiated an idempotent producer.
2025-12-18T15:26:22.630Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [HashSet(replay-source-topic-1)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(replay-source-topic-1,Some(W6ELF5NER9S-dahVIoltJA),Map(replay-source-topic-1-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-12-18T15:26:22.630Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for replay-source-topic-1-0
2025-12-18T15:26:22.630Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-1-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-12-18T15:26:22.630Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.630Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.630Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-12-18T15:26:22.630Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-12-18T15:26:22.630Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766071582630
2025-12-18T15:26:22.632Z  INFO 53856 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Cluster ID: q_FIvFdSQUy63dZpQzsehg
2025-12-18T15:26:22.633Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Changed partition replay-source-topic-1-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-12-18T15:26:22.633Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-12-18T15:26:22.633Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-12-18T15:26:22.633Z  INFO 53856 --- [er-event-thread] state.change.logger                      : [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-12-18T15:26:22.633Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-1, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.633Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:22.634Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-12-18T15:26:22.634Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-12-18T15:26:22.634Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-1 with topic id Some(6W5UTbEiTzar39O_JOA15w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.634Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=0, firstProducerId=0, size=1000) by writing to Zk with path version 1
2025-12-18T15:26:22.647Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=default-dlq-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.648Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition default-dlq-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/default-dlq-0 with properties {}
2025-12-18T15:26:22.648Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition default-dlq-0 broker=0] No checkpointed highwatermark is found for partition default-dlq-0
2025-12-18T15:26:22.648Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition default-dlq-0 broker=0] Log loaded for partition default-dlq-0 with initial high watermark 0
2025-12-18T15:26:22.648Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader default-dlq-0 with topic id Some(iO3c8FF7RSeTA_wcXxLyLg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.654Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=__consumer_offsets-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.654Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-12-18T15:26:22.654Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-12-18T15:26:22.654Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-12-18T15:26:22.654Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-0 with topic id Some(6W5UTbEiTzar39O_JOA15w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-12-18T15:26:22.659Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 60ms correlationId 13 from controller 0 for 7 partitions
2025-12-18T15:26:22.659Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:22.659Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:22.659Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:22.659Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:22.659Z  INFO 53856 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-12-18T15:26:22.660Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 7 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 14
2025-12-18T15:26:22.661Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 15 from controller 0 for 2 partitions
2025-12-18T15:26:22.661Z  INFO 53856 --- [quest-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(circuit-breaker-dlq-0, circuit-breaker-topic-0)
2025-12-18T15:26:22.661Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 15 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:22.663Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=circuit-breaker-dlq-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.663Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition circuit-breaker-dlq-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/circuit-breaker-dlq-0 with properties {}
2025-12-18T15:26:22.663Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition circuit-breaker-dlq-0 broker=0] No checkpointed highwatermark is found for partition circuit-breaker-dlq-0
2025-12-18T15:26:22.663Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition circuit-breaker-dlq-0 broker=0] Log loaded for partition circuit-breaker-dlq-0 with initial high watermark 0
2025-12-18T15:26:22.663Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader circuit-breaker-dlq-0 with topic id Some(qzhLbQ6RS96bclhJleXNmQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.669Z  INFO 53856 --- [quest-handler-7] kafka.log.UnifiedLog$                    : [LogLoader partition=circuit-breaker-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.669Z  INFO 53856 --- [quest-handler-7] kafka.log.LogManager                     : Created log for partition circuit-breaker-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/circuit-breaker-topic-0 with properties {}
2025-12-18T15:26:22.670Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition circuit-breaker-topic-0 broker=0] No checkpointed highwatermark is found for partition circuit-breaker-topic-0
2025-12-18T15:26:22.670Z  INFO 53856 --- [quest-handler-7] kafka.cluster.Partition                  : [Partition circuit-breaker-topic-0 broker=0] Log loaded for partition circuit-breaker-topic-0 with initial high watermark 0
2025-12-18T15:26:22.670Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Leader circuit-breaker-topic-0 with topic id Some(6gPv_MqvRz6Q7bSZFV3Ybw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.672Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.672Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] (Re-)joining group
2025-12-18T15:26:22.673Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-dlq-group in Empty state. Created a new member id consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb and request the member to rejoin with this id.
2025-12-18T15:26:22.674Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb
2025-12-18T15:26:22.674Z  INFO 53856 --- [quest-handler-7] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 13ms correlationId 15 from controller 0 for 2 partitions
2025-12-18T15:26:22.674Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] (Re-)joining group
2025-12-18T15:26:22.674Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb with group instance id None; client reason: need to re-join with the given member-id: consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb)
2025-12-18T15:26:22.674Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 16
2025-12-18T15:26:22.675Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group test-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:22.675Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 17 from controller 0 for 2 partitions
2025-12-18T15:26:22.675Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb', protocol='range'}
2025-12-18T15:26:22.675Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Finished assignment for group at generation 1: {consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb=Assignment(partitions=[test-dlq-0])}
2025-12-18T15:26:22.675Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-6-0, conditional-routing-test-0)
2025-12-18T15:26:22.675Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 17 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:22.676Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb for group test-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.677Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb', protocol='range'}
2025-12-18T15:26:22.677Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Notifying assignor about the new Assignment(partitions=[test-dlq-0])
2025-12-18T15:26:22.677Z  INFO 53856 --- [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Adding newly assigned partitions: test-dlq-0
2025-12-18T15:26:22.677Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-6-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.677Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition replay-source-topic-6-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/replay-source-topic-6-0 with properties {}
2025-12-18T15:26:22.677Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-6-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-6-0
2025-12-18T15:26:22.678Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-6-0 broker=0] Log loaded for partition replay-source-topic-6-0 with initial high watermark 0
2025-12-18T15:26:22.678Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader replay-source-topic-6-0 with topic id Some(D9A8GAvdTMqoZ2RmBU8z_Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.678Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Found no committed offset for partition test-dlq-0
2025-12-18T15:26:22.678Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Resetting offset for partition test-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.678Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: partitions assigned: [test-dlq-0]
2025-12-18T15:26:22.683Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=conditional-routing-test-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.683Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition conditional-routing-test-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/conditional-routing-test-0 with properties {}
2025-12-18T15:26:22.683Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition conditional-routing-test-0 broker=0] No checkpointed highwatermark is found for partition conditional-routing-test-0
2025-12-18T15:26:22.683Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition conditional-routing-test-0 broker=0] Log loaded for partition conditional-routing-test-0 with initial high watermark 0
2025-12-18T15:26:22.683Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader conditional-routing-test-0 with topic id Some(znQmjjTxQhmwhBNaqVHKdg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.685Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.685Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] (Re-)joining group
2025-12-18T15:26:22.686Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group validation-dlq-group in Empty state. Created a new member id consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1 and request the member to rejoin with this id.
2025-12-18T15:26:22.686Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1
2025-12-18T15:26:22.686Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] (Re-)joining group
2025-12-18T15:26:22.686Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group validation-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1 with group instance id None; client reason: need to re-join with the given member-id: consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1)
2025-12-18T15:26:22.687Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group validation-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:22.687Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1', protocol='range'}
2025-12-18T15:26:22.687Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Finished assignment for group at generation 1: {consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1=Assignment(partitions=[validation-dlq-0])}
2025-12-18T15:26:22.687Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1 for group validation-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.688Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1', protocol='range'}
2025-12-18T15:26:22.688Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Notifying assignor about the new Assignment(partitions=[validation-dlq-0])
2025-12-18T15:26:22.688Z  INFO 53856 --- [ntainer#7-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Adding newly assigned partitions: validation-dlq-0
2025-12-18T15:26:22.688Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Found no committed offset for partition validation-dlq-0
2025-12-18T15:26:22.689Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Resetting offset for partition validation-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.689Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: partitions assigned: [validation-dlq-0]
2025-12-18T15:26:22.689Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 14ms correlationId 17 from controller 0 for 2 partitions
2025-12-18T15:26:22.689Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 18
2025-12-18T15:26:22.690Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 19 from controller 0 for 2 partitions
2025-12-18T15:26:22.690Z  INFO 53856 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-5-0, replay-source-topic-4-0)
2025-12-18T15:26:22.690Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 19 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:22.691Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.691Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] (Re-)joining group
2025-12-18T15:26:22.691Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-5-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.691Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition replay-source-topic-5-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/replay-source-topic-5-0 with properties {}
2025-12-18T15:26:22.691Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition replay-source-topic-5-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-5-0
2025-12-18T15:26:22.692Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition replay-source-topic-5-0 broker=0] Log loaded for partition replay-source-topic-5-0 with initial high watermark 0
2025-12-18T15:26:22.692Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader replay-source-topic-5-0 with topic id Some(x9ErRYL5QW63oJyAvD-FoA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.692Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group timeout-dlq-group in Empty state. Created a new member id consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e and request the member to rejoin with this id.
2025-12-18T15:26:22.692Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e
2025-12-18T15:26:22.692Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] (Re-)joining group
2025-12-18T15:26:22.692Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.692Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group timeout-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e with group instance id None; client reason: need to re-join with the given member-id: consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e)
2025-12-18T15:26:22.693Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] (Re-)joining group
2025-12-18T15:26:22.693Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group timeout-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:22.693Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e', protocol='range'}
2025-12-18T15:26:22.693Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Finished assignment for group at generation 1: {consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e=Assignment(partitions=[timeout-dlq-0])}
2025-12-18T15:26:22.693Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-window-group in Empty state. Created a new member id consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff and request the member to rejoin with this id.
2025-12-18T15:26:22.693Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff
2025-12-18T15:26:22.693Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] (Re-)joining group
2025-12-18T15:26:22.693Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e for group timeout-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.694Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-window-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff)
2025-12-18T15:26:22.694Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-window-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:22.694Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff', protocol='range'}
2025-12-18T15:26:22.694Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Finished assignment for group at generation 1: {consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff=Assignment(partitions=[batch-window-topic-0])}
2025-12-18T15:26:22.694Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e', protocol='range'}
2025-12-18T15:26:22.694Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Notifying assignor about the new Assignment(partitions=[timeout-dlq-0])
2025-12-18T15:26:22.694Z  INFO 53856 --- [ntainer#8-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Adding newly assigned partitions: timeout-dlq-0
2025-12-18T15:26:22.694Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff for group batch-window-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Found no committed offset for partition timeout-dlq-0
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] (Re-)joining group
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Resetting offset for partition timeout-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: partitions assigned: [timeout-dlq-0]
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff', protocol='range'}
2025-12-18T15:26:22.695Z  WARN 53856 --- [tainer#17-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-4=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Notifying assignor about the new Assignment(partitions=[batch-window-topic-0])
2025-12-18T15:26:22.695Z  INFO 53856 --- [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Adding newly assigned partitions: batch-window-topic-0
2025-12-18T15:26:22.695Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.696Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group default-dlq-group in Empty state. Created a new member id consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe and request the member to rejoin with this id.
2025-12-18T15:26:22.696Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Found no committed offset for partition batch-window-topic-0
2025-12-18T15:26:22.696Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe
2025-12-18T15:26:22.696Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] (Re-)joining group
2025-12-18T15:26:22.696Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] (Re-)joining group
2025-12-18T15:26:22.696Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group default-dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe with group instance id None; client reason: need to re-join with the given member-id: consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe)
2025-12-18T15:26:22.696Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Resetting offset for partition batch-window-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.696Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: partitions assigned: [batch-window-topic-0]
2025-12-18T15:26:22.696Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 in Empty state. Created a new member id consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994 and request the member to rejoin with this id.
2025-12-18T15:26:22.696Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group default-dlq-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:22.696Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994
2025-12-18T15:26:22.696Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] (Re-)joining group
2025-12-18T15:26:22.697Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe', protocol='range'}
2025-12-18T15:26:22.697Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Finished assignment for group at generation 1: {consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe=Assignment(partitions=[default-dlq-0])}
2025-12-18T15:26:22.697Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994)
2025-12-18T15:26:22.697Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe for group default-dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.697Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:22.697Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994', protocol='range'}
2025-12-18T15:26:22.697Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe', protocol='range'}
2025-12-18T15:26:22.697Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Notifying assignor about the new Assignment(partitions=[default-dlq-0])
2025-12-18T15:26:22.698Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-4-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.698Z  INFO 53856 --- [ntainer#9-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Adding newly assigned partitions: default-dlq-0
2025-12-18T15:26:22.698Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition replay-source-topic-4-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/replay-source-topic-4-0 with properties {}
2025-12-18T15:26:22.698Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition replay-source-topic-4-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-4-0
2025-12-18T15:26:22.698Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Found no committed offset for partition default-dlq-0
2025-12-18T15:26:22.698Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition replay-source-topic-4-0 broker=0] Log loaded for partition replay-source-topic-4-0 with initial high watermark 0
2025-12-18T15:26:22.698Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader replay-source-topic-4-0 with topic id Some(y2qyW70dQySL8FctBK30cQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.698Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Resetting offset for partition default-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.698Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: partitions assigned: [default-dlq-0]
2025-12-18T15:26:22.702Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 12ms correlationId 19 from controller 0 for 2 partitions
2025-12-18T15:26:22.703Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 20
2025-12-18T15:26:22.704Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 21 from controller 0 for 1 partitions
2025-12-18T15:26:22.704Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.704Z  INFO 53856 --- [quest-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(batch-capacity-topic-0)
2025-12-18T15:26:22.704Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.704Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 21 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.704Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] (Re-)joining group
2025-12-18T15:26:22.704Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] (Re-)joining group
2025-12-18T15:26:22.705Z  WARN 53856 --- [tainer#20-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {multi-partition-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.705Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group circuit-breaker-group in Empty state. Created a new member id consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933 and request the member to rejoin with this id.
2025-12-18T15:26:22.705Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group circuit-breaker-dlq-tracker in Empty state. Created a new member id consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48 and request the member to rejoin with this id.
2025-12-18T15:26:22.705Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Request joining group due to: need to re-join with the given member-id: consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48
2025-12-18T15:26:22.705Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] (Re-)joining group
2025-12-18T15:26:22.705Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Request joining group due to: need to re-join with the given member-id: consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933
2025-12-18T15:26:22.705Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.705Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] (Re-)joining group
2025-12-18T15:26:22.705Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.705Z  INFO 53856 --- [quest-handler-4] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-capacity-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.705Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-dlq-tracker in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48 with group instance id None; client reason: need to re-join with the given member-id: consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48)
2025-12-18T15:26:22.706Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] (Re-)joining group
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933 with group instance id None; client reason: need to re-join with the given member-id: consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933)
2025-12-18T15:26:22.706Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] (Re-)joining group
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-4] kafka.log.LogManager                     : Created log for partition batch-capacity-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/batch-capacity-topic-0 with properties {}
2025-12-18T15:26:22.706Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group circuit-breaker-dlq-tracker generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition batch-capacity-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-capacity-topic-0
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-4] kafka.cluster.Partition                  : [Partition batch-capacity-topic-0 broker=0] Log loaded for partition batch-capacity-topic-0 with initial high watermark 0
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Leader batch-capacity-topic-0 with topic id Some(SZVfIZVASLOCGY5j4PCb5w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.706Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group circuit-breaker-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:22.706Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Successfully joined group with generation Generation{generationId=1, memberId='consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48', protocol='range'}
2025-12-18T15:26:22.706Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933', protocol='range'}
2025-12-18T15:26:22.706Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Finished assignment for group at generation 1: {consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48=Assignment(partitions=[circuit-breaker-dlq-0])}
2025-12-18T15:26:22.706Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Finished assignment for group at generation 1: {consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933=Assignment(partitions=[circuit-breaker-topic-0])}
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48 for group circuit-breaker-dlq-tracker for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933 for group circuit-breaker-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group multi-partition-test-group in Empty state. Created a new member id consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8 and request the member to rejoin with this id.
2025-12-18T15:26:22.707Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Request joining group due to: need to re-join with the given member-id: consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8
2025-12-18T15:26:22.707Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] (Re-)joining group
2025-12-18T15:26:22.706Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a in Empty state. Created a new member id consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064 and request the member to rejoin with this id.
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Successfully synced group in generation Generation{generationId=1, memberId='consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48', protocol='range'}
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933', protocol='range'}
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Notifying assignor about the new Assignment(partitions=[circuit-breaker-dlq-0])
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Adding newly assigned partitions: circuit-breaker-dlq-0
2025-12-18T15:26:22.707Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8 with group instance id None; client reason: need to re-join with the given member-id: consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8)
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Notifying assignor about the new Assignment(partitions=[circuit-breaker-topic-0])
2025-12-18T15:26:22.707Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Adding newly assigned partitions: circuit-breaker-topic-0
2025-12-18T15:26:22.707Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] (Re-)joining group
2025-12-18T15:26:22.707Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group multi-partition-test-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:22.707Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064)
2025-12-18T15:26:22.707Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8', protocol='range'}
2025-12-18T15:26:22.707Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Found no committed offset for partition circuit-breaker-dlq-0
2025-12-18T15:26:22.708Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a generation 1 (__consumer_offsets-3) with 1 members
2025-12-18T15:26:22.708Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Found no committed offset for partition circuit-breaker-topic-0
2025-12-18T15:26:22.708Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064', protocol='range'}
2025-12-18T15:26:22.708Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Resetting offset for partition circuit-breaker-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.708Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: partitions assigned: [circuit-breaker-dlq-0]
2025-12-18T15:26:22.708Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Finished assignment for group at generation 1: {consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064=Assignment(partitions=[replay-source-topic-6-0])}
2025-12-18T15:26:22.708Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Resetting offset for partition circuit-breaker-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.708Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: partitions assigned: [circuit-breaker-topic-0]
2025-12-18T15:26:22.708Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064 for group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.709Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.709Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064', protocol='range'}
2025-12-18T15:26:22.709Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] (Re-)joining group
2025-12-18T15:26:22.709Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Notifying assignor about the new Assignment(partitions=[replay-source-topic-6-0])
2025-12-18T15:26:22.709Z  INFO 53856 --- [tainer#19-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Adding newly assigned partitions: replay-source-topic-6-0
2025-12-18T15:26:22.710Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Found no committed offset for partition replay-source-topic-6-0
2025-12-18T15:26:22.710Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group conditional-test-group in Empty state. Created a new member id consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517 and request the member to rejoin with this id.
2025-12-18T15:26:22.710Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Request joining group due to: need to re-join with the given member-id: consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517
2025-12-18T15:26:22.710Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] (Re-)joining group
2025-12-18T15:26:22.710Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Resetting offset for partition replay-source-topic-6-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.710Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a: partitions assigned: [replay-source-topic-6-0]
2025-12-18T15:26:22.710Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 6ms correlationId 21 from controller 0 for 1 partitions
2025-12-18T15:26:22.710Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group conditional-test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517 with group instance id None; client reason: need to re-join with the given member-id: consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517)
2025-12-18T15:26:22.710Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group conditional-test-group generation 1 (__consumer_offsets-4) with 1 members
2025-12-18T15:26:22.711Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517', protocol='range'}
2025-12-18T15:26:22.711Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 22
2025-12-18T15:26:22.711Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.711Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.711Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Finished assignment for group at generation 1: {consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517=Assignment(partitions=[conditional-routing-test-0])}
2025-12-18T15:26:22.711Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 23 from controller 0 for 1 partitions
2025-12-18T15:26:22.711Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] (Re-)joining group
2025-12-18T15:26:22.711Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517 for group conditional-test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.711Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] (Re-)joining group
2025-12-18T15:26:22.711Z  INFO 53856 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-partition-topic-0)
2025-12-18T15:26:22.711Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 23 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.712Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517', protocol='range'}
2025-12-18T15:26:22.712Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group dlq-group in Empty state. Created a new member id consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7 and request the member to rejoin with this id.
2025-12-18T15:26:22.712Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Notifying assignor about the new Assignment(partitions=[conditional-routing-test-0])
2025-12-18T15:26:22.712Z  INFO 53856 --- [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Adding newly assigned partitions: conditional-routing-test-0
2025-12-18T15:26:22.712Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Request joining group due to: need to re-join with the given member-id: consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7
2025-12-18T15:26:22.712Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 in Empty state. Created a new member id consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620 and request the member to rejoin with this id.
2025-12-18T15:26:22.712Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] (Re-)joining group
2025-12-18T15:26:22.712Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620
2025-12-18T15:26:22.712Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] (Re-)joining group
2025-12-18T15:26:22.712Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group dlq-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7 with group instance id None; client reason: need to re-join with the given member-id: consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7)
2025-12-18T15:26:22.712Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Found no committed offset for partition conditional-routing-test-0
2025-12-18T15:26:22.712Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group dlq-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:22.712Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620)
2025-12-18T15:26:22.713Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7', protocol='range'}
2025-12-18T15:26:22.713Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:22.713Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Finished assignment for group at generation 1: {consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7=Assignment(partitions=[dlq-topic-0])}
2025-12-18T15:26:22.713Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Resetting offset for partition conditional-routing-test-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.713Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: partitions assigned: [conditional-routing-test-0]
2025-12-18T15:26:22.713Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620', protocol='range'}
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7 for group dlq-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.713Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Finished assignment for group at generation 1: {consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620=Assignment(partitions=[replay-source-topic-5-0])}
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-1] kafka.log.UnifiedLog$                    : [LogLoader partition=multi-partition-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition multi-partition-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/multi-partition-topic-0 with properties {}
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620 for group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition multi-partition-topic-0 broker=0] No checkpointed highwatermark is found for partition multi-partition-topic-0
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition multi-partition-topic-0 broker=0] Log loaded for partition multi-partition-topic-0 with initial high watermark 0
2025-12-18T15:26:22.713Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Leader multi-partition-topic-0 with topic id Some(8YnfQfAGQKOgdgiYW0xUOw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.713Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620', protocol='range'}
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7', protocol='range'}
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Notifying assignor about the new Assignment(partitions=[replay-source-topic-5-0])
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Notifying assignor about the new Assignment(partitions=[dlq-topic-0])
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#18-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Adding newly assigned partitions: replay-source-topic-5-0
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#11-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Adding newly assigned partitions: dlq-topic-0
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] (Re-)joining group
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Found no committed offset for partition dlq-topic-0
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Found no committed offset for partition replay-source-topic-5-0
2025-12-18T15:26:22.714Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Resetting offset for partition dlq-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: partitions assigned: [dlq-topic-0]
2025-12-18T15:26:22.715Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group double-group in Empty state. Created a new member id consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e and request the member to rejoin with this id.
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Request joining group due to: need to re-join with the given member-id: consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] (Re-)joining group
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Resetting offset for partition replay-source-topic-5-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2: partitions assigned: [replay-source-topic-5-0]
2025-12-18T15:26:22.715Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group double-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e with group instance id None; client reason: need to re-join with the given member-id: consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e)
2025-12-18T15:26:22.715Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group double-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e', protocol='range'}
2025-12-18T15:26:22.715Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Finished assignment for group at generation 1: {consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e=Assignment(partitions=[double-topic-0])}
2025-12-18T15:26:22.716Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e for group double-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.716Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e', protocol='range'}
2025-12-18T15:26:22.716Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Notifying assignor about the new Assignment(partitions=[double-topic-0])
2025-12-18T15:26:22.716Z  INFO 53856 --- [tainer#12-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-double-group-57, groupId=double-group] Adding newly assigned partitions: double-topic-0
2025-12-18T15:26:22.716Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Found no committed offset for partition double-topic-0
2025-12-18T15:26:22.717Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-double-group-57, groupId=double-group] Resetting offset for partition double-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.717Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: partitions assigned: [double-topic-0]
2025-12-18T15:26:22.718Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 23 from controller 0 for 1 partitions
2025-12-18T15:26:22.718Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 24
2025-12-18T15:26:22.719Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 25 from controller 0 for 1 partitions
2025-12-18T15:26:22.719Z  INFO 53856 --- [quest-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(batch-mixed-topic-0)
2025-12-18T15:26:22.719Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 25 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.720Z  INFO 53856 --- [quest-handler-5] kafka.log.UnifiedLog$                    : [LogLoader partition=batch-mixed-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.720Z  INFO 53856 --- [quest-handler-5] kafka.log.LogManager                     : Created log for partition batch-mixed-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/batch-mixed-topic-0 with properties {}
2025-12-18T15:26:22.721Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition batch-mixed-topic-0 broker=0] No checkpointed highwatermark is found for partition batch-mixed-topic-0
2025-12-18T15:26:22.721Z  INFO 53856 --- [quest-handler-5] kafka.cluster.Partition                  : [Partition batch-mixed-topic-0 broker=0] Log loaded for partition batch-mixed-topic-0 with initial high watermark 0
2025-12-18T15:26:22.721Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Leader batch-mixed-topic-0 with topic id Some(LoAxAwZwTXqQwEX8H-HEvA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.723Z  WARN 53856 --- [tainer#10-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-61, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {test-topic=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.723Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.723Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.724Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] (Re-)joining group
2025-12-18T15:26:22.724Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] (Re-)joining group
2025-12-18T15:26:22.725Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-group in Empty state. Created a new member id consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6 and request the member to rejoin with this id.
2025-12-18T15:26:22.725Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-capacity-group in Empty state. Created a new member id consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f and request the member to rejoin with this id.
2025-12-18T15:26:22.725Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6
2025-12-18T15:26:22.725Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f
2025-12-18T15:26:22.725Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] (Re-)joining group
2025-12-18T15:26:22.725Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] (Re-)joining group
2025-12-18T15:26:22.725Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 6ms correlationId 25 from controller 0 for 1 partitions
2025-12-18T15:26:22.725Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-capacity-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f)
2025-12-18T15:26:22.725Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6 with group instance id None; client reason: need to re-join with the given member-id: consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6)
2025-12-18T15:26:22.725Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-capacity-group generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:22.725Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group test-group generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:22.725Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f', protocol='range'}
2025-12-18T15:26:22.726Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6', protocol='range'}
2025-12-18T15:26:22.726Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 26
2025-12-18T15:26:22.726Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Finished assignment for group at generation 1: {consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f=Assignment(partitions=[batch-capacity-topic-0])}
2025-12-18T15:26:22.726Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f for group batch-capacity-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.726Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 27 from controller 0 for 1 partitions
2025-12-18T15:26:22.726Z  INFO 53856 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(test-topic-0)
2025-12-18T15:26:22.726Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 27 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.727Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f', protocol='range'}
2025-12-18T15:26:22.727Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Notifying assignor about the new Assignment(partitions=[batch-capacity-topic-0])
2025-12-18T15:26:22.727Z  INFO 53856 --- [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Adding newly assigned partitions: batch-capacity-topic-0
2025-12-18T15:26:22.727Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Found no committed offset for partition batch-capacity-topic-0
2025-12-18T15:26:22.728Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Resetting offset for partition batch-capacity-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.728Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: partitions assigned: [batch-capacity-topic-0]
2025-12-18T15:26:22.728Z  INFO 53856 --- [quest-handler-3] kafka.log.UnifiedLog$                    : [LogLoader partition=test-topic-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.728Z  INFO 53856 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition test-topic-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/test-topic-0 with properties {}
2025-12-18T15:26:22.729Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.729Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition test-topic-0 broker=0] No checkpointed highwatermark is found for partition test-topic-0
2025-12-18T15:26:22.729Z  INFO 53856 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0
2025-12-18T15:26:22.729Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Leader test-topic-0 with topic id Some(_GFIrNtDStOQpRbDofgQKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.729Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] (Re-)joining group
2025-12-18T15:26:22.729Z  WARN 53856 --- [tainer#21-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {multi-partition-dlq=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.730Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.730Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] (Re-)joining group
2025-12-18T15:26:22.730Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group batch-mixed-group in Empty state. Created a new member id consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2 and request the member to rejoin with this id.
2025-12-18T15:26:22.730Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Request joining group due to: need to re-join with the given member-id: consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2
2025-12-18T15:26:22.730Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] (Re-)joining group
2025-12-18T15:26:22.731Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group multi-partition-dlq-collector in Empty state. Created a new member id consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d and request the member to rejoin with this id.
2025-12-18T15:26:22.731Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-mixed-group in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2 with group instance id None; client reason: need to re-join with the given member-id: consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2)
2025-12-18T15:26:22.731Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Request joining group due to: need to re-join with the given member-id: consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d
2025-12-18T15:26:22.731Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] (Re-)joining group
2025-12-18T15:26:22.731Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group batch-mixed-group generation 1 (__consumer_offsets-0) with 1 members
2025-12-18T15:26:22.731Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-dlq-collector in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d with group instance id None; client reason: need to re-join with the given member-id: consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d)
2025-12-18T15:26:22.731Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2', protocol='range'}
2025-12-18T15:26:22.731Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group multi-partition-dlq-collector generation 1 (__consumer_offsets-3) with 1 members
2025-12-18T15:26:22.731Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Successfully joined group with generation Generation{generationId=1, memberId='consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d', protocol='range'}
2025-12-18T15:26:22.731Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Finished assignment for group at generation 1: {consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2=Assignment(partitions=[batch-mixed-topic-0])}
2025-12-18T15:26:22.731Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2 for group batch-mixed-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.732Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2', protocol='range'}
2025-12-18T15:26:22.732Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Notifying assignor about the new Assignment(partitions=[batch-mixed-topic-0])
2025-12-18T15:26:22.732Z  INFO 53856 --- [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Adding newly assigned partitions: batch-mixed-topic-0
2025-12-18T15:26:22.733Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Found no committed offset for partition batch-mixed-topic-0
2025-12-18T15:26:22.733Z  INFO 53856 --- [quest-handler-3] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 7ms correlationId 27 from controller 0 for 1 partitions
2025-12-18T15:26:22.733Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Resetting offset for partition batch-mixed-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.733Z  WARN 53856 --- [tainer#15-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-2=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.733Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: partitions assigned: [batch-mixed-topic-0]
2025-12-18T15:26:22.733Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 28
2025-12-18T15:26:22.733Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.734Z  INFO 53856 --- [ad | producer-3] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-3] ProducerId set to 0 with epoch 0
2025-12-18T15:26:22.734Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] (Re-)joining group
2025-12-18T15:26:22.734Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 29 from controller 0 for 2 partitions
2025-12-18T15:26:22.734Z  INFO 53856 --- [quest-handler-2] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-2-0, multi-partition-dlq-0)
2025-12-18T15:26:22.734Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 29 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac in Empty state. Created a new member id consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b and request the member to rejoin with this id.
2025-12-18T15:26:22.735Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b
2025-12-18T15:26:22.735Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] (Re-)joining group
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-2] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-2-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b)
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-2] kafka.log.LogManager                     : Created log for partition replay-source-topic-2-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/replay-source-topic-2-0 with properties {}
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition replay-source-topic-2-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-2-0
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition replay-source-topic-2-0 broker=0] Log loaded for partition replay-source-topic-2-0 with initial high watermark 0
2025-12-18T15:26:22.735Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Leader replay-source-topic-2-0 with topic id Some(HG8Q35XOS5S4RE15QbuWiQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.735Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:22.736Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b', protocol='range'}
2025-12-18T15:26:22.741Z  INFO 53856 --- [quest-handler-2] kafka.log.UnifiedLog$                    : [LogLoader partition=multi-partition-dlq-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.741Z  INFO 53856 --- [quest-handler-2] kafka.log.LogManager                     : Created log for partition multi-partition-dlq-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/multi-partition-dlq-0 with properties {}
2025-12-18T15:26:22.741Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition multi-partition-dlq-0 broker=0] No checkpointed highwatermark is found for partition multi-partition-dlq-0
2025-12-18T15:26:22.741Z  INFO 53856 --- [quest-handler-2] kafka.cluster.Partition                  : [Partition multi-partition-dlq-0 broker=0] Log loaded for partition multi-partition-dlq-0 with initial high watermark 0
2025-12-18T15:26:22.741Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Leader multi-partition-dlq-0 with topic id Some(lt03hjY1Ty6zThbFc9yDmw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.743Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.743Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] (Re-)joining group
2025-12-18T15:26:22.743Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group string-group in Empty state. Created a new member id consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072 and request the member to rejoin with this id.
2025-12-18T15:26:22.744Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Request joining group due to: need to re-join with the given member-id: consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072
2025-12-18T15:26:22.744Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] (Re-)joining group
2025-12-18T15:26:22.744Z  INFO 53856 --- [quest-handler-2] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 10ms correlationId 29 from controller 0 for 2 partitions
2025-12-18T15:26:22.744Z  WARN 53856 --- [tainer#16-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-3=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.744Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.744Z  INFO 53856 --- [quest-handler-1] state.change.logger                      : [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 30
2025-12-18T15:26:22.744Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group string-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072 with group instance id None; client reason: need to re-join with the given member-id: consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072)
2025-12-18T15:26:22.744Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] (Re-)joining group
2025-12-18T15:26:22.745Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group string-group generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:22.745Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 31 from controller 0 for 1 partitions
2025-12-18T15:26:22.745Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072', protocol='range'}
2025-12-18T15:26:22.745Z  INFO 53856 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-3-0)
2025-12-18T15:26:22.745Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 31 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.745Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Finished assignment for group at generation 1: {consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072=Assignment(partitions=[string-topic-0])}
2025-12-18T15:26:22.745Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072 for group string-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.745Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 in Empty state. Created a new member id consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92 and request the member to rejoin with this id.
2025-12-18T15:26:22.746Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92
2025-12-18T15:26:22.746Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] (Re-)joining group
2025-12-18T15:26:22.746Z  INFO 53856 --- [quest-handler-0] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-3-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.746Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072', protocol='range'}
2025-12-18T15:26:22.746Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92)
2025-12-18T15:26:22.746Z  INFO 53856 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition replay-source-topic-3-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/replay-source-topic-3-0 with properties {}
2025-12-18T15:26:22.746Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Notifying assignor about the new Assignment(partitions=[string-topic-0])
2025-12-18T15:26:22.746Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-3-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-3-0
2025-12-18T15:26:22.746Z  INFO 53856 --- [tainer#13-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-string-group-65, groupId=string-group] Adding newly assigned partitions: string-topic-0
2025-12-18T15:26:22.746Z  INFO 53856 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition replay-source-topic-3-0 broker=0] Log loaded for partition replay-source-topic-3-0 with initial high watermark 0
2025-12-18T15:26:22.746Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 generation 1 (__consumer_offsets-2) with 1 members
2025-12-18T15:26:22.746Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Leader replay-source-topic-3-0 with topic id Some(c6Cb20MURQKFpMaEiAknIA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.746Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92', protocol='range'}
2025-12-18T15:26:22.747Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Found no committed offset for partition string-topic-0
2025-12-18T15:26:22.747Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-string-group-65, groupId=string-group] Resetting offset for partition string-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.747Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: partitions assigned: [string-topic-0]
2025-12-18T15:26:22.749Z  WARN 53856 --- [tainer#14-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {replay-source-topic-1=LEADER_NOT_AVAILABLE}
2025-12-18T15:26:22.749Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Discovered group coordinator localhost:46137 (id: 2147483647 rack: null)
2025-12-18T15:26:22.750Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] (Re-)joining group
2025-12-18T15:26:22.751Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Dynamic member with unknown member id joins group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe in Empty state. Created a new member id consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905 and request the member to rejoin with this id.
2025-12-18T15:26:22.751Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Request joining group due to: need to re-join with the given member-id: consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905
2025-12-18T15:26:22.751Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] (Re-)joining group
2025-12-18T15:26:22.751Z  WARN 53856 --- [tainer#13-0-C-1] n.d.Kafka.Aspect.KafkaListenerAspect     : duplicate message detected for eventId: test-message - message was ignored
2025-12-18T15:26:22.751Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905 with group instance id None; client reason: need to re-join with the given member-id: consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905)
2025-12-18T15:26:22.752Z  INFO 53856 --- [quest-handler-0] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 6ms correlationId 31 from controller 0 for 1 partitions
2025-12-18T15:26:22.752Z  INFO 53856 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe generation 1 (__consumer_offsets-1) with 1 members
2025-12-18T15:26:22.752Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Successfully joined group with generation Generation{generationId=1, memberId='consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905', protocol='range'}
2025-12-18T15:26:22.752Z  INFO 53856 --- [quest-handler-4] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 32
2025-12-18T15:26:22.752Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Handling LeaderAndIsr request correlationId 33 from controller 0 for 1 partitions
2025-12-18T15:26:22.753Z  INFO 53856 --- [quest-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(replay-source-topic-1-0)
2025-12-18T15:26:22.753Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 33 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-12-18T15:26:22.755Z  INFO 53856 --- [quest-handler-6] kafka.log.UnifiedLog$                    : [LogLoader partition=replay-source-topic-1-0, dir=/tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163] Loading producer state till offset 0 with message format version 2
2025-12-18T15:26:22.755Z  INFO 53856 --- [quest-handler-6] kafka.log.LogManager                     : Created log for partition replay-source-topic-1-0 in /tmp/spring.kafka.06237b08-5f0e-44cd-be85-64488f4e0c2414711699360208319163/replay-source-topic-1-0 with properties {}
2025-12-18T15:26:22.755Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition replay-source-topic-1-0 broker=0] No checkpointed highwatermark is found for partition replay-source-topic-1-0
2025-12-18T15:26:22.755Z  INFO 53856 --- [quest-handler-6] kafka.cluster.Partition                  : [Partition replay-source-topic-1-0 broker=0] Log loaded for partition replay-source-topic-1-0 with initial high watermark 0
2025-12-18T15:26:22.755Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Leader replay-source-topic-1-0 with topic id Some(W6ELF5NER9S-dahVIoltJA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-12-18T15:26:22.760Z  INFO 53856 --- [quest-handler-6] state.change.logger                      : [Broker id=0] Finished LeaderAndIsr request in 8ms correlationId 33 from controller 0 for 1 partitions
2025-12-18T15:26:22.761Z  INFO 53856 --- [quest-handler-5] state.change.logger                      : [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 34
2025-12-18T15:26:22.776Z  INFO 53856 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2025-12-18T15:26:22.906Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Finished assignment for group at generation 1: {consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994=Assignment(partitions=[replay-source-topic-4-0])}
2025-12-18T15:26:22.906Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994 for group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.907Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994', protocol='range'}
2025-12-18T15:26:22.907Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Notifying assignor about the new Assignment(partitions=[replay-source-topic-4-0])
2025-12-18T15:26:22.907Z  INFO 53856 --- [tainer#17-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Adding newly assigned partitions: replay-source-topic-4-0
2025-12-18T15:26:22.908Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Found no committed offset for partition replay-source-topic-4-0
2025-12-18T15:26:22.908Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Resetting offset for partition replay-source-topic-4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.908Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157: partitions assigned: [replay-source-topic-4-0]
2025-12-18T15:26:22.909Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Finished assignment for group at generation 1: {consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8=Assignment(partitions=[multi-partition-topic-0])}
2025-12-18T15:26:22.909Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8 for group multi-partition-test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.910Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8', protocol='range'}
2025-12-18T15:26:22.910Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Notifying assignor about the new Assignment(partitions=[multi-partition-topic-0])
2025-12-18T15:26:22.910Z  INFO 53856 --- [tainer#20-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Adding newly assigned partitions: multi-partition-topic-0
2025-12-18T15:26:22.911Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Found no committed offset for partition multi-partition-topic-0
2025-12-18T15:26:22.911Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Resetting offset for partition multi-partition-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.911Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: partitions assigned: [multi-partition-topic-0]
2025-12-18T15:26:22.921Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Finished assignment for group at generation 1: {consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d=Assignment(partitions=[multi-partition-dlq-0])}
2025-12-18T15:26:22.922Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d for group multi-partition-dlq-collector for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.923Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Successfully synced group in generation Generation{generationId=1, memberId='consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d', protocol='range'}
2025-12-18T15:26:22.923Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Notifying assignor about the new Assignment(partitions=[multi-partition-dlq-0])
2025-12-18T15:26:22.923Z  INFO 53856 --- [tainer#21-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Adding newly assigned partitions: multi-partition-dlq-0
2025-12-18T15:26:22.923Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Found no committed offset for partition multi-partition-dlq-0
2025-12-18T15:26:22.924Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Resetting offset for partition multi-partition-dlq-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.924Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: partitions assigned: [multi-partition-dlq-0]
2025-12-18T15:26:22.939Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Finished assignment for group at generation 1: {consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905=Assignment(partitions=[replay-source-topic-1-0])}
2025-12-18T15:26:22.940Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905 for group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.941Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905', protocol='range'}
2025-12-18T15:26:22.941Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Notifying assignor about the new Assignment(partitions=[replay-source-topic-1-0])
2025-12-18T15:26:22.941Z  INFO 53856 --- [tainer#14-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Adding newly assigned partitions: replay-source-topic-1-0
2025-12-18T15:26:22.941Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6=Assignment(partitions=[test-topic-0])}
2025-12-18T15:26:22.941Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6 for group test-group for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.941Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Found no committed offset for partition replay-source-topic-1-0
2025-12-18T15:26:22.942Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Resetting offset for partition replay-source-topic-1-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.942Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe: partitions assigned: [replay-source-topic-1-0]
2025-12-18T15:26:22.942Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6', protocol='range'}
2025-12-18T15:26:22.942Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Notifying assignor about the new Assignment(partitions=[test-topic-0])
2025-12-18T15:26:22.942Z  INFO 53856 --- [tainer#10-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-61, groupId=test-group] Adding newly assigned partitions: test-topic-0
2025-12-18T15:26:22.943Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Found no committed offset for partition test-topic-0
2025-12-18T15:26:22.943Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-61, groupId=test-group] Resetting offset for partition test-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.943Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [test-topic-0]
2025-12-18T15:26:22.969Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Finished assignment for group at generation 1: {consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b=Assignment(partitions=[replay-source-topic-2-0])}
2025-12-18T15:26:22.970Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b for group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.971Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b', protocol='range'}
2025-12-18T15:26:22.971Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Notifying assignor about the new Assignment(partitions=[replay-source-topic-2-0])
2025-12-18T15:26:22.971Z  INFO 53856 --- [tainer#15-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Adding newly assigned partitions: replay-source-topic-2-0
2025-12-18T15:26:22.971Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Found no committed offset for partition replay-source-topic-2-0
2025-12-18T15:26:22.972Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Resetting offset for partition replay-source-topic-2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.972Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac: partitions assigned: [replay-source-topic-2-0]
2025-12-18T15:26:22.979Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Finished assignment for group at generation 1: {consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92=Assignment(partitions=[replay-source-topic-3-0])}
2025-12-18T15:26:22.979Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92 for group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 for generation 1. The group has 1 members, 0 of which are static.
2025-12-18T15:26:22.980Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Successfully synced group in generation Generation{generationId=1, memberId='consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92', protocol='range'}
2025-12-18T15:26:22.980Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Notifying assignor about the new Assignment(partitions=[replay-source-topic-3-0])
2025-12-18T15:26:22.981Z  INFO 53856 --- [tainer#16-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Adding newly assigned partitions: replay-source-topic-3-0
2025-12-18T15:26:22.981Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Found no committed offset for partition replay-source-topic-3-0
2025-12-18T15:26:22.982Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Resetting offset for partition replay-source-topic-3-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:46137 (id: 0 rack: null)], epoch=0}}.
2025-12-18T15:26:22.982Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404: partitions assigned: [replay-source-topic-3-0]
2025-12-18T15:26:27.323Z  INFO 53856 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Processing automatic preferred replica leader election
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Revoke previously assigned partitions conditional-routing-test-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#8-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Revoke previously assigned partitions timeout-dlq-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#12-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-double-group-57, groupId=double-group] Revoke previously assigned partitions double-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Revoke previously assigned partitions batch-mixed-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: partitions revoked: [timeout-dlq-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#13-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-string-group-65, groupId=string-group] Revoke previously assigned partitions string-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: partitions revoked: [batch-mixed-topic-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#19-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Revoke previously assigned partitions replay-source-topic-6-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#10-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-61, groupId=test-group] Revoke previously assigned partitions test-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Revoke previously assigned partitions circuit-breaker-dlq-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Member consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#18-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Revoke previously assigned partitions replay-source-topic-5-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Revoke previously assigned partitions test-dlq-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: partitions revoked: [circuit-breaker-dlq-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Member consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: partitions revoked: [test-dlq-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Revoke previously assigned partitions replay-source-topic-1-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#15-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Revoke previously assigned partitions replay-source-topic-2-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Member consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Member consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe: partitions revoked: [replay-source-topic-1-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Member consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#7-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Revoke previously assigned partitions validation-dlq-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Revoke previously assigned partitions circuit-breaker-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Revoke previously assigned partitions batch-window-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: partitions revoked: [circuit-breaker-topic-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: partitions revoked: [validation-dlq-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#17-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Revoke previously assigned partitions replay-source-topic-4-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#11-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Revoke previously assigned partitions dlq-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Member consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157: partitions revoked: [replay-source-topic-4-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: partitions revoked: [conditional-routing-test-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: partitions revoked: [dlq-topic-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Revoke previously assigned partitions batch-capacity-topic-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Member consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Member consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group timeout-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: partitions revoked: [double-topic-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#21-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Revoke previously assigned partitions multi-partition-dlq-0
2025-12-18T15:26:32.778Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group test-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#20-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Revoke previously assigned partitions multi-partition-topic-0
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group timeout-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: partitions revoked: [batch-window-topic-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: partitions revoked: [multi-partition-topic-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#9-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Revoke previously assigned partitions default-dlq-0
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group circuit-breaker-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Member consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: partitions revoked: [string-topic-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a: partitions revoked: [replay-source-topic-6-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: partitions revoked: [default-dlq-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: [test-topic-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Member consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Member consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#16-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Revoke previously assigned partitions replay-source-topic-3-0
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Member consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2: partitions revoked: [replay-source-topic-5-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Member consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404: partitions revoked: [replay-source-topic-3-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Member consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Member consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac: partitions revoked: [replay-source-topic-2-0]
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Member consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Member consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group circuit-breaker-dlq-tracker in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-mixed-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group circuit-breaker-dlq-tracker with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-mixed-group-60, groupId=batch-mixed-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: partitions revoked: [batch-capacity-topic-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Member consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-dlq-group-48, groupId=default-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.778Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-circuit-breaker-group-50-35a3e4a6-d94d-4093-967d-8c0ac77b4933, groupInstanceId=None, clientId=consumer-circuit-breaker-group-50, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group circuit-breaker-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.778Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Member consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1 sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-capacity-group-58, groupId=batch-capacity-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Member consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: partitions revoked: [multi-partition-dlq-0]
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Member consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-circuit-breaker-dlq-tracker-51-8de3770f-d1b7-49b9-ae97-f72add1c7d48, groupInstanceId=None, clientId=consumer-circuit-breaker-dlq-tracker-51, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group circuit-breaker-dlq-tracker through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group conditional-test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-double-group-57, groupId=double-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-validation-dlq-group-46, groupId=validation-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-61, groupId=test-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group string-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-mixed-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-dlq-group-45-d9dcf157-8e4f-4958-977c-be2bedf0edeb, groupInstanceId=None, clientId=consumer-test-dlq-group-45, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#14-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, groupId=replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#20-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-test-group-59, groupId=multi-partition-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-timeout-dlq-group-47-298664da-c885-4873-aef4-8eb3ff89d55e, groupInstanceId=None, clientId=consumer-timeout-dlq-group-47, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group timeout-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-group-50, groupId=circuit-breaker-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Member consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d sending LeaveGroup request to coordinator localhost:46137 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Removing member consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-conditional-test-group-52, groupId=conditional-test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.779Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group conditional-test-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a with generation 2 is now empty (__consumer_offsets-3)
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group test-group with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.779Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-mixed-group-60-6948f2c7-f9e7-4774-a16b-ea773b811df2, groupInstanceId=None, clientId=consumer-batch-mixed-group-60, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-mixed-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-string-group-65, groupId=string-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group string-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#21-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-multi-partition-dlq-collector-62, groupId=multi-partition-dlq-collector] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-circuit-breaker-dlq-tracker-51, groupId=circuit-breaker-dlq-tracker] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54-0248bab1-62bd-4541-b90e-f27a57a76994, groupInstanceId=None, clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-dlq-group-45, groupId=test-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-timeout-dlq-group-47, groupId=timeout-dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66-70af870f-740a-408b-b0b7-690657fa3905, groupInstanceId=None, clientId=consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#11-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-dlq-group-56, groupId=dlq-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#18-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, groupId=replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#13-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-string-group-65, groupId=string-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-batch-window-group-49, groupId=batch-window-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53-db384861-d04c-406e-88ee-27ae1377b064, groupInstanceId=None, clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group multi-partition-test-group with generation 2 is now empty (__consumer_offsets-1)
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#16-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, groupId=replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-group-61-dff807a9-01d4-410c-9d24-ffa674697ee6, groupInstanceId=None, clientId=consumer-test-group-61, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-conditional-test-group-52-2c3a7184-c157-43b3-9393-af3f313bb517, groupInstanceId=None, clientId=consumer-conditional-test-group-52, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group conditional-test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#19-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53, groupId=replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#12-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-double-group-57, groupId=double-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Unsubscribed all topics or patterns and assigned partitions
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-string-group-65-90c5743d-fda9-4d4a-994b-f6fd172a3072, groupInstanceId=None, clientId=consumer-string-group-65, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group string-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group default-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-capacity-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-capacity-group with generation 2 is now empty (__consumer_offsets-2)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group default-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64-e1990fc3-c9e4-4414-9a69-e01b5a81cb92, groupInstanceId=None, clientId=consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group validation-dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Removing member consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group validation-dlq-group with generation 2 is now empty (__consumer_offsets-4)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63-35fab495-0b32-4a01-988b-ccc7b87d566b, groupInstanceId=None, clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55-3df409ae-4d30-4dbe-8dce-33d32735e620, groupInstanceId=None, clientId=consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-multi-partition-test-group-59-dc01a1b5-ab0d-46c7-b337-dd9774a618e8, groupInstanceId=None, clientId=consumer-multi-partition-test-group-59, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group multi-partition-test-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#17-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54, groupId=replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.780Z  INFO 53856 --- [tainer#10-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-61, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group dlq-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7 on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.781Z  INFO 53856 --- [tainer#15-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63, groupId=replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac] Request joining group due to: consumer pro-actively leaving the group
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group batch-window-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group multi-partition-dlq-collector in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Removing member consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-capacity-group-58-cc282c60-b72a-40ea-890e-eb18c9cc3d6f, groupInstanceId=None, clientId=consumer-batch-capacity-group-58, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-capacity-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group batch-window-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group dlq-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-default-dlq-group-48-d5a7fce0-c85b-497c-9390-d26ef9800dbe, groupInstanceId=None, clientId=consumer-default-dlq-group-48, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group default-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-validation-dlq-group-46-f7add7e1-ab3b-4b4c-9d9a-ff0d19b33fe1, groupInstanceId=None, clientId=consumer-validation-dlq-group-46, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group validation-dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group multi-partition-dlq-collector with generation 2 is now empty (__consumer_offsets-3)
2025-12-18T15:26:32.781Z  INFO 53856 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-multi-partition-dlq-collector-62-62883519-23b7-48bd-8fc7-73743fc04f0d, groupInstanceId=None, clientId=consumer-multi-partition-dlq-collector-62, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group multi-partition-dlq-collector through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.782Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group double-group in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Removing member consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-12-18T15:26:32.782Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group double-group with generation 2 is now empty (__consumer_offsets-0)
2025-12-18T15:26:32.782Z  INFO 53856 --- [quest-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-dlq-group-56-c56bcf64-0e36-4c42-9e88-3eca3d0bf8c7, groupInstanceId=None, clientId=consumer-dlq-group-56, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group dlq-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.782Z  INFO 53856 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-batch-window-group-49-fc0071b6-92c9-4262-acd4-87c7700e7dff, groupInstanceId=None, clientId=consumer-batch-window-group-49, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group batch-window-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.782Z  INFO 53856 --- [quest-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-double-group-57-45ffbc84-b9e6-4b7d-b5a8-6e1600de997e, groupInstanceId=None, clientId=consumer-double-group-57, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group double-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#20-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:32.933Z  INFO 53856 --- [tainer#17-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:32.934Z  INFO 53856 --- [tainer#17-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157-54 unregistered
2025-12-18T15:26:32.934Z  INFO 53856 --- [tainer#17-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-4-f0e58f0c-9974-4662-bf20-4ec1e0910157: Consumer stopped
2025-12-18T15:26:32.934Z  INFO 53856 --- [tainer#20-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-multi-partition-test-group-59 unregistered
2025-12-18T15:26:32.934Z  INFO 53856 --- [tainer#20-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-test-group: Consumer stopped
2025-12-18T15:26:32.945Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:32.945Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:32.945Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:32.945Z  INFO 53856 --- [tainer#21-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:32.946Z  INFO 53856 --- [tainer#21-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-multi-partition-dlq-collector-62 unregistered
2025-12-18T15:26:32.946Z  INFO 53856 --- [tainer#21-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : multi-partition-dlq-collector: Consumer stopped
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#10-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:32.964Z  INFO 53856 --- [tainer#14-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:32.965Z  INFO 53856 --- [tainer#10-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-test-group-61 unregistered
2025-12-18T15:26:32.965Z  INFO 53856 --- [tainer#10-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: Consumer stopped
2025-12-18T15:26:32.965Z  INFO 53856 --- [tainer#14-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe-66 unregistered
2025-12-18T15:26:32.965Z  INFO 53856 --- [tainer#14-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-1-1ac918e4-56fd-4acd-8441-27db64aea3fe: Consumer stopped
2025-12-18T15:26:32.998Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:32.998Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:32.998Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:32.998Z  INFO 53856 --- [tainer#15-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:32.998Z  INFO 53856 --- [tainer#15-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac-63 unregistered
2025-12-18T15:26:32.998Z  INFO 53856 --- [tainer#15-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-2-a34865d9-b816-4657-ad1d-366f47d107ac: Consumer stopped
2025-12-18T15:26:33.003Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.003Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.003Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.003Z  INFO 53856 --- [tainer#16-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.004Z  INFO 53856 --- [tainer#16-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404-64 unregistered
2025-12-18T15:26:33.004Z  INFO 53856 --- [tainer#16-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-3-b6ce3f45-db57-4c40-8daa-2e9854fa4404: Consumer stopped
2025-12-18T15:26:33.204Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.204Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.204Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.204Z  INFO 53856 --- [ntainer#6-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.205Z  INFO 53856 --- [ntainer#6-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-test-dlq-group-45 unregistered
2025-12-18T15:26:33.205Z  INFO 53856 --- [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-dlq-group: Consumer stopped
2025-12-18T15:26:33.212Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.212Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.212Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.212Z  INFO 53856 --- [ntainer#7-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.213Z  INFO 53856 --- [ntainer#7-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-validation-dlq-group-46 unregistered
2025-12-18T15:26:33.213Z  INFO 53856 --- [ntainer#7-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : validation-dlq-group: Consumer stopped
2025-12-18T15:26:33.218Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.218Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.218Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.218Z  INFO 53856 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.218Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.218Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#9-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#8-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-window-group-49 unregistered
2025-12-18T15:26:33.219Z  INFO 53856 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-window-group: Consumer stopped
2025-12-18T15:26:33.220Z  INFO 53856 --- [ntainer#9-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-default-dlq-group-48 unregistered
2025-12-18T15:26:33.220Z  INFO 53856 --- [ntainer#9-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-dlq-group: Consumer stopped
2025-12-18T15:26:33.220Z  INFO 53856 --- [ntainer#8-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-timeout-dlq-group-47 unregistered
2025-12-18T15:26:33.220Z  INFO 53856 --- [ntainer#8-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : timeout-dlq-group: Consumer stopped
2025-12-18T15:26:33.226Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.226Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.226Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.226Z  INFO 53856 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-circuit-breaker-dlq-tracker-51 unregistered
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-dlq-tracker: Consumer stopped
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-circuit-breaker-group-50 unregistered
2025-12-18T15:26:33.227Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.227Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.227Z  INFO 53856 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : circuit-breaker-group: Consumer stopped
2025-12-18T15:26:33.227Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.227Z  INFO 53856 --- [tainer#19-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.228Z  INFO 53856 --- [tainer#19-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a-53 unregistered
2025-12-18T15:26:33.228Z  INFO 53856 --- [tainer#19-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-6-bc0bf290-7220-4884-a60f-b8114b43a17a: Consumer stopped
2025-12-18T15:26:33.234Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#11-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#12-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.234Z  INFO 53856 --- [tainer#18-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.235Z  INFO 53856 --- [ntainer#5-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-conditional-test-group-52 unregistered
2025-12-18T15:26:33.235Z  INFO 53856 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : conditional-test-group: Consumer stopped
2025-12-18T15:26:33.235Z  INFO 53856 --- [tainer#12-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-double-group-57 unregistered
2025-12-18T15:26:33.236Z  INFO 53856 --- [tainer#12-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : double-group: Consumer stopped
2025-12-18T15:26:33.236Z  INFO 53856 --- [tainer#11-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-dlq-group-56 unregistered
2025-12-18T15:26:33.236Z  INFO 53856 --- [tainer#11-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : dlq-group: Consumer stopped
2025-12-18T15:26:33.236Z  INFO 53856 --- [tainer#18-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2-55 unregistered
2025-12-18T15:26:33.236Z  INFO 53856 --- [tainer#18-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : replay-test-listener-5-76bf0de9-5b7f-4fc3-a7ab-642e14a707c2: Consumer stopped
2025-12-18T15:26:33.248Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.248Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.248Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.248Z  INFO 53856 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.249Z  INFO 53856 --- [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-capacity-group-58 unregistered
2025-12-18T15:26:33.249Z  INFO 53856 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-capacity-group: Consumer stopped
2025-12-18T15:26:33.250Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.250Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.250Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.250Z  INFO 53856 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.251Z  INFO 53856 --- [ntainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-batch-mixed-group-60 unregistered
2025-12-18T15:26:33.251Z  INFO 53856 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : batch-mixed-group: Consumer stopped
2025-12-18T15:26:33.272Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.272Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.272Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.272Z  INFO 53856 --- [tainer#13-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.273Z  INFO 53856 --- [tainer#13-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-string-group-65 unregistered
2025-12-18T15:26:33.273Z  INFO 53856 --- [tainer#13-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : string-group: Consumer stopped
2025-12-18T15:26:33.274Z  INFO 53856 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-12-18T15:26:33.274Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.275Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.275Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-12-18T15:26:33.275Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.275Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-3 unregistered
2025-12-18T15:26:33.276Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2025-12-18T15:26:33.276Z  INFO 53856 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2025-12-18T15:26:33.276Z  INFO 53856 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2025-12-18T15:26:33.276Z  INFO 53856 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2025-12-18T15:26:33.276Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-12-18T15:26:33.277Z  INFO 53856 --- [channel-manager] org.apache.kafka.clients.NetworkClient   : [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected.
2025-12-18T15:26:33.277Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-12-18T15:26:33.277Z  INFO 53856 --- [           main] kafka.server.KafkaRequestHandlerPool     : [data-plane Kafka Request Handler on Broker 0], shutting down
2025-12-18T15:26:33.277Z  INFO 53856 --- [           main] kafka.server.KafkaRequestHandlerPool     : [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Shutting down
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-12-18T15:26:33.278Z  INFO 53856 --- [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Stopped
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2025-12-18T15:26:33.278Z  INFO 53856 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Shutting down
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Shutdown completed
2025-12-18T15:26:33.278Z  INFO 53856 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Stopped
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2025-12-18T15:26:33.278Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-12-18T15:26:33.278Z  INFO 53856 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] k.server.ReplicaAlterLogDirsManager      : [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] k.server.ReplicaAlterLogDirsManager      : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Shutting down
2025-12-18T15:26:33.279Z  INFO 53856 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-12-18T15:26:33.279Z  INFO 53856 --- [r-0-ElectLeader] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ElectLeader]: Stopped
2025-12-18T15:26:33.285Z  INFO 53856 --- [           main] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Shutting down
2025-12-18T15:26:33.285Z  INFO 53856 --- [           main] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Shutdown completed
2025-12-18T15:26:33.285Z  INFO 53856 --- [nSenderThread-0] kafka.server.AddPartitionsToTxnManager   : [AddPartitionsToTxnSenderThread-0]: Stopped
2025-12-18T15:26:33.285Z  INFO 53856 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2025-12-18T15:26:33.285Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed
2025-12-18T15:26:33.286Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] k.s.NodeToControllerChannelManagerImpl   : Node to controller channel manager for alter-partition shutdown
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed
2025-12-18T15:26:33.286Z  INFO 53856 --- [channel-manager] k.server.NodeToControllerRequestThread   : [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] k.s.NodeToControllerChannelManagerImpl   : Node to controller channel manager for forwarding shutdown
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Shutting down.
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Shutting down
2025-12-18T15:26:33.286Z  INFO 53856 --- [           main] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Shutdown completed
2025-12-18T15:26:33.286Z  INFO 53856 --- [leaner-thread-0] kafka.log.LogCleaner$CleanerThread       : [kafka-log-cleaner-thread-0]: Stopped
2025-12-18T15:26:33.292Z  INFO 53856 --- [699360208319163] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-0] Wrote producer snapshot at offset 8 with 0 producer ids in 2 ms.
2025-12-18T15:26:33.315Z  INFO 53856 --- [699360208319163] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=string-topic-0] Wrote producer snapshot at offset 2 with 1 producer ids in 1 ms.
2025-12-18T15:26:33.340Z  INFO 53856 --- [699360208319163] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-3] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms.
2025-12-18T15:26:33.362Z  INFO 53856 --- [699360208319163] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 12 with 0 producer ids in 2 ms.
2025-12-18T15:26:33.373Z  INFO 53856 --- [699360208319163] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-1] Wrote producer snapshot at offset 9 with 0 producer ids in 1 ms.
2025-12-18T15:26:33.378Z  INFO 53856 --- [699360208319163] o.a.k.s.i.log.ProducerStateManager       : [ProducerStateManager partition=__consumer_offsets-4] Wrote producer snapshot at offset 12 with 0 producer ids in 1 ms.
2025-12-18T15:26:33.394Z  INFO 53856 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2025-12-18T15:26:33.395Z  INFO 53856 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] k.controller.ZkPartitionStateMachine     : [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] kafka.controller.ZkReplicaStateMachine   : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2025-12-18T15:26:33.395Z  INFO 53856 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Shutting down
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Shutdown completed
2025-12-18T15:26:33.395Z  INFO 53856 --- [-process-thread] stener$ChangeNotificationProcessorThread : [feature-zk-node-event-process-thread]: Stopped
2025-12-18T15:26:33.395Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Closing.
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000070e5240000 closed
2025-12-18T15:26:33.497Z  INFO 53856 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000070e5240000
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient Kafka server] Closed.
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2025-12-18T15:26:33.497Z  INFO 53856 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2025-12-18T15:26:33.497Z  INFO 53856 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-12-18T15:26:33.497Z  INFO 53856 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-12-18T15:26:33.497Z  INFO 53856 --- [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-12-18T15:26:33.497Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-12-18T15:26:33.499Z  INFO 53856 --- [           main] kafka.network.SocketServer               : [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-12-18T15:26:33.499Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-12-18T15:26:33.499Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-12-18T15:26:33.499Z  INFO 53856 --- [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-12-18T15:26:33.499Z  INFO 53856 --- [           main] kafka.server.BrokerTopicStats            : Broker and topic stats closed
2025-12-18T15:26:33.500Z  INFO 53856 --- [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.server for 0 unregistered
2025-12-18T15:26:33.500Z  INFO 53856 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2025-12-18T15:26:33.501Z  INFO 53856 --- [nnectionExpirer] o.a.z.server.NIOServerCnxnFactory        : ConnnectionExpirerThread interrupted
2025-12-18T15:26:33.502Z  INFO 53856 --- [electorThread-0] o.a.z.server.NIOServerCnxnFactory        : selector thread exitted run method
2025-12-18T15:26:33.502Z  INFO 53856 --- [electorThread-1] o.a.z.server.NIOServerCnxnFactory        : selector thread exitted run method
2025-12-18T15:26:33.502Z  INFO 53856 --- [ad:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : accept thread exitted run method
2025-12-18T15:26:33.502Z  INFO 53856 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2025-12-18T15:26:33.502Z  INFO 53856 --- [           main] o.a.zookeeper.server.RequestThrottler    : Shutting down
2025-12-18T15:26:33.502Z  INFO 53856 --- [equestThrottler] o.a.zookeeper.server.RequestThrottler    : Draining request throttler queue
2025-12-18T15:26:33.502Z  INFO 53856 --- [equestThrottler] o.a.zookeeper.server.RequestThrottler    : RequestThrottler shutdown. Dropped 0 requests
2025-12-18T15:26:33.502Z  INFO 53856 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2025-12-18T15:26:33.502Z  INFO 53856 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2025-12-18T15:26:33.502Z  INFO 53856 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2025-12-18T15:26:33.502Z  INFO 53856 --- [0 cport:43887):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2025-12-18T15:26:33.502Z  INFO 53856 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2025-12-18T15:26:33.502Z  INFO 53856 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[ERROR] Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 17.54 s <<< FAILURE! -- in net.damero.TypeHandlingIntegrationTest
[ERROR] net.damero.TypeHandlingIntegrationTest.testStringTypeHandling -- Time elapsed: 10.88 s <<< ERROR!
org.awaitility.core.ConditionTimeoutException: Assertion condition Should receive both messages if deduplication is handled correctly ==> expected: <2> but was: <1> within 10 seconds.
	at org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)
	at org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)
	at org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)
	at org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)
	at org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)
	at net.damero.TypeHandlingIntegrationTest.testStringTypeHandling(TypeHandlingIntegrationTest.java:83)
	at java.base/java.lang.reflect.Method.invoke(Method.java:565)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
Caused by: org.opentest4j.AssertionFailedError: Should receive both messages if deduplication is handled correctly ==> expected: <2> but was: <1>
	at org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:151)
	at org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132)
	at org.junit.jupiter.api.AssertEquals.failNotEqual(AssertEquals.java:197)
	at org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:150)
	at org.junit.jupiter.api.Assertions.assertEquals(Assertions.java:563)
	at net.damero.TypeHandlingIntegrationTest.lambda$testStringTypeHandling$0(TypeHandlingIntegrationTest.java:84)
	at org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)
	at org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)
	at org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:328)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1090)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:614)
	at java.base/java.lang.Thread.run(Thread.java:1474)

[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   TypeHandlingIntegrationTest.testStringTypeHandling:83  ConditionTimeout Assertion condition Should receive both messages if deduplication is handled correctly ==> expected: <2> but was: <1> within 10 seconds.
[INFO] 
[ERROR] Tests run: 3, Failures: 0, Errors: 1, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  20.488 s
[INFO] Finished at: 2025-12-18T15:26:33Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.5.4:test (default-test) on project java-damero: 
[ERROR] 
[ERROR] See /home/sam-o-reilly/Downloads/java-damero/target/surefire-reports for the individual test results.
[ERROR] See dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
